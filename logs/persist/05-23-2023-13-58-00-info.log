2023-05-23 13:58:00,460 | root | INFO | main.py run @ 50 : processing unit: cpu
2023-05-23 13:58:00,460 | root | INFO | main.py run @ 68 : train dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/train.csv', 'output_path': 'data/preprocessed/dataset-v2/', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-05-23 13:58:00,460 | root | INFO | main.py run @ 69 : test dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/test.csv', 'output_path': 'data/preprocessed/dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-05-23 13:58:00,470 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,470 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,560 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-05-23 13:58:00,560 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-test-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-05-23 13:58:00,560 | root | INFO | main.py run @ 68 : train dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,560 | root | INFO | main.py run @ 69 : test dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,560 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,570 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 68 : train dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 69 : test dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 68 : train dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 69 : test dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 68 : train dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 69 : test dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 68 : train dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-train-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,580 | root | INFO | main.py run @ 69 : test dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-test-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 13:58:00,590 | root | INFO | main.py run @ 73 : started new session: balanced-v2-04
2023-05-23 13:58:00,590 | root | INFO | main.py create_model_configs @ 37 : activation module kwargs: {}
2023-05-23 13:58:00,600 | root | INFO | main.py create_model_configs @ 38 : loss module kwargs: {'reduction': 'sum', 'pos_weight': tensor(0.7500)}
2023-05-23 13:58:00,600 | root | INFO | main.py run @ 84 : started new command `train` of session `balanced-v2-04`
2023-05-23 13:58:00,610 | root | INFO | dataset.py preprocess @ 189 : trying to load tokens from file
2023-05-23 13:58:03,897 | root | INFO | dataset.py __vectorize__ @ 103 : loading vectors from file
2023-05-23 13:58:07,332 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-23 13:58:07,372 | root | INFO | dataset.py split_dataset_by_label @ 158 : loading splits from: data/preprocessed/conversation-balanced-v2-04/conversation-bow-with-triple/rr.idr/splits-n4stratified.pkl
2023-05-23 13:58:07,382 | root | INFO | ann.py __init__ @ 213 : dimension list of nodes: [32, 1]
2023-05-23 13:58:07,382 | root | INFO | ann.py __init__ @ 214 : dropout list: [0.0]
2023-05-23 13:58:07,382 | root | INFO | ann.py learn @ 248 : training phase started
2023-05-23 13:58:07,382 | root | INFO | ann.py learn @ 251 : number of folds: 4
2023-05-23 13:58:07,382 | root | INFO | ann.py learn @ 254 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 13:58:07,382 | root | INFO | ann.py learn @ 259 : fetching data for fold #0
2023-05-23 13:58:07,382 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 13:58:07,392 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 13:58:12,404 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 0 | train -> loss: 272.35705 | validation -> loss: 2.85393 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 13:58:17,556 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 1 | train -> loss: 269.09127 | validation -> loss: 2.83240 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 13:58:22,811 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 2 | train -> loss: 265.48943 | validation -> loss: 2.77565 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 13:58:27,707 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 3 | train -> loss: 257.77266 | validation -> loss: 2.66989 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 13:58:32,912 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 4 | train -> loss: 244.61310 | validation -> loss: 2.50163 | accuracy: 63.095238 | precision: 91.489365 | recall: 8.531746 | f2: 10.421716
2023-05-23 13:58:38,055 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 5 | train -> loss: 225.95607 | validation -> loss: 2.29196 | accuracy: 69.365082 | precision: 91.549294 | recall: 25.793652 | f2: 30.120483
2023-05-23 13:58:43,137 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 6 | train -> loss: 205.63713 | validation -> loss: 2.10226 | accuracy: 71.666664 | precision: 90.163933 | recall: 32.738094 | f2: 37.517052
2023-05-23 13:58:48,169 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 7 | train -> loss: 186.96491 | validation -> loss: 1.93981 | accuracy: 73.333336 | precision: 90.776703 | recall: 37.103172 | f2: 42.079208
2023-05-23 13:58:53,333 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 8 | train -> loss: 171.54526 | validation -> loss: 1.79285 | accuracy: 85.079369 | precision: 88.164253 | recall: 72.420631 | f2: 75.102882
2023-05-23 13:58:58,495 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 9 | train -> loss: 159.31860 | validation -> loss: 1.69116 | accuracy: 88.412697 | precision: 87.923729 | recall: 82.341270 | f2: 83.400322
2023-05-23 13:59:03,685 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 10 | train -> loss: 149.30593 | validation -> loss: 1.59447 | accuracy: 88.571426 | precision: 88.793106 | recall: 81.746033 | f2: 83.064514
2023-05-23 13:59:08,708 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 11 | train -> loss: 141.26926 | validation -> loss: 1.52910 | accuracy: 88.968254 | precision: 88.912582 | recall: 82.738098 | f2: 83.903419
2023-05-23 13:59:13,872 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 12 | train -> loss: 135.45960 | validation -> loss: 1.47324 | accuracy: 89.126984 | precision: 90.507729 | recall: 81.349205 | f2: 83.029572
2023-05-23 13:59:18,989 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 13 | train -> loss: 130.70892 | validation -> loss: 1.44888 | accuracy: 90.793648 | precision: 87.307693 | recall: 90.079369 | f2: 89.511040
2023-05-23 13:59:24,204 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 14 | train -> loss: 125.25048 | validation -> loss: 1.38603 | accuracy: 89.761909 | precision: 91.390732 | recall: 82.142860 | f2: 83.839615
2023-05-23 13:59:29,108 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 15 | train -> loss: 120.59378 | validation -> loss: 1.40234 | accuracy: 90.555557 | precision: 84.936485 | recall: 92.857140 | f2: 91.156998
2023-05-23 13:59:34,204 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 16 | train -> loss: 116.69526 | validation -> loss: 1.32173 | accuracy: 91.428574 | precision: 88.823524 | recall: 89.880959 | f2: 89.667458
2023-05-23 13:59:39,258 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 17 | train -> loss: 111.95827 | validation -> loss: 1.33305 | accuracy: 86.984131 | precision: 92.500000 | recall: 73.412697 | f2: 76.572845
2023-05-23 13:59:44,290 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 18 | train -> loss: 109.20515 | validation -> loss: 1.29121 | accuracy: 88.253967 | precision: 92.583733 | recall: 76.785713 | f2: 79.498764
2023-05-23 13:59:49,691 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 19 | train -> loss: 105.68648 | validation -> loss: 1.22345 | accuracy: 90.714287 | precision: 91.973969 | recall: 84.126984 | f2: 85.587402
2023-05-23 13:59:56,757 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 20 | train -> loss: 103.29856 | validation -> loss: 1.26107 | accuracy: 91.507935 | precision: 85.895119 | recall: 94.246033 | f2: 92.448425
2023-05-23 14:00:03,738 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 21 | train -> loss: 100.90147 | validation -> loss: 1.19088 | accuracy: 92.380951 | precision: 88.931297 | recall: 92.460320 | f2: 91.732285
2023-05-23 14:00:09,939 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 22 | train -> loss: 97.84181 | validation -> loss: 1.14382 | accuracy: 92.142853 | precision: 90.581161 | recall: 89.682541 | f2: 89.860832
2023-05-23 14:00:15,767 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 23 | train -> loss: 95.26493 | validation -> loss: 1.20622 | accuracy: 88.174606 | precision: 93.611794 | recall: 75.595238 | f2: 78.621544
2023-05-23 14:00:20,899 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 24 | train -> loss: 92.92323 | validation -> loss: 1.10455 | accuracy: 92.380951 | precision: 90.963860 | recall: 89.880959 | f2: 90.095467
2023-05-23 14:00:26,664 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 25 | train -> loss: 91.37555 | validation -> loss: 1.19427 | accuracy: 88.253967 | precision: 94.723618 | recall: 74.801590 | f2: 78.086159
2023-05-23 14:00:31,750 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 26 | train -> loss: 88.90456 | validation -> loss: 1.06197 | accuracy: 92.063492 | precision: 91.908714 | recall: 87.896820 | f2: 88.670937
2023-05-23 14:00:36,814 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 27 | train -> loss: 88.17720 | validation -> loss: 1.05763 | accuracy: 93.095238 | precision: 89.714279 | recall: 93.452385 | f2: 92.680046
2023-05-23 14:00:42,461 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 28 | train -> loss: 85.87227 | validation -> loss: 1.05679 | accuracy: 93.015877 | precision: 89.245285 | recall: 93.849205 | f2: 92.890808
2023-05-23 14:00:48,090 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 29 | train -> loss: 83.65529 | validation -> loss: 1.02073 | accuracy: 92.301590 | precision: 92.662468 | recall: 87.698410 | f2: 88.648216
2023-05-23 14:00:53,596 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 30 | train -> loss: 81.73585 | validation -> loss: 1.00824 | accuracy: 93.809525 | precision: 90.961540 | recall: 93.849205 | f2: 93.257103
2023-05-23 14:00:59,429 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 31 | train -> loss: 80.22045 | validation -> loss: 1.00266 | accuracy: 92.460320 | precision: 93.418259 | recall: 87.301590 | f2: 88.459991
2023-05-23 14:01:04,953 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 32 | train -> loss: 80.56206 | validation -> loss: 0.96237 | accuracy: 93.412697 | precision: 91.518738 | recall: 92.063492 | f2: 91.954025
2023-05-23 14:01:10,767 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 33 | train -> loss: 77.24640 | validation -> loss: 1.00596 | accuracy: 93.015877 | precision: 88.235298 | recall: 95.238098 | f2: 93.750000
2023-05-23 14:01:16,113 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 34 | train -> loss: 76.15255 | validation -> loss: 0.93412 | accuracy: 93.492058 | precision: 91.372551 | recall: 92.460320 | f2: 92.240700
2023-05-23 14:01:21,335 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 35 | train -> loss: 74.61088 | validation -> loss: 0.92336 | accuracy: 93.492058 | precision: 93.061226 | recall: 90.476189 | f2: 90.981644
2023-05-23 14:01:26,259 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 36 | train -> loss: 73.91835 | validation -> loss: 0.97412 | accuracy: 93.333336 | precision: 88.888893 | recall: 95.238098 | f2: 93.896713
2023-05-23 14:01:31,462 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 37 | train -> loss: 73.38208 | validation -> loss: 0.91546 | accuracy: 93.412697 | precision: 94.129982 | recall: 89.087303 | f2: 90.052147
2023-05-23 14:01:36,575 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 38 | train -> loss: 69.75499 | validation -> loss: 0.91118 | accuracy: 93.888893 | precision: 91.295937 | recall: 93.650795 | f2: 93.170151
2023-05-23 14:01:41,740 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 39 | train -> loss: 68.92205 | validation -> loss: 0.88406 | accuracy: 93.888893 | precision: 91.944992 | recall: 92.857140 | f2: 92.673264
2023-05-23 14:01:46,874 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 40 | train -> loss: 69.42626 | validation -> loss: 0.87078 | accuracy: 93.888893 | precision: 92.445328 | recall: 92.261902 | f2: 92.298531
2023-05-23 14:01:51,969 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 41 | train -> loss: 67.02977 | validation -> loss: 0.89765 | accuracy: 93.650795 | precision: 95.106384 | recall: 88.690475 | f2: 89.903465
2023-05-23 14:01:57,042 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 42 | train -> loss: 65.57332 | validation -> loss: 0.88438 | accuracy: 93.095238 | precision: 95.227768 | recall: 87.103180 | f2: 88.615265
2023-05-23 14:02:02,182 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 43 | train -> loss: 65.93052 | validation -> loss: 0.83690 | accuracy: 94.047615 | precision: 92.307693 | recall: 92.857140 | f2: 92.746727
2023-05-23 14:02:07,235 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 44 | train -> loss: 65.24309 | validation -> loss: 0.83098 | accuracy: 93.968254 | precision: 92.292488 | recall: 92.658730 | f2: 92.585251
2023-05-23 14:02:12,338 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 45 | train -> loss: 64.07226 | validation -> loss: 0.82125 | accuracy: 94.444443 | precision: 94.105690 | recall: 91.865082 | f2: 92.304626
2023-05-23 14:02:17,387 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 46 | train -> loss: 62.35846 | validation -> loss: 0.81372 | accuracy: 94.285713 | precision: 93.199997 | recall: 92.460320 | f2: 92.607315
2023-05-23 14:02:22,505 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 47 | train -> loss: 62.10352 | validation -> loss: 0.81001 | accuracy: 94.365082 | precision: 93.386772 | recall: 92.460320 | f2: 92.644135
2023-05-23 14:02:27,547 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 48 | train -> loss: 61.07944 | validation -> loss: 0.81656 | accuracy: 94.365082 | precision: 92.202728 | recall: 93.849205 | f2: 93.515221
2023-05-23 14:02:32,799 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 49 | train -> loss: 59.41445 | validation -> loss: 0.80505 | accuracy: 94.365082 | precision: 95.387840 | recall: 90.277779 | f2: 91.255516
2023-05-23 14:02:38,278 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 50 | train -> loss: 58.63608 | validation -> loss: 0.83750 | accuracy: 93.492058 | precision: 95.670998 | recall: 87.698410 | f2: 89.184830
2023-05-23 14:02:44,161 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 51 | train -> loss: 58.46763 | validation -> loss: 0.83314 | accuracy: 94.047615 | precision: 90.093460 | recall: 95.634918 | f2: 94.472755
2023-05-23 14:02:49,884 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 52 | train -> loss: 57.33305 | validation -> loss: 0.87829 | accuracy: 93.015877 | precision: 95.814980 | recall: 86.309525 | f2: 88.056679
2023-05-23 14:02:55,482 | root | INFO | ann.py learn @ 290 : fold: 0 | epoch: 53 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 14:02:55,591 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 53 | train -> loss: 56.94513 | validation -> loss: 0.75810 | accuracy: 94.841270 | precision: 93.638168 | recall: 93.452385 | f2: 93.489479
2023-05-23 14:03:01,063 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 54 | train -> loss: 54.66488 | validation -> loss: 0.75655 | accuracy: 94.682541 | precision: 94.320488 | recall: 92.261902 | f2: 92.666397
2023-05-23 14:03:06,278 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 55 | train -> loss: 54.23953 | validation -> loss: 0.77173 | accuracy: 94.682541 | precision: 92.427185 | recall: 94.444443 | f2: 94.033981
2023-05-23 14:03:11,649 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 56 | train -> loss: 53.71803 | validation -> loss: 0.76308 | accuracy: 94.761902 | precision: 93.280632 | recall: 93.650795 | f2: 93.576523
2023-05-23 14:03:17,342 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 57 | train -> loss: 53.69265 | validation -> loss: 0.76284 | accuracy: 94.841270 | precision: 95.445129 | recall: 91.468254 | f2: 92.236893
2023-05-23 14:03:23,615 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 58 | train -> loss: 53.70748 | validation -> loss: 0.75433 | accuracy: 94.761902 | precision: 94.877045 | recall: 91.865082 | f2: 92.452080
2023-05-23 14:03:29,415 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 59 | train -> loss: 53.06504 | validation -> loss: 0.76231 | accuracy: 94.841270 | precision: 95.445129 | recall: 91.468254 | f2: 92.236893
2023-05-23 14:03:34,679 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 60 | train -> loss: 53.15193 | validation -> loss: 0.74937 | accuracy: 94.682541 | precision: 93.612770 | recall: 93.055557 | f2: 93.166473
2023-05-23 14:03:39,757 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 61 | train -> loss: 53.42754 | validation -> loss: 0.75376 | accuracy: 94.841270 | precision: 95.257729 | recall: 91.666672 | f2: 92.363052
2023-05-23 14:03:45,033 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 62 | train -> loss: 52.65769 | validation -> loss: 0.75313 | accuracy: 94.761902 | precision: 95.247940 | recall: 91.468254 | f2: 92.199997
2023-05-23 14:03:50,208 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 63 | train -> loss: 52.86382 | validation -> loss: 0.75980 | accuracy: 94.841270 | precision: 95.445129 | recall: 91.468254 | f2: 92.236893
2023-05-23 14:03:55,294 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 64 | train -> loss: 52.13274 | validation -> loss: 0.75580 | accuracy: 94.841270 | precision: 95.445129 | recall: 91.468254 | f2: 92.236893
2023-05-23 14:04:01,339 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 65 | train -> loss: 52.59758 | validation -> loss: 0.76516 | accuracy: 94.523811 | precision: 92.069633 | recall: 94.444443 | f2: 93.959732
2023-05-23 14:04:06,579 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 66 | train -> loss: 52.26877 | validation -> loss: 0.74134 | accuracy: 94.841270 | precision: 94.523331 | recall: 92.460320 | f2: 92.865685
2023-05-23 14:04:11,992 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 67 | train -> loss: 51.74442 | validation -> loss: 0.74645 | accuracy: 94.761902 | precision: 95.247940 | recall: 91.468254 | f2: 92.199997
2023-05-23 14:04:17,482 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 68 | train -> loss: 52.08006 | validation -> loss: 0.74871 | accuracy: 94.682541 | precision: 95.238098 | recall: 91.269836 | f2: 92.036812
2023-05-23 14:04:23,792 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 69 | train -> loss: 51.82538 | validation -> loss: 0.74366 | accuracy: 94.761902 | precision: 95.247940 | recall: 91.468254 | f2: 92.199997
2023-05-23 14:04:29,957 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 70 | train -> loss: 51.60418 | validation -> loss: 0.73733 | accuracy: 94.682541 | precision: 94.141411 | recall: 92.460320 | f2: 92.791718
2023-05-23 14:04:35,434 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 71 | train -> loss: 51.41198 | validation -> loss: 0.73686 | accuracy: 94.920639 | precision: 95.081970 | recall: 92.063492 | f2: 92.651756
2023-05-23 14:04:41,391 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 72 | train -> loss: 51.19824 | validation -> loss: 0.73275 | accuracy: 94.761902 | precision: 93.800003 | recall: 93.055557 | f2: 93.203499
2023-05-23 14:04:46,916 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 73 | train -> loss: 51.36083 | validation -> loss: 0.73573 | accuracy: 94.761902 | precision: 94.331985 | recall: 92.460320 | f2: 92.828682
2023-05-23 14:04:52,705 | root | INFO | ann.py learn @ 313 : fold: 0 | epoch: 74 | train -> loss: 50.97787 | validation -> loss: 0.73195 | accuracy: 95.000000 | precision: 94.908348 | recall: 92.460320 | f2: 92.939774
2023-05-23 14:04:52,715 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-13-58-00-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/weights/f0/model_fold0.pth
2023-05-23 14:04:53,519 | root | INFO | ann.py learn @ 254 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 14:04:53,520 | root | INFO | ann.py learn @ 259 : fetching data for fold #1
2023-05-23 14:04:53,523 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 14:04:53,526 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 14:04:59,203 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 0 | train -> loss: 274.59411 | validation -> loss: 2.84561 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:05:04,117 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 1 | train -> loss: 268.08637 | validation -> loss: 2.81496 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:05:09,139 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 2 | train -> loss: 263.20259 | validation -> loss: 2.74409 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:05:14,428 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 3 | train -> loss: 253.64908 | validation -> loss: 2.61222 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:05:19,932 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 4 | train -> loss: 237.89715 | validation -> loss: 2.44619 | accuracy: 61.428570 | precision: 95.000000 | recall: 3.769841 | f2: 4.666012
2023-05-23 14:05:25,334 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 5 | train -> loss: 218.86548 | validation -> loss: 2.22165 | accuracy: 70.158730 | precision: 94.444443 | recall: 26.984129 | f2: 31.481480
2023-05-23 14:05:30,752 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 6 | train -> loss: 199.96978 | validation -> loss: 2.02640 | accuracy: 77.936508 | precision: 87.417221 | recall: 52.380955 | f2: 56.945641
2023-05-23 14:05:36,019 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 7 | train -> loss: 183.65402 | validation -> loss: 1.85893 | accuracy: 81.507942 | precision: 87.534622 | recall: 62.698410 | f2: 66.470345
2023-05-23 14:05:41,059 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 8 | train -> loss: 169.84381 | validation -> loss: 1.72444 | accuracy: 78.174606 | precision: 89.347076 | recall: 51.587303 | f2: 56.350239
2023-05-23 14:05:46,504 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 9 | train -> loss: 158.78789 | validation -> loss: 1.61592 | accuracy: 88.730156 | precision: 87.396690 | recall: 83.928574 | f2: 84.599998
2023-05-23 14:05:51,897 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 10 | train -> loss: 149.80460 | validation -> loss: 1.50957 | accuracy: 88.809525 | precision: 89.715538 | recall: 81.349205 | f2: 82.895264
2023-05-23 14:05:57,000 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 11 | train -> loss: 142.64339 | validation -> loss: 1.43475 | accuracy: 88.492065 | precision: 90.337082 | recall: 79.761902 | f2: 81.674118
2023-05-23 14:06:02,057 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 12 | train -> loss: 136.68684 | validation -> loss: 1.42525 | accuracy: 90.793648 | precision: 86.194031 | recall: 91.666672 | f2: 90.517242
2023-05-23 14:06:08,369 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 13 | train -> loss: 131.29556 | validation -> loss: 1.39784 | accuracy: 82.936508 | precision: 93.134323 | recall: 61.904762 | f2: 66.354744
2023-05-23 14:06:14,119 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 14 | train -> loss: 127.94732 | validation -> loss: 1.26677 | accuracy: 91.507935 | precision: 90.101013 | recall: 88.492065 | f2: 88.809242
2023-05-23 14:06:19,725 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 15 | train -> loss: 122.25737 | validation -> loss: 1.22309 | accuracy: 91.984131 | precision: 91.718430 | recall: 87.896820 | f2: 88.635460
2023-05-23 14:06:25,664 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 16 | train -> loss: 117.37838 | validation -> loss: 1.19469 | accuracy: 92.222221 | precision: 89.960632 | recall: 90.674606 | f2: 90.530899
2023-05-23 14:06:30,709 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 17 | train -> loss: 114.60128 | validation -> loss: 1.21375 | accuracy: 91.984131 | precision: 86.837296 | recall: 94.246033 | f2: 92.664841
2023-05-23 14:06:36,088 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 18 | train -> loss: 111.55434 | validation -> loss: 1.11802 | accuracy: 92.619049 | precision: 91.853363 | recall: 89.484123 | f2: 89.948151
2023-05-23 14:06:41,786 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 19 | train -> loss: 107.55768 | validation -> loss: 1.09677 | accuracy: 92.460320 | precision: 92.872116 | recall: 87.896820 | f2: 88.848778
2023-05-23 14:06:47,866 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 20 | train -> loss: 104.76373 | validation -> loss: 1.06524 | accuracy: 93.015877 | precision: 91.434265 | recall: 91.071426 | f2: 91.143761
2023-05-23 14:06:54,055 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 21 | train -> loss: 102.79303 | validation -> loss: 1.07569 | accuracy: 92.698410 | precision: 88.432838 | recall: 94.047615 | f2: 92.868340
2023-05-23 14:06:59,437 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 22 | train -> loss: 99.60833 | validation -> loss: 1.01799 | accuracy: 93.333336 | precision: 91.176468 | recall: 92.261902 | f2: 92.042755
2023-05-23 14:07:05,202 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 23 | train -> loss: 97.38233 | validation -> loss: 1.04050 | accuracy: 92.301590 | precision: 94.143166 | recall: 86.111107 | f2: 87.605980
2023-05-23 14:07:10,471 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 24 | train -> loss: 95.34153 | validation -> loss: 0.96682 | accuracy: 93.650795 | precision: 92.063492 | recall: 92.063492 | f2: 92.063492
2023-05-23 14:07:15,868 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 25 | train -> loss: 92.97154 | validation -> loss: 0.98078 | accuracy: 93.015877 | precision: 94.255318 | recall: 87.896820 | f2: 89.098953
2023-05-23 14:07:21,589 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 26 | train -> loss: 89.67969 | validation -> loss: 0.94043 | accuracy: 93.730156 | precision: 93.995857 | recall: 90.079369 | f2: 90.836334
2023-05-23 14:07:27,017 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 27 | train -> loss: 87.79820 | validation -> loss: 0.91203 | accuracy: 93.809525 | precision: 93.827156 | recall: 90.476189 | f2: 91.127098
2023-05-23 14:07:32,587 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 28 | train -> loss: 85.92340 | validation -> loss: 0.91243 | accuracy: 94.126984 | precision: 91.505791 | recall: 94.047615 | f2: 93.528023
2023-05-23 14:07:37,946 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 29 | train -> loss: 83.93913 | validation -> loss: 0.87512 | accuracy: 94.206352 | precision: 92.337921 | recall: 93.253967 | f2: 93.069305
2023-05-23 14:07:43,441 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 30 | train -> loss: 83.64105 | validation -> loss: 0.88069 | accuracy: 94.603172 | precision: 92.248062 | recall: 94.444443 | f2: 93.996841
2023-05-23 14:07:48,820 | root | INFO | ann.py learn @ 290 : fold: 1 | epoch: 31 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 14:07:48,971 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 31 | train -> loss: 80.70994 | validation -> loss: 0.87211 | accuracy: 93.650795 | precision: 94.725739 | recall: 89.087303 | f2: 90.160645
2023-05-23 14:07:54,181 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 32 | train -> loss: 77.37619 | validation -> loss: 0.85613 | accuracy: 94.761902 | precision: 92.277992 | recall: 94.841270 | f2: 94.317284
2023-05-23 14:07:59,501 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 33 | train -> loss: 76.98434 | validation -> loss: 0.84421 | accuracy: 94.285713 | precision: 93.548386 | recall: 92.063492 | f2: 92.356689
2023-05-23 14:08:04,633 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 34 | train -> loss: 76.54719 | validation -> loss: 0.89881 | accuracy: 93.730156 | precision: 95.698921 | recall: 88.293655 | f2: 89.681580
2023-05-23 14:08:09,845 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 35 | train -> loss: 76.43943 | validation -> loss: 0.84660 | accuracy: 94.206352 | precision: 94.802490 | recall: 90.476189 | f2: 91.309570
2023-05-23 14:08:22,896 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 36 | train -> loss: 76.28577 | validation -> loss: 0.84617 | accuracy: 94.206352 | precision: 94.802490 | recall: 90.476189 | f2: 91.309570
2023-05-23 14:08:30,954 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 37 | train -> loss: 75.76808 | validation -> loss: 0.83878 | accuracy: 94.126984 | precision: 94.421486 | recall: 90.674606 | f2: 91.399994
2023-05-23 14:08:37,350 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 38 | train -> loss: 75.35183 | validation -> loss: 0.82810 | accuracy: 94.682541 | precision: 93.267326 | recall: 93.452385 | f2: 93.415314
2023-05-23 14:08:42,534 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 39 | train -> loss: 74.94961 | validation -> loss: 0.82233 | accuracy: 94.444443 | precision: 93.227097 | recall: 92.857140 | f2: 92.930893
2023-05-23 14:08:48,301 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 40 | train -> loss: 74.58841 | validation -> loss: 0.82493 | accuracy: 94.444443 | precision: 94.467209 | recall: 91.468254 | f2: 92.052719
2023-05-23 14:08:53,860 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 41 | train -> loss: 73.72770 | validation -> loss: 0.81751 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:08:59,201 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 42 | train -> loss: 73.34646 | validation -> loss: 0.82812 | accuracy: 95.000000 | precision: 92.322456 | recall: 95.436508 | f2: 94.797005
2023-05-23 14:09:04,278 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 43 | train -> loss: 73.47966 | validation -> loss: 0.83009 | accuracy: 93.968254 | precision: 94.957985 | recall: 89.682541 | f2: 90.690208
2023-05-23 14:09:09,524 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 44 | train -> loss: 72.89756 | validation -> loss: 0.82693 | accuracy: 93.968254 | precision: 94.957985 | recall: 89.682541 | f2: 90.690208
2023-05-23 14:09:15,411 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 45 | train -> loss: 72.61863 | validation -> loss: 0.82002 | accuracy: 94.206352 | precision: 94.802490 | recall: 90.476189 | f2: 91.309570
2023-05-23 14:09:20,943 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 46 | train -> loss: 71.79201 | validation -> loss: 0.83310 | accuracy: 94.047615 | precision: 95.735611 | recall: 89.087303 | f2: 90.342049
2023-05-23 14:09:26,873 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 47 | train -> loss: 71.90836 | validation -> loss: 0.80249 | accuracy: 94.920639 | precision: 93.307083 | recall: 94.047615 | f2: 93.898575
2023-05-23 14:09:32,424 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 48 | train -> loss: 71.38987 | validation -> loss: 0.80303 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:09:37,609 | root | INFO | ann.py learn @ 290 : fold: 1 | epoch: 49 | Learning rate changed from: 0.00125 -> 0.0003125
2023-05-23 14:09:37,730 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 49 | train -> loss: 70.91955 | validation -> loss: 0.82091 | accuracy: 94.206352 | precision: 95.560249 | recall: 89.682541 | f2: 90.799515
2023-05-23 14:09:43,420 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 50 | train -> loss: 70.22992 | validation -> loss: 0.79503 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:09:48,451 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 51 | train -> loss: 70.05811 | validation -> loss: 0.80735 | accuracy: 94.206352 | precision: 94.802490 | recall: 90.476189 | f2: 91.309570
2023-05-23 14:09:53,649 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 52 | train -> loss: 70.09092 | validation -> loss: 0.79568 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:09:59,078 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 53 | train -> loss: 69.96866 | validation -> loss: 0.78941 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:10:04,275 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 54 | train -> loss: 69.96917 | validation -> loss: 0.79312 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:10:09,485 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 55 | train -> loss: 69.81993 | validation -> loss: 0.79334 | accuracy: 94.761902 | precision: 94.153229 | recall: 92.658730 | f2: 92.953819
2023-05-23 14:10:14,853 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 56 | train -> loss: 70.15227 | validation -> loss: 0.78948 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:10:20,147 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 57 | train -> loss: 69.64115 | validation -> loss: 0.78943 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:10:26,170 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 58 | train -> loss: 69.65914 | validation -> loss: 0.78979 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:10:31,835 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 59 | train -> loss: 69.43785 | validation -> loss: 0.79039 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:10:37,090 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 60 | train -> loss: 69.42284 | validation -> loss: 0.79326 | accuracy: 94.761902 | precision: 94.693878 | recall: 92.063492 | f2: 92.577812
2023-05-23 14:10:42,221 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 61 | train -> loss: 69.89553 | validation -> loss: 0.78692 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:10:47,504 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 62 | train -> loss: 69.33491 | validation -> loss: 0.78476 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:10:53,459 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 63 | train -> loss: 69.17834 | validation -> loss: 0.78406 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:10:58,889 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 64 | train -> loss: 69.09598 | validation -> loss: 0.78247 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:11:04,052 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 65 | train -> loss: 68.90727 | validation -> loss: 0.78608 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:11:09,432 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 66 | train -> loss: 69.19739 | validation -> loss: 0.78581 | accuracy: 95.158730 | precision: 94.211578 | recall: 93.650795 | f2: 93.762413
2023-05-23 14:11:14,908 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 67 | train -> loss: 68.74688 | validation -> loss: 0.78391 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:11:21,522 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 68 | train -> loss: 68.83916 | validation -> loss: 0.78463 | accuracy: 94.920639 | precision: 94.176712 | recall: 93.055557 | f2: 93.277649
2023-05-23 14:11:26,934 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 69 | train -> loss: 68.63546 | validation -> loss: 0.78181 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:11:32,108 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 70 | train -> loss: 68.49845 | validation -> loss: 0.78662 | accuracy: 94.761902 | precision: 94.693878 | recall: 92.063492 | f2: 92.577812
2023-05-23 14:11:37,311 | root | INFO | ann.py learn @ 290 : fold: 1 | epoch: 71 | Learning rate changed from: 0.0003125 -> 7.8125e-05
2023-05-23 14:11:37,446 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 71 | train -> loss: 68.45893 | validation -> loss: 0.78082 | accuracy: 94.920639 | precision: 94.534416 | recall: 92.658730 | f2: 93.027893
2023-05-23 14:11:42,648 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 72 | train -> loss: 68.27544 | validation -> loss: 0.78111 | accuracy: 94.841270 | precision: 94.164993 | recall: 92.857140 | f2: 93.115799
2023-05-23 14:11:47,963 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 73 | train -> loss: 68.23236 | validation -> loss: 0.78363 | accuracy: 94.920639 | precision: 94.354836 | recall: 92.857140 | f2: 93.152870
2023-05-23 14:11:53,095 | root | INFO | ann.py learn @ 313 : fold: 1 | epoch: 74 | train -> loss: 68.30912 | validation -> loss: 0.78045 | accuracy: 94.920639 | precision: 94.354836 | recall: 92.857140 | f2: 93.152870
2023-05-23 14:11:53,101 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-13-58-00-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/weights/f1/model_fold1.pth
2023-05-23 14:11:53,606 | root | INFO | ann.py learn @ 254 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 14:11:53,609 | root | INFO | ann.py learn @ 259 : fetching data for fold #2
2023-05-23 14:11:53,611 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 14:11:53,615 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 14:11:58,781 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 0 | train -> loss: 272.29834 | validation -> loss: 2.85333 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:12:03,971 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 1 | train -> loss: 268.63375 | validation -> loss: 2.81787 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:12:09,182 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 2 | train -> loss: 264.38567 | validation -> loss: 2.74742 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:12:14,224 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 3 | train -> loss: 255.97597 | validation -> loss: 2.61653 | accuracy: 60.000004 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:12:19,271 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 4 | train -> loss: 241.42195 | validation -> loss: 2.41770 | accuracy: 66.984131 | precision: 95.833328 | recall: 18.253969 | f2: 21.780304
2023-05-23 14:12:24,398 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 5 | train -> loss: 222.58496 | validation -> loss: 2.19234 | accuracy: 73.253967 | precision: 89.952156 | recall: 37.301590 | f2: 42.247192
2023-05-23 14:12:29,482 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 6 | train -> loss: 203.23112 | validation -> loss: 2.03039 | accuracy: 84.444443 | precision: 86.320755 | recall: 72.619041 | f2: 75.000000
2023-05-23 14:12:34,596 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 7 | train -> loss: 185.96507 | validation -> loss: 1.84041 | accuracy: 73.253967 | precision: 92.820511 | recall: 35.912697 | f2: 40.931705
2023-05-23 14:12:39,661 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 8 | train -> loss: 171.64791 | validation -> loss: 1.69398 | accuracy: 88.095238 | precision: 86.721992 | recall: 82.936508 | f2: 83.666931
2023-05-23 14:12:45,125 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 9 | train -> loss: 160.61732 | validation -> loss: 1.55261 | accuracy: 87.539688 | precision: 89.342407 | recall: 78.174606 | f2: 80.179077
2023-05-23 14:12:50,206 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 10 | train -> loss: 150.95467 | validation -> loss: 1.45835 | accuracy: 87.063492 | precision: 89.743591 | recall: 76.388893 | f2: 78.732109
2023-05-23 14:12:55,467 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 11 | train -> loss: 143.59911 | validation -> loss: 1.39264 | accuracy: 89.920631 | precision: 88.080803 | recall: 86.507935 | f2: 86.818001
2023-05-23 14:13:00,839 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 12 | train -> loss: 136.13846 | validation -> loss: 1.32967 | accuracy: 88.015869 | precision: 91.923988 | recall: 76.785713 | f2: 79.400902
2023-05-23 14:13:06,149 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 13 | train -> loss: 131.46288 | validation -> loss: 1.27169 | accuracy: 90.476189 | precision: 89.344261 | recall: 86.507935 | f2: 87.060699
2023-05-23 14:13:11,588 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 14 | train -> loss: 127.10333 | validation -> loss: 1.32615 | accuracy: 89.920631 | precision: 82.668976 | recall: 94.642860 | f2: 91.978401
2023-05-23 14:13:16,972 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 15 | train -> loss: 122.04605 | validation -> loss: 1.18900 | accuracy: 91.587296 | precision: 89.484123 | recall: 89.484123 | f2: 89.484123
2023-05-23 14:13:22,311 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 16 | train -> loss: 118.33683 | validation -> loss: 1.14938 | accuracy: 91.111115 | precision: 91.525421 | recall: 85.714287 | f2: 86.816719
2023-05-23 14:13:28,357 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 17 | train -> loss: 115.21436 | validation -> loss: 1.14296 | accuracy: 92.698410 | precision: 88.867928 | recall: 93.452385 | f2: 92.498032
2023-05-23 14:13:33,886 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 18 | train -> loss: 112.46671 | validation -> loss: 1.08364 | accuracy: 92.063492 | precision: 91.393440 | recall: 88.492065 | f2: 89.057503
2023-05-23 14:13:39,067 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 19 | train -> loss: 108.97220 | validation -> loss: 1.05336 | accuracy: 92.380951 | precision: 91.975311 | recall: 88.690475 | f2: 89.328537
2023-05-23 14:13:44,190 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 20 | train -> loss: 104.84242 | validation -> loss: 1.04944 | accuracy: 93.412697 | precision: 90.248566 | recall: 93.650795 | f2: 92.949982
2023-05-23 14:13:49,516 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 21 | train -> loss: 102.86551 | validation -> loss: 1.00548 | accuracy: 92.619049 | precision: 92.371140 | recall: 88.888893 | f2: 89.564171
2023-05-23 14:13:54,663 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 22 | train -> loss: 99.72621 | validation -> loss: 0.97660 | accuracy: 93.333336 | precision: 91.832664 | recall: 91.468254 | f2: 91.540901
2023-05-23 14:14:00,130 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 23 | train -> loss: 97.89499 | validation -> loss: 0.95959 | accuracy: 93.571434 | precision: 91.228065 | recall: 92.857140 | f2: 92.526695
2023-05-23 14:14:05,339 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 24 | train -> loss: 94.42723 | validation -> loss: 0.97395 | accuracy: 91.984131 | precision: 94.285713 | recall: 85.119041 | f2: 86.806961
2023-05-23 14:14:10,622 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 25 | train -> loss: 93.00620 | validation -> loss: 0.96645 | accuracy: 93.730156 | precision: 89.868668 | recall: 95.039680 | f2: 93.958412
2023-05-23 14:14:15,698 | root | INFO | ann.py learn @ 290 : fold: 2 | epoch: 26 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 14:14:15,829 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 26 | train -> loss: 91.57432 | validation -> loss: 0.90049 | accuracy: 93.888893 | precision: 91.944992 | recall: 92.857140 | f2: 92.673264
2023-05-23 14:14:21,118 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 27 | train -> loss: 86.81759 | validation -> loss: 0.89637 | accuracy: 93.730156 | precision: 91.913216 | recall: 92.460320 | f2: 92.350372
2023-05-23 14:14:26,315 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 28 | train -> loss: 86.10984 | validation -> loss: 0.89339 | accuracy: 93.968254 | precision: 91.960785 | recall: 93.055557 | f2: 92.834518
2023-05-23 14:14:31,393 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 29 | train -> loss: 85.47405 | validation -> loss: 0.90996 | accuracy: 93.888893 | precision: 90.666672 | recall: 94.444443 | f2: 93.663910
2023-05-23 14:14:36,457 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 30 | train -> loss: 85.34592 | validation -> loss: 0.88388 | accuracy: 93.571434 | precision: 92.555328 | recall: 91.269836 | f2: 91.524078
2023-05-23 14:14:41,757 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 31 | train -> loss: 84.72887 | validation -> loss: 0.88665 | accuracy: 94.126984 | precision: 91.505791 | recall: 94.047615 | f2: 93.528023
2023-05-23 14:14:46,995 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 32 | train -> loss: 84.22386 | validation -> loss: 0.88880 | accuracy: 94.206352 | precision: 91.362762 | recall: 94.444443 | f2: 93.811592
2023-05-23 14:14:52,191 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 33 | train -> loss: 83.92431 | validation -> loss: 0.87147 | accuracy: 93.650795 | precision: 92.741936 | recall: 91.269836 | f2: 91.560509
2023-05-23 14:14:57,641 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 34 | train -> loss: 83.50576 | validation -> loss: 0.87039 | accuracy: 93.968254 | precision: 91.960785 | recall: 93.055557 | f2: 92.834518
2023-05-23 14:15:02,917 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 35 | train -> loss: 82.97006 | validation -> loss: 0.88571 | accuracy: 94.365082 | precision: 91.081596 | recall: 95.238098 | f2: 94.376717
2023-05-23 14:15:08,223 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 36 | train -> loss: 82.15996 | validation -> loss: 0.86313 | accuracy: 94.047615 | precision: 91.976517 | recall: 93.253967 | f2: 92.995651
2023-05-23 14:15:13,490 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 37 | train -> loss: 81.75663 | validation -> loss: 0.85644 | accuracy: 93.730156 | precision: 92.756538 | recall: 91.468254 | f2: 91.723045
2023-05-23 14:15:18,658 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 38 | train -> loss: 81.46602 | validation -> loss: 0.85657 | accuracy: 94.365082 | precision: 92.038834 | recall: 94.047615 | f2: 93.638878
2023-05-23 14:15:23,949 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 39 | train -> loss: 80.76312 | validation -> loss: 0.92541 | accuracy: 93.968254 | precision: 89.338234 | recall: 96.428574 | f2: 94.921875
2023-05-23 14:15:29,308 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 40 | train -> loss: 80.22004 | validation -> loss: 0.84935 | accuracy: 94.126984 | precision: 92.322830 | recall: 93.055557 | f2: 92.908081
2023-05-23 14:15:34,706 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 41 | train -> loss: 79.76692 | validation -> loss: 0.85155 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:15:40,066 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 42 | train -> loss: 79.57628 | validation -> loss: 0.84012 | accuracy: 94.285713 | precision: 92.352936 | recall: 93.452385 | f2: 93.230400
2023-05-23 14:15:45,263 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 43 | train -> loss: 79.25596 | validation -> loss: 0.84248 | accuracy: 93.650795 | precision: 93.621399 | recall: 90.277779 | f2: 90.927261
2023-05-23 14:15:50,523 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 44 | train -> loss: 78.44317 | validation -> loss: 0.84241 | accuracy: 94.603172 | precision: 91.923073 | recall: 94.841270 | f2: 94.242897
2023-05-23 14:15:55,615 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 45 | train -> loss: 77.59451 | validation -> loss: 0.83808 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:16:00,769 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 46 | train -> loss: 77.90486 | validation -> loss: 0.83343 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:16:06,196 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 47 | train -> loss: 77.04050 | validation -> loss: 0.83206 | accuracy: 94.682541 | precision: 92.100189 | recall: 94.841270 | f2: 94.280075
2023-05-23 14:16:11,483 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 48 | train -> loss: 76.66809 | validation -> loss: 0.82249 | accuracy: 94.444443 | precision: 93.227097 | recall: 92.857140 | f2: 92.930893
2023-05-23 14:16:16,411 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 49 | train -> loss: 76.52677 | validation -> loss: 0.81738 | accuracy: 94.444443 | precision: 93.574295 | recall: 92.460320 | f2: 92.680984
2023-05-23 14:16:21,690 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 50 | train -> loss: 76.08833 | validation -> loss: 0.81673 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:16:26,788 | root | INFO | ann.py learn @ 290 : fold: 2 | epoch: 51 | Learning rate changed from: 0.00125 -> 0.0003125
2023-05-23 14:16:26,921 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 51 | train -> loss: 75.90678 | validation -> loss: 0.81597 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:16:32,341 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 52 | train -> loss: 74.94107 | validation -> loss: 0.82020 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:16:37,587 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 53 | train -> loss: 74.84650 | validation -> loss: 0.82763 | accuracy: 94.285713 | precision: 91.221375 | recall: 94.841270 | f2: 94.094490
2023-05-23 14:16:43,065 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 54 | train -> loss: 74.67612 | validation -> loss: 0.81735 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:16:48,433 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 55 | train -> loss: 75.46837 | validation -> loss: 0.82359 | accuracy: 94.365082 | precision: 91.395798 | recall: 94.841270 | f2: 94.131546
2023-05-23 14:16:53,553 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 56 | train -> loss: 74.52328 | validation -> loss: 0.81141 | accuracy: 94.444443 | precision: 93.055557 | recall: 93.055557 | f2: 93.055557
2023-05-23 14:16:58,647 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 57 | train -> loss: 74.30425 | validation -> loss: 0.81657 | accuracy: 94.682541 | precision: 92.100189 | recall: 94.841270 | f2: 94.280075
2023-05-23 14:17:03,742 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 58 | train -> loss: 74.19806 | validation -> loss: 0.81307 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:17:08,912 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 59 | train -> loss: 74.15293 | validation -> loss: 0.81687 | accuracy: 94.682541 | precision: 92.100189 | recall: 94.841270 | f2: 94.280075
2023-05-23 14:17:13,972 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 60 | train -> loss: 74.09740 | validation -> loss: 0.80922 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:17:19,080 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 61 | train -> loss: 73.91502 | validation -> loss: 0.81098 | accuracy: 94.682541 | precision: 92.100189 | recall: 94.841270 | f2: 94.280075
2023-05-23 14:17:24,035 | root | INFO | ann.py learn @ 290 : fold: 2 | epoch: 62 | Learning rate changed from: 0.0003125 -> 7.8125e-05
2023-05-23 14:17:24,176 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 62 | train -> loss: 73.81013 | validation -> loss: 0.80432 | accuracy: 94.285713 | precision: 93.027893 | recall: 92.658730 | f2: 92.732330
2023-05-23 14:17:29,238 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 63 | train -> loss: 73.74372 | validation -> loss: 0.80985 | accuracy: 94.761902 | precision: 92.441864 | recall: 94.642860 | f2: 94.194313
2023-05-23 14:17:34,362 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 64 | train -> loss: 74.17513 | validation -> loss: 0.80769 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:17:39,320 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 65 | train -> loss: 73.65433 | validation -> loss: 0.80774 | accuracy: 94.682541 | precision: 92.427185 | recall: 94.444443 | f2: 94.033981
2023-05-23 14:17:44,431 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 66 | train -> loss: 73.58134 | validation -> loss: 0.80479 | accuracy: 94.682541 | precision: 92.427185 | recall: 94.444443 | f2: 94.033981
2023-05-23 14:17:49,571 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 67 | train -> loss: 73.97628 | validation -> loss: 0.80635 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:17:56,029 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 68 | train -> loss: 73.46411 | validation -> loss: 0.80807 | accuracy: 94.603172 | precision: 92.412453 | recall: 94.246033 | f2: 93.873520
2023-05-23 14:18:01,196 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 69 | train -> loss: 73.53949 | validation -> loss: 0.80644 | accuracy: 94.603172 | precision: 92.084946 | recall: 94.642860 | f2: 94.119965
2023-05-23 14:18:06,163 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 70 | train -> loss: 73.50958 | validation -> loss: 0.80490 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:18:10,845 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 71 | train -> loss: 73.42566 | validation -> loss: 0.80847 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:18:15,650 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 72 | train -> loss: 73.46588 | validation -> loss: 0.81140 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:18:20,359 | root | INFO | ann.py learn @ 290 : fold: 2 | epoch: 73 | Learning rate changed from: 7.8125e-05 -> 1.953125e-05
2023-05-23 14:18:20,481 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 73 | train -> loss: 73.33139 | validation -> loss: 0.80505 | accuracy: 94.682541 | precision: 92.427185 | recall: 94.444443 | f2: 94.033981
2023-05-23 14:18:25,531 | root | INFO | ann.py learn @ 313 : fold: 2 | epoch: 74 | train -> loss: 73.52234 | validation -> loss: 0.80857 | accuracy: 94.682541 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 14:18:25,541 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-13-58-00-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/weights/f2/model_fold2.pth
2023-05-23 14:18:26,011 | root | INFO | ann.py learn @ 254 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 14:18:26,011 | root | INFO | ann.py learn @ 259 : fetching data for fold #3
2023-05-23 14:18:26,011 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 14:18:26,011 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 14:18:31,189 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 0 | train -> loss: 272.64773 | validation -> loss: 2.84953 | accuracy: 59.968227 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:18:36,423 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 1 | train -> loss: 268.21032 | validation -> loss: 2.81919 | accuracy: 59.968227 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:18:41,427 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 2 | train -> loss: 263.58749 | validation -> loss: 2.74931 | accuracy: 59.968227 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:18:46,526 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 3 | train -> loss: 254.14354 | validation -> loss: 2.62839 | accuracy: 59.968227 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-23 14:18:51,532 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 4 | train -> loss: 238.62284 | validation -> loss: 2.44710 | accuracy: 67.434471 | precision: 97.000000 | recall: 19.246031 | f2: 22.920605
2023-05-23 14:18:56,744 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 5 | train -> loss: 219.25847 | validation -> loss: 2.24345 | accuracy: 71.882446 | precision: 89.473686 | recall: 33.730160 | f2: 38.531281
2023-05-23 14:19:01,883 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 6 | train -> loss: 199.16956 | validation -> loss: 2.05412 | accuracy: 73.947578 | precision: 86.974785 | recall: 41.071430 | f2: 45.918365
2023-05-23 14:19:07,345 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 7 | train -> loss: 181.70779 | validation -> loss: 1.89862 | accuracy: 78.236694 | precision: 87.096771 | recall: 53.571426 | f2: 58.039551
2023-05-23 14:19:12,602 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 8 | train -> loss: 167.69179 | validation -> loss: 1.77923 | accuracy: 79.904686 | precision: 88.854492 | recall: 56.944443 | f2: 61.351006
2023-05-23 14:19:18,565 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 9 | train -> loss: 155.91555 | validation -> loss: 1.68630 | accuracy: 82.287529 | precision: 89.355743 | recall: 63.293655 | f2: 67.214493
2023-05-23 14:19:24,294 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 10 | train -> loss: 145.96766 | validation -> loss: 1.62244 | accuracy: 83.002380 | precision: 91.666672 | recall: 63.293655 | f2: 67.470390
2023-05-23 14:19:29,615 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 11 | train -> loss: 138.46031 | validation -> loss: 1.53727 | accuracy: 86.497215 | precision: 89.018692 | recall: 75.595238 | f2: 77.945992
2023-05-23 14:19:35,399 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 12 | train -> loss: 133.44639 | validation -> loss: 1.49533 | accuracy: 86.814934 | precision: 91.219513 | recall: 74.206345 | f2: 77.081612
2023-05-23 14:19:40,947 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 13 | train -> loss: 128.30825 | validation -> loss: 1.44973 | accuracy: 87.768074 | precision: 91.273582 | recall: 76.785713 | f2: 79.303276
2023-05-23 14:19:45,446 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 14 | train -> loss: 122.82228 | validation -> loss: 1.38837 | accuracy: 88.641777 | precision: 88.160675 | recall: 82.738098 | f2: 83.768585
2023-05-23 14:19:49,660 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 15 | train -> loss: 118.54872 | validation -> loss: 1.36642 | accuracy: 88.959488 | precision: 91.383217 | recall: 79.960320 | f2: 82.010582
2023-05-23 14:19:53,826 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 16 | train -> loss: 114.86373 | validation -> loss: 1.37790 | accuracy: 87.688644 | precision: 93.086418 | recall: 74.801590 | f2: 77.860390
2023-05-23 14:19:57,922 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 17 | train -> loss: 112.11778 | validation -> loss: 1.28813 | accuracy: 90.230339 | precision: 88.798370 | recall: 86.507935 | f2: 86.956520
2023-05-23 14:20:02,098 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 18 | train -> loss: 107.92215 | validation -> loss: 1.29440 | accuracy: 88.800636 | precision: 93.317429 | recall: 77.579369 | f2: 80.287476
2023-05-23 14:20:06,168 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 19 | train -> loss: 105.34377 | validation -> loss: 1.30591 | accuracy: 88.403496 | precision: 94.306931 | recall: 75.595238 | f2: 78.719009
2023-05-23 14:20:10,224 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 20 | train -> loss: 102.13691 | validation -> loss: 1.26913 | accuracy: 90.150909 | precision: 84.172661 | recall: 92.857140 | f2: 90.979782
2023-05-23 14:20:14,223 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 21 | train -> loss: 98.95694 | validation -> loss: 1.16686 | accuracy: 91.421768 | precision: 91.422592 | recall: 86.706345 | f2: 87.610260
2023-05-23 14:20:18,291 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 22 | train -> loss: 97.41806 | validation -> loss: 1.14655 | accuracy: 91.024628 | precision: 90.143738 | recall: 87.103180 | f2: 87.694763
2023-05-23 14:20:22,481 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 23 | train -> loss: 94.84357 | validation -> loss: 1.19797 | accuracy: 89.515488 | precision: 94.497612 | recall: 78.373016 | f2: 81.142151
2023-05-23 14:20:26,699 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 24 | train -> loss: 92.81722 | validation -> loss: 1.17567 | accuracy: 90.786339 | precision: 85.144928 | recall: 93.253967 | f2: 91.510902
2023-05-23 14:20:30,886 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 25 | train -> loss: 90.14037 | validation -> loss: 1.08702 | accuracy: 92.374901 | precision: 93.776825 | recall: 86.706345 | f2: 88.033844
2023-05-23 14:20:35,175 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 26 | train -> loss: 88.00008 | validation -> loss: 1.06660 | accuracy: 92.216042 | precision: 92.647057 | recall: 87.500000 | f2: 88.483147
2023-05-23 14:20:39,907 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 27 | train -> loss: 86.29287 | validation -> loss: 1.04268 | accuracy: 92.136612 | precision: 90.744469 | recall: 89.484123 | f2: 89.733383
2023-05-23 14:20:44,294 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 28 | train -> loss: 83.93503 | validation -> loss: 1.02906 | accuracy: 92.295471 | precision: 90.297028 | recall: 90.476189 | f2: 90.440300
2023-05-23 14:20:48,794 | root | INFO | ann.py learn @ 290 : fold: 3 | epoch: 29 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 14:20:48,896 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 29 | train -> loss: 82.28875 | validation -> loss: 1.00105 | accuracy: 92.454323 | precision: 91.820045 | recall: 89.087303 | f2: 89.620758
2023-05-23 14:20:53,563 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 30 | train -> loss: 79.25502 | validation -> loss: 1.00640 | accuracy: 92.374901 | precision: 90.157478 | recall: 90.873016 | f2: 90.729004
2023-05-23 14:20:58,072 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 31 | train -> loss: 79.29718 | validation -> loss: 0.99760 | accuracy: 92.454323 | precision: 91.649696 | recall: 89.285713 | f2: 89.748703
2023-05-23 14:21:02,681 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 32 | train -> loss: 78.44966 | validation -> loss: 0.99417 | accuracy: 92.216042 | precision: 90.438248 | recall: 90.079369 | f2: 90.150909
2023-05-23 14:21:07,386 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 33 | train -> loss: 77.95266 | validation -> loss: 0.99121 | accuracy: 92.454323 | precision: 92.164948 | recall: 88.690475 | f2: 89.364258
2023-05-23 14:21:11,596 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 34 | train -> loss: 77.28995 | validation -> loss: 1.00694 | accuracy: 92.851471 | precision: 94.042549 | recall: 87.698410 | f2: 88.897827
2023-05-23 14:21:15,804 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 35 | train -> loss: 77.58047 | validation -> loss: 0.98389 | accuracy: 92.533752 | precision: 91.497978 | recall: 89.682541 | f2: 90.039841
2023-05-23 14:21:20,064 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 36 | train -> loss: 76.87734 | validation -> loss: 0.98795 | accuracy: 92.692612 | precision: 90.234375 | recall: 91.666672 | f2: 91.376587
2023-05-23 14:21:24,352 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 37 | train -> loss: 76.56609 | validation -> loss: 0.98260 | accuracy: 92.613182 | precision: 90.058479 | recall: 91.666672 | f2: 91.340454
2023-05-23 14:21:28,613 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 38 | train -> loss: 75.70026 | validation -> loss: 0.98406 | accuracy: 92.772041 | precision: 93.657509 | recall: 87.896820 | f2: 88.991562
2023-05-23 14:21:33,176 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 39 | train -> loss: 75.90444 | validation -> loss: 0.98477 | accuracy: 92.930893 | precision: 94.243065 | recall: 87.698410 | f2: 88.933601
2023-05-23 14:21:37,827 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 40 | train -> loss: 75.25762 | validation -> loss: 0.96855 | accuracy: 92.851471 | precision: 90.748032 | recall: 91.468254 | f2: 91.323296
2023-05-23 14:21:42,754 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 41 | train -> loss: 74.99098 | validation -> loss: 0.96948 | accuracy: 92.613182 | precision: 92.197128 | recall: 89.087303 | f2: 89.692375
2023-05-23 14:21:47,097 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 42 | train -> loss: 74.71078 | validation -> loss: 0.97540 | accuracy: 92.772041 | precision: 89.635315 | recall: 92.658730 | f2: 92.037842
2023-05-23 14:21:51,261 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 43 | train -> loss: 74.20360 | validation -> loss: 0.99904 | accuracy: 93.010323 | precision: 88.951317 | recall: 94.246033 | f2: 93.137253
2023-05-23 14:21:55,427 | root | INFO | ann.py learn @ 290 : fold: 3 | epoch: 44 | Learning rate changed from: 0.00125 -> 0.0003125
2023-05-23 14:21:55,543 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 44 | train -> loss: 73.93130 | validation -> loss: 0.95356 | accuracy: 92.851471 | precision: 90.748032 | recall: 91.468254 | f2: 91.323296
2023-05-23 14:21:59,644 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 45 | train -> loss: 72.93372 | validation -> loss: 0.95876 | accuracy: 92.930893 | precision: 90.766212 | recall: 91.666672 | f2: 91.485146
2023-05-23 14:22:03,917 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 46 | train -> loss: 72.72019 | validation -> loss: 0.95104 | accuracy: 92.772041 | precision: 91.382767 | recall: 90.476189 | f2: 90.656067
2023-05-23 14:22:08,177 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 47 | train -> loss: 72.80828 | validation -> loss: 0.95458 | accuracy: 92.851471 | precision: 90.748032 | recall: 91.468254 | f2: 91.323296
2023-05-23 14:22:12,518 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 48 | train -> loss: 72.64864 | validation -> loss: 0.95855 | accuracy: 92.851471 | precision: 92.418030 | recall: 89.484123 | f2: 90.055916
2023-05-23 14:22:17,471 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 49 | train -> loss: 72.48100 | validation -> loss: 0.95810 | accuracy: 92.851471 | precision: 90.116280 | recall: 92.261902 | f2: 91.824646
2023-05-23 14:22:22,769 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 50 | train -> loss: 72.54528 | validation -> loss: 0.94959 | accuracy: 93.010323 | precision: 91.106720 | recall: 91.468254 | f2: 91.395721
2023-05-23 14:22:28,184 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 51 | train -> loss: 72.43104 | validation -> loss: 0.95749 | accuracy: 92.851471 | precision: 90.116280 | recall: 92.261902 | f2: 91.824646
2023-05-23 14:22:33,441 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 52 | train -> loss: 72.26063 | validation -> loss: 0.94758 | accuracy: 92.930893 | precision: 92.089249 | recall: 90.079369 | f2: 90.474289
2023-05-23 14:22:38,496 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 53 | train -> loss: 72.73091 | validation -> loss: 0.95075 | accuracy: 93.089752 | precision: 90.962669 | recall: 91.865082 | f2: 91.683167
2023-05-23 14:22:45,395 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 54 | train -> loss: 71.99772 | validation -> loss: 0.95697 | accuracy: 93.089752 | precision: 91.287132 | recall: 91.468254 | f2: 91.431969
2023-05-23 14:22:51,198 | root | INFO | ann.py learn @ 290 : fold: 3 | epoch: 55 | Learning rate changed from: 0.0003125 -> 7.8125e-05
2023-05-23 14:22:51,333 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 55 | train -> loss: 72.09868 | validation -> loss: 0.94868 | accuracy: 92.851471 | precision: 91.399994 | recall: 90.674606 | f2: 90.818764
2023-05-23 14:22:56,788 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 56 | train -> loss: 71.84632 | validation -> loss: 0.94231 | accuracy: 92.930893 | precision: 91.750504 | recall: 90.476189 | f2: 90.728210
2023-05-23 14:23:02,027 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 57 | train -> loss: 71.85566 | validation -> loss: 0.94875 | accuracy: 92.851471 | precision: 91.399994 | recall: 90.674606 | f2: 90.818764
2023-05-23 14:23:07,622 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 58 | train -> loss: 71.75617 | validation -> loss: 0.94644 | accuracy: 92.851471 | precision: 91.566261 | recall: 90.476189 | f2: 90.692123
2023-05-23 14:23:12,480 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 59 | train -> loss: 71.79046 | validation -> loss: 0.94565 | accuracy: 92.851471 | precision: 91.399994 | recall: 90.674606 | f2: 90.818764
2023-05-23 14:23:20,125 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 60 | train -> loss: 71.87645 | validation -> loss: 0.94595 | accuracy: 93.089752 | precision: 91.451294 | recall: 91.269836 | f2: 91.306076
2023-05-23 14:23:25,718 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 61 | train -> loss: 71.70915 | validation -> loss: 0.94209 | accuracy: 93.089752 | precision: 91.451294 | recall: 91.269836 | f2: 91.306076
2023-05-23 14:23:31,159 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 62 | train -> loss: 71.90583 | validation -> loss: 0.94484 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:23:36,867 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 63 | train -> loss: 71.71004 | validation -> loss: 0.94291 | accuracy: 92.851471 | precision: 91.399994 | recall: 90.674606 | f2: 90.818764
2023-05-23 14:23:42,118 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 64 | train -> loss: 71.62636 | validation -> loss: 0.94259 | accuracy: 93.169182 | precision: 91.468254 | recall: 91.468254 | f2: 91.468254
2023-05-23 14:23:47,180 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 65 | train -> loss: 71.65936 | validation -> loss: 0.94754 | accuracy: 92.930893 | precision: 91.583168 | recall: 90.674606 | f2: 90.854874
2023-05-23 14:23:54,333 | root | INFO | ann.py learn @ 290 : fold: 3 | epoch: 66 | Learning rate changed from: 7.8125e-05 -> 1.953125e-05
2023-05-23 14:23:54,465 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 66 | train -> loss: 71.59508 | validation -> loss: 0.94851 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:23:59,884 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 67 | train -> loss: 71.53119 | validation -> loss: 0.94541 | accuracy: 92.851471 | precision: 91.399994 | recall: 90.674606 | f2: 90.818764
2023-05-23 14:24:05,218 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 68 | train -> loss: 71.56705 | validation -> loss: 0.94036 | accuracy: 92.851471 | precision: 91.399994 | recall: 90.674606 | f2: 90.818764
2023-05-23 14:24:10,486 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 69 | train -> loss: 71.51749 | validation -> loss: 0.95026 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:24:15,549 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 70 | train -> loss: 71.53900 | validation -> loss: 0.94428 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:24:20,896 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 71 | train -> loss: 71.58861 | validation -> loss: 0.94197 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:24:27,509 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 72 | train -> loss: 71.58243 | validation -> loss: 0.94514 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:24:32,978 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 73 | train -> loss: 71.51562 | validation -> loss: 0.94195 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:24:38,279 | root | INFO | ann.py learn @ 313 : fold: 3 | epoch: 74 | train -> loss: 71.49640 | validation -> loss: 0.94432 | accuracy: 92.930893 | precision: 91.417160 | recall: 90.873016 | f2: 90.981331
2023-05-23 14:24:38,289 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-13-58-00-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/weights/f3/model_fold3.pth
2023-05-23 14:24:38,730 | root | INFO | ann.py learn @ 332 : best model of cross validation for current training phase: fold #2 with metric value of '0.9464285969734192'
2023-05-23 14:24:38,750 | root | INFO | main.py run @ 84 : started new command `test` of session `balanced-v2-04`
2023-05-23 14:24:38,760 | root | INFO | dataset.py preprocess @ 192 : generating tokens from scratch
2023-05-23 14:25:09,956 | root | INFO | dataset.py preprocess @ 195 : applying preprocessing modules
2023-05-23 14:25:09,956 | root | INFO | dataset.py preprocess @ 197 : applying repetition remover
2023-05-23 14:25:13,055 | root | INFO | dataset.py preprocess @ 197 : applying author id replacer
2023-05-23 14:25:13,645 | root | INFO | dataset.py __vectorize__ @ 106 : trying to create vectors from scratch
2023-05-23 14:25:28,864 | root | INFO | dataset.py prepare @ 220 : saving tokens as pickle at data/preprocessed/conversation-balanced-v2-04/test-conversation-bow-with-triple/rr.idr/tokens.pkl
2023-05-23 14:25:29,415 | root | INFO | dataset.py prepare @ 225 : saving vectors as pickle at data/preprocessed/conversation-balanced-v2-04/test-conversation-bow-with-triple/rr.idr/vectors.pkl
2023-05-23 14:25:34,667 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-23 14:25:34,736 | root | INFO | ann.py __init__ @ 213 : dimension list of nodes: [32, 1]
2023-05-23 14:25:34,741 | root | INFO | ann.py __init__ @ 214 : dropout list: [0.0]

######################## merged from another log file. because there was a runtime error in the previous session.

2023-05-23 15:28:18,743 | root | INFO | main.py run @ 84 : started new command `test` of session `balanced-v2-04`
2023-05-23 15:28:18,743 | root | INFO | dataset.py preprocess @ 189 : trying to load tokens from file
2023-05-23 15:28:23,326 | root | INFO | dataset.py __vectorize__ @ 103 : loading vectors from file
2023-05-23 15:28:27,809 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-23 15:28:27,849 | root | INFO | dataset.py preprocess @ 189 : trying to load tokens from file
2023-05-23 15:28:28,099 | root | INFO | dataset.py __vectorize__ @ 103 : loading vectors from file
2023-05-23 15:28:34,539 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-23 15:28:34,605 | root | INFO | ann.py __init__ @ 213 : dimension list of nodes: [32, 1]
2023-05-23 15:28:34,608 | root | INFO | ann.py __init__ @ 214 : dropout list: [0.0]
2023-05-23 15:28:35,448 | root | INFO | ann.py test @ 357 : predictions are saved at output/05-23-2023-15-28-18-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/preds.pkl.
2023-05-23 15:28:35,450 | root | INFO | ann.py test @ 360 : targets are saved at output/05-23-2023-15-28-18-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/targets.pkl.
2023-05-23 15:28:35,451 | root | WARNING | main.py run @ 83 : no dataset was specified.
2023-05-23 15:28:35,452 | root | INFO | main.py run @ 84 : started new command `eval` of session `balanced-v2-04`
2023-05-23 15:28:35,453 | root | INFO | ann.py __init__ @ 213 : dimension list of nodes: [32, 1]
2023-05-23 15:28:35,454 | root | INFO | ann.py __init__ @ 214 : dropout list: [0.0]
2023-05-23 15:28:36,561 | root | INFO | baseline.py evaluate @ 67 : saving ROC curve at: output/05-23-2023-15-28-18-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/ROC-curve.png
2023-05-23 15:28:37,244 | root | INFO | baseline.py evaluate @ 74 : saving precision-recall curve at: output/05-23-2023-15-28-18-balanced-v2-04/ann-with-superloss/conversation-bow-with-triple/rr.idr-0.005-32.1-0.0/precision-recall-curve.png
2023-05-23 15:28:37,256 | root | INFO | baseline.py evaluate @ 77 : test set -> AUCROC: 0.9664882 | AUCPR: 0.9345212 | accuracy: 0.9229287 | precision: 0.8766390 | recall: 0.9267327

