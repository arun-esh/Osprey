2023-05-23 15:44:08,825 | root | INFO | main.py run @ 50 : processing unit: cpu
2023-05-23 15:44:08,825 | root | INFO | main.py run @ 68 : train dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/train.csv', 'output_path': 'data/preprocessed/dataset-v2/', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-05-23 15:44:08,835 | root | INFO | main.py run @ 69 : test dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/test.csv', 'output_path': 'data/preprocessed/dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-05-23 15:44:08,835 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,835 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,925 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-05-23 15:44:08,925 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-test-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-05-23 15:44:08,925 | root | INFO | main.py run @ 68 : train dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,925 | root | INFO | main.py run @ 69 : test dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,925 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,925 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,935 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 68 : train dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 69 : test dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 68 : train dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 69 : test dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 68 : train dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 69 : test dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 68 : train dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-train-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 69 : test dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-test-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-23 15:44:08,945 | root | INFO | main.py run @ 73 : started new session: balanced-v2-04
2023-05-23 15:44:08,945 | root | INFO | main.py create_model_configs @ 37 : activation module kwargs: {}
2023-05-23 15:44:08,955 | root | INFO | main.py create_model_configs @ 38 : loss module kwargs: {'reduction': 'sum', 'pos_weight': tensor(0.7500)}
2023-05-23 15:44:08,955 | root | INFO | main.py run @ 84 : started new command `train` of session `balanced-v2-04`
2023-05-23 15:44:08,955 | root | INFO | dataset.py preprocess @ 189 : trying to load tokens from file
2023-05-23 15:44:12,640 | root | INFO | dataset.py __vectorize__ @ 103 : loading vectors from file
2023-05-23 15:44:16,162 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-23 15:44:16,202 | root | INFO | dataset.py split_dataset_by_label @ 158 : loading splits from: data/preprocessed/conversation-balanced-v2-04/conversation-bow/rr.idr/splits-n4stratified.pkl
2023-05-23 15:44:16,202 | root | INFO | ann.py __init__ @ 213 : dimension list of nodes: [32, 1]
2023-05-23 15:44:16,212 | root | INFO | ann.py __init__ @ 214 : dropout list: [0.0]
2023-05-23 15:44:16,212 | root | INFO | ann.py learn @ 61 : training phase started
2023-05-23 15:44:16,212 | root | INFO | ann.py learn @ 64 : number of folds: 4
2023-05-23 15:44:16,212 | root | INFO | ann.py learn @ 67 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 15:44:16,212 | root | INFO | ann.py learn @ 72 : fetching data for fold #0
2023-05-23 15:44:16,212 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 15:44:16,212 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 15:44:20,808 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 0 | train -> loss: 2083.48329 | validation -> loss: 587.88904 | accuracy: 72.063492 | precision: 89.583328 | recall: 34.126984 | f2: 38.949276
2023-05-23 15:44:24,997 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 1 | train -> loss: 1429.30491 | validation -> loss: 522.58685 | accuracy: 71.111115 | precision: 95.454544 | recall: 29.166666 | f2: 33.870968
2023-05-23 15:44:29,213 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 2 | train -> loss: 1058.53702 | validation -> loss: 323.70441 | accuracy: 91.666672 | precision: 89.504951 | recall: 89.682541 | f2: 89.646965
2023-05-23 15:44:35,790 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 3 | train -> loss: 946.81046 | validation -> loss: 291.88782 | accuracy: 92.063492 | precision: 88.996140 | recall: 91.468254 | f2: 90.962906
2023-05-23 15:44:40,720 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 4 | train -> loss: 853.12003 | validation -> loss: 274.12378 | accuracy: 93.095238 | precision: 89.118202 | recall: 94.246033 | f2: 93.173798
2023-05-23 15:44:45,390 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 5 | train -> loss: 752.16017 | validation -> loss: 253.05966 | accuracy: 92.777779 | precision: 93.110641 | recall: 88.492065 | f2: 89.378754
2023-05-23 15:44:50,064 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 6 | train -> loss: 739.55150 | validation -> loss: 239.65567 | accuracy: 92.857140 | precision: 93.487396 | recall: 88.293655 | f2: 89.285713
2023-05-23 15:44:54,687 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 7 | train -> loss: 684.34383 | validation -> loss: 371.22537 | accuracy: 87.619049 | precision: 77.187500 | recall: 98.015877 | f2: 92.996994
2023-05-23 15:44:59,239 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 8 | train -> loss: 643.78224 | validation -> loss: 258.36435 | accuracy: 92.222221 | precision: 85.865723 | recall: 96.428574 | f2: 94.113091
2023-05-23 15:45:03,867 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 9 | train -> loss: 671.66847 | validation -> loss: 259.27454 | accuracy: 91.984131 | precision: 85.288963 | recall: 96.626984 | f2: 94.124466
2023-05-23 15:45:08,611 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 10 | train -> loss: 610.26902 | validation -> loss: 225.45790 | accuracy: 92.936508 | precision: 95.604393 | recall: 86.309525 | f2: 88.021049
2023-05-23 15:45:13,648 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 11 | train -> loss: 575.31097 | validation -> loss: 210.32571 | accuracy: 93.730156 | precision: 95.503212 | recall: 88.492065 | f2: 89.810715
2023-05-23 15:45:18,648 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 12 | train -> loss: 631.65816 | validation -> loss: 216.67346 | accuracy: 92.619049 | precision: 95.768372 | recall: 85.317459 | f2: 87.221100
2023-05-23 15:45:24,474 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 13 | train -> loss: 537.59886 | validation -> loss: 208.08914 | accuracy: 94.126984 | precision: 95.744682 | recall: 89.285713 | f2: 90.506836
2023-05-23 15:45:31,464 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 14 | train -> loss: 573.50691 | validation -> loss: 191.59367 | accuracy: 95.238098 | precision: 94.758064 | recall: 93.253967 | f2: 93.550957
2023-05-23 15:45:36,533 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 15 | train -> loss: 529.29103 | validation -> loss: 186.78625 | accuracy: 95.317459 | precision: 94.949493 | recall: 93.253967 | f2: 93.588211
2023-05-23 15:45:41,483 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 16 | train -> loss: 490.99248 | validation -> loss: 237.42389 | accuracy: 91.428574 | precision: 96.478874 | recall: 81.547615 | f2: 84.152336
2023-05-23 15:45:46,942 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 17 | train -> loss: 496.61550 | validation -> loss: 181.73694 | accuracy: 94.285713 | precision: 95.378151 | recall: 90.079369 | f2: 91.091499
2023-05-23 15:45:51,951 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 18 | train -> loss: 477.08931 | validation -> loss: 228.35532 | accuracy: 92.063492 | precision: 85.438599 | recall: 96.626984 | f2: 94.160866
2023-05-23 15:45:56,807 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 19 | train -> loss: 450.62117 | validation -> loss: 178.86240 | accuracy: 95.238098 | precision: 95.306122 | recall: 92.658730 | f2: 93.176376
2023-05-23 15:46:01,574 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 20 | train -> loss: 435.67770 | validation -> loss: 215.25772 | accuracy: 93.095238 | precision: 96.230598 | recall: 86.111107 | f2: 87.961082
2023-05-23 15:46:06,197 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 21 | train -> loss: 450.78473 | validation -> loss: 331.18527 | accuracy: 86.349205 | precision: 96.629211 | recall: 68.253967 | f2: 72.512650
2023-05-23 15:46:11,027 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 22 | train -> loss: 445.53819 | validation -> loss: 247.07437 | accuracy: 91.825394 | precision: 84.748695 | recall: 97.023811 | f2: 94.292328
2023-05-23 15:46:15,215 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 23 | train -> loss: 458.19979 | validation -> loss: 198.13461 | accuracy: 93.333336 | precision: 95.851532 | recall: 87.103180 | f2: 88.722717
2023-05-23 15:46:20,419 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 24 | train -> loss: 415.40275 | validation -> loss: 175.27161 | accuracy: 94.206352 | precision: 95.368423 | recall: 89.880959 | f2: 90.927338
2023-05-23 15:46:26,773 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 25 | train -> loss: 412.36218 | validation -> loss: 206.54282 | accuracy: 92.936508 | precision: 88.073395 | recall: 95.238098 | f2: 93.713394
2023-05-23 15:46:31,155 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 26 | train -> loss: 427.69785 | validation -> loss: 635.51324 | accuracy: 65.238098 | precision: 94.594589 | recall: 13.888889 | f2: 16.746412
2023-05-23 15:46:35,970 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 27 | train -> loss: 373.63152 | validation -> loss: 211.88889 | accuracy: 92.936508 | precision: 96.420578 | recall: 85.515877 | f2: 87.494926
2023-05-23 15:46:41,052 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 28 | train -> loss: 368.31406 | validation -> loss: 258.71246 | accuracy: 91.825394 | precision: 84.391083 | recall: 97.619041 | f2: 94.651787
2023-05-23 15:46:45,589 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 29 | train -> loss: 382.32204 | validation -> loss: 314.18561 | accuracy: 87.619049 | precision: 96.276596 | recall: 71.825394 | f2: 75.668892
2023-05-23 15:46:50,302 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 30 | train -> loss: 397.07562 | validation -> loss: 180.20393 | accuracy: 93.968254 | precision: 95.922745 | recall: 88.690475 | f2: 90.048347
2023-05-23 15:46:55,025 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 31 | train -> loss: 353.83941 | validation -> loss: 169.68863 | accuracy: 95.079361 | precision: 93.503937 | recall: 94.246033 | f2: 94.096672
2023-05-23 15:46:59,434 | root | INFO | ann.py learn @ 101 : fold: 0 | epoch: 32 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 15:46:59,555 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 32 | train -> loss: 480.29861 | validation -> loss: 194.50101 | accuracy: 94.206352 | precision: 95.948830 | recall: 89.285713 | f2: 90.543259
2023-05-23 15:47:04,279 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 33 | train -> loss: 327.97467 | validation -> loss: 170.29152 | accuracy: 95.555557 | precision: 94.094490 | recall: 94.841270 | f2: 94.690964
2023-05-23 15:47:08,880 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 34 | train -> loss: 317.95880 | validation -> loss: 190.62726 | accuracy: 94.206352 | precision: 95.948830 | recall: 89.285713 | f2: 90.543259
2023-05-23 15:47:13,253 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 35 | train -> loss: 311.32540 | validation -> loss: 167.84329 | accuracy: 95.158730 | precision: 94.929001 | recall: 92.857140 | f2: 93.264244
2023-05-23 15:47:19,633 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 36 | train -> loss: 314.54045 | validation -> loss: 180.42714 | accuracy: 95.079361 | precision: 91.385773 | recall: 96.825394 | f2: 95.686272
2023-05-23 15:47:25,059 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 37 | train -> loss: 307.97983 | validation -> loss: 167.97855 | accuracy: 95.000000 | precision: 95.463921 | recall: 91.865082 | f2: 92.562973
2023-05-23 15:47:29,866 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 38 | train -> loss: 303.34052 | validation -> loss: 164.50406 | accuracy: 95.079361 | precision: 95.102043 | recall: 92.460320 | f2: 92.976852
2023-05-23 15:47:34,844 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 39 | train -> loss: 301.11141 | validation -> loss: 176.35912 | accuracy: 94.682541 | precision: 95.807129 | recall: 90.674606 | f2: 91.656639
2023-05-23 15:47:39,811 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 40 | train -> loss: 290.86715 | validation -> loss: 162.71278 | accuracy: 95.555557 | precision: 94.268776 | recall: 94.642860 | f2: 94.567802
2023-05-23 15:47:44,467 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 41 | train -> loss: 293.86484 | validation -> loss: 162.78958 | accuracy: 95.238098 | precision: 95.121948 | recall: 92.857140 | f2: 93.301430
2023-05-23 15:47:49,319 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 42 | train -> loss: 288.43339 | validation -> loss: 170.08437 | accuracy: 95.000000 | precision: 95.652176 | recall: 91.666672 | f2: 92.436974
2023-05-23 15:47:53,878 | root | INFO | ann.py learn @ 101 : fold: 0 | epoch: 43 | Learning rate changed from: 0.00125 -> 0.0003125
2023-05-23 15:47:54,010 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 43 | train -> loss: 280.08875 | validation -> loss: 162.53325 | accuracy: 95.634918 | precision: 93.762184 | recall: 95.436508 | f2: 95.096878
2023-05-23 15:47:58,991 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 44 | train -> loss: 267.06282 | validation -> loss: 159.38452 | accuracy: 95.476189 | precision: 94.433395 | recall: 94.246033 | f2: 94.283447
2023-05-23 15:48:03,261 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 45 | train -> loss: 266.33467 | validation -> loss: 159.96873 | accuracy: 95.555557 | precision: 94.979919 | recall: 93.849205 | f2: 94.073189
2023-05-23 15:48:08,226 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 46 | train -> loss: 264.78336 | validation -> loss: 162.23874 | accuracy: 95.555557 | precision: 93.579773 | recall: 95.436508 | f2: 95.059288
2023-05-23 15:48:14,742 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 47 | train -> loss: 262.45205 | validation -> loss: 161.30106 | accuracy: 95.238098 | precision: 95.306122 | recall: 92.658730 | f2: 93.176376
2023-05-23 15:48:19,527 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 48 | train -> loss: 261.32374 | validation -> loss: 160.19275 | accuracy: 95.634918 | precision: 94.280075 | recall: 94.841270 | f2: 94.728500
2023-05-23 15:48:24,394 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 49 | train -> loss: 259.95003 | validation -> loss: 160.18329 | accuracy: 95.476189 | precision: 94.969818 | recall: 93.650795 | f2: 93.911659
2023-05-23 15:48:29,185 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 50 | train -> loss: 261.34130 | validation -> loss: 160.25452 | accuracy: 95.555557 | precision: 95.161285 | recall: 93.650795 | f2: 93.949043
2023-05-23 15:48:34,160 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 51 | train -> loss: 259.78323 | validation -> loss: 160.04898 | accuracy: 95.555557 | precision: 95.161285 | recall: 93.650795 | f2: 93.949043
2023-05-23 15:48:38,946 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 52 | train -> loss: 260.58335 | validation -> loss: 161.96399 | accuracy: 95.317459 | precision: 95.687881 | recall: 92.460320 | f2: 93.088295
2023-05-23 15:48:43,789 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 53 | train -> loss: 260.26969 | validation -> loss: 162.76614 | accuracy: 95.238098 | precision: 95.679016 | recall: 92.261902 | f2: 92.925659
2023-05-23 15:48:48,483 | root | INFO | ann.py learn @ 101 : fold: 0 | epoch: 54 | Learning rate changed from: 0.0003125 -> 7.8125e-05
2023-05-23 15:48:48,605 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 54 | train -> loss: 256.85106 | validation -> loss: 168.39973 | accuracy: 95.079361 | precision: 95.661156 | recall: 91.865082 | f2: 92.599998
2023-05-23 15:48:53,286 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 55 | train -> loss: 254.27115 | validation -> loss: 159.37750 | accuracy: 95.555557 | precision: 95.161285 | recall: 93.650795 | f2: 93.949043
2023-05-23 15:48:57,650 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 56 | train -> loss: 252.58650 | validation -> loss: 159.80597 | accuracy: 95.555557 | precision: 95.344131 | recall: 93.452385 | f2: 93.824699
2023-05-23 15:49:03,348 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 57 | train -> loss: 252.38664 | validation -> loss: 158.81563 | accuracy: 95.634918 | precision: 94.989983 | recall: 94.047615 | f2: 94.234589
2023-05-23 15:49:09,317 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 58 | train -> loss: 252.26192 | validation -> loss: 159.14819 | accuracy: 95.555557 | precision: 95.161285 | recall: 93.650795 | f2: 93.949043
2023-05-23 15:49:14,047 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 59 | train -> loss: 251.50988 | validation -> loss: 158.65157 | accuracy: 95.634918 | precision: 94.989983 | recall: 94.047615 | f2: 94.234589
2023-05-23 15:49:18,748 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 60 | train -> loss: 251.54345 | validation -> loss: 160.59177 | accuracy: 95.238098 | precision: 95.306122 | recall: 92.658730 | f2: 93.176376
2023-05-23 15:49:23,694 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 61 | train -> loss: 252.45646 | validation -> loss: 158.97200 | accuracy: 95.634918 | precision: 94.989983 | recall: 94.047615 | f2: 94.234589
2023-05-23 15:49:28,401 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 62 | train -> loss: 251.26144 | validation -> loss: 161.07843 | accuracy: 95.238098 | precision: 95.306122 | recall: 92.658730 | f2: 93.176376
2023-05-23 15:49:33,122 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 63 | train -> loss: 251.06854 | validation -> loss: 159.15556 | accuracy: 95.634918 | precision: 95.171028 | recall: 93.849205 | f2: 94.110626
2023-05-23 15:49:37,785 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 64 | train -> loss: 250.86966 | validation -> loss: 159.41470 | accuracy: 95.555557 | precision: 95.161285 | recall: 93.650795 | f2: 93.949043
2023-05-23 15:49:42,629 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 65 | train -> loss: 250.79591 | validation -> loss: 158.76933 | accuracy: 95.634918 | precision: 94.989983 | recall: 94.047615 | f2: 94.234589
2023-05-23 15:49:47,212 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 66 | train -> loss: 250.22236 | validation -> loss: 160.04086 | accuracy: 95.555557 | precision: 95.344131 | recall: 93.452385 | f2: 93.824699
2023-05-23 15:49:51,523 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 67 | train -> loss: 249.34539 | validation -> loss: 159.17616 | accuracy: 95.555557 | precision: 95.161285 | recall: 93.650795 | f2: 93.949043
2023-05-23 15:49:57,777 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 68 | train -> loss: 250.40250 | validation -> loss: 159.24678 | accuracy: 95.555557 | precision: 95.161285 | recall: 93.650795 | f2: 93.949043
2023-05-23 15:50:03,498 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 69 | train -> loss: 250.17563 | validation -> loss: 158.68846 | accuracy: 95.634918 | precision: 94.989983 | recall: 94.047615 | f2: 94.234589
2023-05-23 15:50:08,354 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 70 | train -> loss: 249.82562 | validation -> loss: 159.73251 | accuracy: 95.555557 | precision: 95.344131 | recall: 93.452385 | f2: 93.824699
2023-05-23 15:50:13,097 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 71 | train -> loss: 249.98534 | validation -> loss: 158.49568 | accuracy: 95.634918 | precision: 94.989983 | recall: 94.047615 | f2: 94.234589
2023-05-23 15:50:17,961 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 72 | train -> loss: 250.37528 | validation -> loss: 158.38568 | accuracy: 95.634918 | precision: 94.989983 | recall: 94.047615 | f2: 94.234589
2023-05-23 15:50:22,592 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 73 | train -> loss: 249.61036 | validation -> loss: 158.74399 | accuracy: 95.634918 | precision: 95.171028 | recall: 93.849205 | f2: 94.110626
2023-05-23 15:50:27,328 | root | INFO | ann.py learn @ 124 : fold: 0 | epoch: 74 | train -> loss: 249.35001 | validation -> loss: 158.77943 | accuracy: 95.634918 | precision: 95.171028 | recall: 93.849205 | f2: 94.110626
2023-05-23 15:50:27,328 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/weights/f0/model_fold0.pth
2023-05-23 15:50:28,185 | root | INFO | ann.py learn @ 67 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 15:50:28,185 | root | INFO | ann.py learn @ 72 : fetching data for fold #1
2023-05-23 15:50:28,185 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 15:50:28,195 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 15:50:32,541 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 0 | train -> loss: 2095.00819 | validation -> loss: 601.10199 | accuracy: 72.698418 | precision: 90.816322 | recall: 35.317459 | f2: 40.235081
2023-05-23 15:50:37,102 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 1 | train -> loss: 1476.12477 | validation -> loss: 373.13882 | accuracy: 85.396828 | precision: 89.603958 | recall: 71.825394 | f2: 74.793388
2023-05-23 15:50:41,287 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 2 | train -> loss: 1126.66740 | validation -> loss: 320.48181 | accuracy: 86.587303 | precision: 93.059128 | recall: 71.825394 | f2: 75.259872
2023-05-23 15:50:45,666 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 3 | train -> loss: 944.89082 | validation -> loss: 288.35312 | accuracy: 91.587296 | precision: 85.535721 | recall: 95.039680 | f2: 92.973602
2023-05-23 15:50:51,797 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 4 | train -> loss: 871.04654 | validation -> loss: 241.38258 | accuracy: 92.698410 | precision: 94.017097 | recall: 87.301590 | f2: 88.566826
2023-05-23 15:50:56,327 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 5 | train -> loss: 776.34279 | validation -> loss: 224.14633 | accuracy: 93.412697 | precision: 94.692146 | recall: 88.492065 | f2: 89.666267
2023-05-23 15:51:00,922 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 6 | train -> loss: 796.62759 | validation -> loss: 303.47150 | accuracy: 92.539680 | precision: 86.607140 | recall: 96.230164 | f2: 94.138199
2023-05-23 15:51:05,754 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 7 | train -> loss: 748.69302 | validation -> loss: 220.51225 | accuracy: 93.888893 | precision: 89.463959 | recall: 96.031746 | f2: 94.642159
2023-05-23 15:51:10,374 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 8 | train -> loss: 695.20597 | validation -> loss: 221.19373 | accuracy: 92.936508 | precision: 96.839729 | recall: 85.119041 | f2: 87.230583
2023-05-23 15:51:15,198 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 9 | train -> loss: 675.10985 | validation -> loss: 220.21677 | accuracy: 93.095238 | precision: 87.298744 | recall: 96.825394 | f2: 94.757286
2023-05-23 15:51:19,981 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 10 | train -> loss: 571.32783 | validation -> loss: 172.55606 | accuracy: 95.793655 | precision: 93.786407 | recall: 95.833328 | f2: 95.416832
2023-05-23 15:51:24,674 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 11 | train -> loss: 549.34339 | validation -> loss: 179.27283 | accuracy: 94.841270 | precision: 91.493385 | recall: 96.031746 | f2: 95.088409
2023-05-23 15:51:29,560 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 12 | train -> loss: 510.32549 | validation -> loss: 193.76196 | accuracy: 93.650795 | precision: 96.491226 | recall: 87.301590 | f2: 88.996765
2023-05-23 15:51:34,322 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 13 | train -> loss: 539.66164 | validation -> loss: 303.66922 | accuracy: 87.936508 | precision: 97.826088 | recall: 71.428574 | f2: 75.503357
2023-05-23 15:51:38,792 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 14 | train -> loss: 499.09898 | validation -> loss: 155.22169 | accuracy: 95.634918 | precision: 96.098557 | recall: 92.857140 | f2: 93.487816
2023-05-23 15:51:43,208 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 15 | train -> loss: 477.59923 | validation -> loss: 153.91963 | accuracy: 96.111115 | precision: 94.520546 | recall: 95.833328 | f2: 95.567863
2023-05-23 15:51:49,761 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 16 | train -> loss: 478.16359 | validation -> loss: 157.02609 | accuracy: 96.111115 | precision: 95.409180 | recall: 94.841270 | f2: 94.954315
2023-05-23 15:51:54,845 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 17 | train -> loss: 431.45896 | validation -> loss: 156.48248 | accuracy: 96.587303 | precision: 95.463509 | recall: 96.031746 | f2: 95.917557
2023-05-23 15:51:59,662 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 18 | train -> loss: 529.20311 | validation -> loss: 190.72444 | accuracy: 94.206352 | precision: 96.949890 | recall: 88.293655 | f2: 89.898994
2023-05-23 15:52:04,566 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 19 | train -> loss: 433.28380 | validation -> loss: 164.30936 | accuracy: 95.873016 | precision: 95.748993 | recall: 93.849205 | f2: 94.223106
2023-05-23 15:52:09,371 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 20 | train -> loss: 367.10388 | validation -> loss: 310.86627 | accuracy: 86.746033 | precision: 97.733711 | recall: 68.452385 | f2: 72.815529
2023-05-23 15:52:14,141 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 21 | train -> loss: 413.24212 | validation -> loss: 155.22141 | accuracy: 96.031746 | precision: 95.766129 | recall: 94.246033 | f2: 94.546181
2023-05-23 15:52:18,939 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 22 | train -> loss: 384.95299 | validation -> loss: 210.26929 | accuracy: 94.523811 | precision: 90.055252 | recall: 97.023811 | f2: 95.545135
2023-05-23 15:52:23,594 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 23 | train -> loss: 395.97256 | validation -> loss: 366.98672 | accuracy: 84.444443 | precision: 97.826088 | recall: 62.500000 | f2: 67.365273
2023-05-23 15:52:28,439 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 24 | train -> loss: 453.53160 | validation -> loss: 196.52144 | accuracy: 94.365082 | precision: 97.582420 | recall: 88.095238 | f2: 89.842171
2023-05-23 15:52:32,890 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 25 | train -> loss: 344.62575 | validation -> loss: 196.09583 | accuracy: 95.158730 | precision: 90.942696 | recall: 97.619041 | f2: 96.206490
2023-05-23 15:52:37,459 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 26 | train -> loss: 434.51310 | validation -> loss: 269.04422 | accuracy: 93.015877 | precision: 86.236938 | recall: 98.214287 | f2: 95.559845
2023-05-23 15:52:44,088 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 27 | train -> loss: 388.70215 | validation -> loss: 164.49571 | accuracy: 96.111115 | precision: 94.003868 | recall: 96.428574 | f2: 95.933678
2023-05-23 15:52:48,955 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 28 | train -> loss: 310.12309 | validation -> loss: 147.06447 | accuracy: 96.507935 | precision: 96.000000 | recall: 95.238098 | f2: 95.389511
2023-05-23 15:52:53,717 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 29 | train -> loss: 282.94508 | validation -> loss: 186.41472 | accuracy: 95.476189 | precision: 91.620110 | recall: 97.619041 | f2: 96.357224
2023-05-23 15:52:58,528 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 30 | train -> loss: 299.58416 | validation -> loss: 157.27586 | accuracy: 96.825394 | precision: 95.312500 | recall: 96.825394 | f2: 96.518990
2023-05-23 15:53:03,416 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 31 | train -> loss: 352.95234 | validation -> loss: 151.17633 | accuracy: 96.666664 | precision: 96.015938 | recall: 95.634918 | f2: 95.710876
2023-05-23 15:53:08,261 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 32 | train -> loss: 298.83208 | validation -> loss: 157.80800 | accuracy: 96.428574 | precision: 95.088409 | recall: 96.031746 | f2: 95.841583
2023-05-23 15:53:13,015 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 33 | train -> loss: 293.73237 | validation -> loss: 192.15378 | accuracy: 95.634918 | precision: 91.806335 | recall: 97.817459 | f2: 96.553078
2023-05-23 15:53:18,007 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 34 | train -> loss: 273.49977 | validation -> loss: 795.27551 | accuracy: 81.904762 | precision: 69.060776 | recall: 99.206345 | f2: 91.240875
2023-05-23 15:53:22,782 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 35 | train -> loss: 357.97576 | validation -> loss: 284.20477 | accuracy: 90.952377 | precision: 97.560974 | recall: 79.365082 | f2: 82.440231
2023-05-23 15:53:27,275 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 36 | train -> loss: 281.96120 | validation -> loss: 156.87958 | accuracy: 96.904762 | precision: 95.677795 | recall: 96.626984 | f2: 96.435638
2023-05-23 15:53:31,815 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 37 | train -> loss: 319.55109 | validation -> loss: 183.83339 | accuracy: 95.873016 | precision: 92.803032 | recall: 97.222221 | f2: 96.305031
2023-05-23 15:53:38,497 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 38 | train -> loss: 265.05126 | validation -> loss: 189.93811 | accuracy: 94.206352 | precision: 97.362640 | recall: 87.896820 | f2: 89.639824
2023-05-23 15:53:43,261 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 39 | train -> loss: 355.75353 | validation -> loss: 169.01532 | accuracy: 96.031746 | precision: 96.707825 | recall: 93.253967 | f2: 93.924866
2023-05-23 15:53:48,106 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 40 | train -> loss: 300.83640 | validation -> loss: 174.18065 | accuracy: 96.587303 | precision: 96.192383 | recall: 95.238098 | f2: 95.427437
2023-05-23 15:53:52,827 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 41 | train -> loss: 237.99111 | validation -> loss: 174.75264 | accuracy: 96.349205 | precision: 96.169350 | recall: 94.642860 | f2: 94.944267
2023-05-23 15:53:57,661 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 42 | train -> loss: 343.02255 | validation -> loss: 305.28555 | accuracy: 91.111115 | precision: 97.804878 | recall: 79.563492 | f2: 82.646332
2023-05-23 15:54:02,446 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 43 | train -> loss: 261.11237 | validation -> loss: 183.36116 | accuracy: 95.873016 | precision: 97.280334 | recall: 92.261902 | f2: 93.223740
2023-05-23 15:54:07,268 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 44 | train -> loss: 268.57827 | validation -> loss: 155.23772 | accuracy: 95.952377 | precision: 96.130348 | recall: 93.650795 | f2: 94.136414
2023-05-23 15:54:12,010 | root | INFO | ann.py learn @ 101 : fold: 1 | epoch: 45 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 15:54:12,131 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 45 | train -> loss: 233.43932 | validation -> loss: 282.02313 | accuracy: 91.190475 | precision: 97.578690 | recall: 79.960320 | f2: 82.955948
2023-05-23 15:54:16,926 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 46 | train -> loss: 173.61165 | validation -> loss: 159.36371 | accuracy: 96.428574 | precision: 95.991982 | recall: 95.039680 | f2: 95.228630
2023-05-23 15:54:21,396 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 47 | train -> loss: 161.56874 | validation -> loss: 159.96960 | accuracy: 96.507935 | precision: 96.370964 | recall: 94.841270 | f2: 95.143311
2023-05-23 15:54:26,703 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 48 | train -> loss: 178.56432 | validation -> loss: 160.11328 | accuracy: 96.507935 | precision: 96.558701 | recall: 94.642860 | f2: 95.019920
2023-05-23 15:54:33,013 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 49 | train -> loss: 170.35896 | validation -> loss: 157.32948 | accuracy: 96.666664 | precision: 96.015938 | recall: 95.634918 | f2: 95.710876
2023-05-23 15:54:37,775 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 50 | train -> loss: 160.72408 | validation -> loss: 165.01636 | accuracy: 96.428574 | precision: 96.551720 | recall: 94.444443 | f2: 94.858513
2023-05-23 15:54:42,490 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 51 | train -> loss: 155.43945 | validation -> loss: 175.11502 | accuracy: 96.349205 | precision: 94.038460 | recall: 97.023811 | f2: 96.411667
2023-05-23 15:54:47,322 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 52 | train -> loss: 164.14666 | validation -> loss: 160.30672 | accuracy: 96.587303 | precision: 95.107635 | recall: 96.428574 | f2: 96.161453
2023-05-23 15:54:52,220 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 53 | train -> loss: 154.28426 | validation -> loss: 158.85338 | accuracy: 96.428574 | precision: 95.991982 | recall: 95.039680 | f2: 95.228630
2023-05-23 15:54:56,959 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 54 | train -> loss: 152.62403 | validation -> loss: 166.34763 | accuracy: 96.507935 | precision: 96.370964 | recall: 94.841270 | f2: 95.143311
2023-05-23 15:55:01,553 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 55 | train -> loss: 146.73007 | validation -> loss: 176.21799 | accuracy: 96.507935 | precision: 94.061302 | recall: 97.420631 | f2: 96.729706
2023-05-23 15:55:06,094 | root | INFO | ann.py learn @ 101 : fold: 1 | epoch: 56 | Learning rate changed from: 0.00125 -> 0.0003125
2023-05-23 15:55:06,226 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 56 | train -> loss: 152.84764 | validation -> loss: 160.41597 | accuracy: 96.507935 | precision: 95.634918 | recall: 95.634918 | f2: 95.634918
2023-05-23 15:55:10,994 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 57 | train -> loss: 137.14811 | validation -> loss: 161.07008 | accuracy: 96.507935 | precision: 95.634918 | recall: 95.634918 | f2: 95.634918
2023-05-23 15:55:15,427 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 58 | train -> loss: 138.22166 | validation -> loss: 162.12096 | accuracy: 96.666664 | precision: 95.294121 | recall: 96.428574 | f2: 96.199524
2023-05-23 15:55:20,645 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 59 | train -> loss: 138.06072 | validation -> loss: 161.25430 | accuracy: 96.507935 | precision: 95.634918 | recall: 95.634918 | f2: 95.634918
2023-05-23 15:55:26,520 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 60 | train -> loss: 136.75471 | validation -> loss: 164.70541 | accuracy: 96.507935 | precision: 96.558701 | recall: 94.642860 | f2: 95.019920
2023-05-23 15:55:30,606 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 61 | train -> loss: 136.19198 | validation -> loss: 161.84579 | accuracy: 96.507935 | precision: 95.634918 | recall: 95.634918 | f2: 95.634918
2023-05-23 15:55:34,948 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 62 | train -> loss: 133.84421 | validation -> loss: 162.81972 | accuracy: 96.587303 | precision: 95.825050 | recall: 95.634918 | f2: 95.672890
2023-05-23 15:55:39,508 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 63 | train -> loss: 136.48262 | validation -> loss: 162.26309 | accuracy: 96.587303 | precision: 95.825050 | recall: 95.634918 | f2: 95.672890
2023-05-23 15:55:44,062 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 64 | train -> loss: 137.50511 | validation -> loss: 163.05836 | accuracy: 96.428574 | precision: 95.808380 | recall: 95.238098 | f2: 95.351608
2023-05-23 15:55:48,412 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 65 | train -> loss: 135.28005 | validation -> loss: 162.16367 | accuracy: 96.507935 | precision: 95.816734 | recall: 95.436508 | f2: 95.512314
2023-05-23 15:55:52,962 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 66 | train -> loss: 135.18257 | validation -> loss: 162.54858 | accuracy: 96.746033 | precision: 95.481339 | recall: 96.428574 | f2: 96.237625
2023-05-23 15:55:57,191 | root | INFO | ann.py learn @ 101 : fold: 1 | epoch: 67 | Learning rate changed from: 0.0003125 -> 7.8125e-05
2023-05-23 15:55:57,310 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 67 | train -> loss: 136.27315 | validation -> loss: 162.08163 | accuracy: 96.666664 | precision: 95.294121 | recall: 96.428574 | f2: 96.199524
2023-05-23 15:56:01,739 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 68 | train -> loss: 131.07514 | validation -> loss: 162.06845 | accuracy: 96.666664 | precision: 95.472443 | recall: 96.230164 | f2: 96.077660
2023-05-23 15:56:06,025 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 69 | train -> loss: 131.05846 | validation -> loss: 162.07646 | accuracy: 96.587303 | precision: 95.463509 | recall: 96.031746 | f2: 95.917557
2023-05-23 15:56:10,315 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 70 | train -> loss: 131.07090 | validation -> loss: 161.98557 | accuracy: 96.666664 | precision: 95.652176 | recall: 96.031746 | f2: 95.955589
2023-05-23 15:56:14,542 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 71 | train -> loss: 131.50227 | validation -> loss: 162.13411 | accuracy: 96.666664 | precision: 95.652176 | recall: 96.031746 | f2: 95.955589
2023-05-23 15:56:20,610 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 72 | train -> loss: 130.88364 | validation -> loss: 162.49796 | accuracy: 96.666664 | precision: 95.294121 | recall: 96.428574 | f2: 96.199524
2023-05-23 15:56:25,143 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 73 | train -> loss: 129.86640 | validation -> loss: 162.57733 | accuracy: 96.587303 | precision: 95.825050 | recall: 95.634918 | f2: 95.672890
2023-05-23 15:56:29,763 | root | INFO | ann.py learn @ 124 : fold: 1 | epoch: 74 | train -> loss: 130.39114 | validation -> loss: 162.32498 | accuracy: 96.666664 | precision: 95.652176 | recall: 96.031746 | f2: 95.955589
2023-05-23 15:56:29,773 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/weights/f1/model_fold1.pth
2023-05-23 15:56:30,233 | root | INFO | ann.py learn @ 67 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 15:56:30,233 | root | INFO | ann.py learn @ 72 : fetching data for fold #2
2023-05-23 15:56:30,243 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 15:56:30,243 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 15:56:34,415 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 0 | train -> loss: 2036.90932 | validation -> loss: 536.40637 | accuracy: 81.111107 | precision: 86.944443 | recall: 62.103176 | f2: 65.867004
2023-05-23 15:56:38,607 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 1 | train -> loss: 1374.32974 | validation -> loss: 335.41769 | accuracy: 89.603172 | precision: 90.631805 | recall: 82.539680 | f2: 84.040405
2023-05-23 15:56:42,896 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 2 | train -> loss: 1086.15668 | validation -> loss: 318.32394 | accuracy: 85.873016 | precision: 94.054054 | recall: 69.047615 | f2: 72.925400
2023-05-23 15:56:47,202 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 3 | train -> loss: 964.48372 | validation -> loss: 265.11520 | accuracy: 89.761909 | precision: 94.326241 | recall: 79.166672 | f2: 81.795815
2023-05-23 15:56:51,476 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 4 | train -> loss: 856.86382 | validation -> loss: 220.87239 | accuracy: 93.253967 | precision: 92.668030 | recall: 90.277779 | f2: 90.745911
2023-05-23 15:56:55,642 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 5 | train -> loss: 801.02819 | validation -> loss: 203.49286 | accuracy: 93.968254 | precision: 91.634247 | recall: 93.452385 | f2: 93.083008
2023-05-23 15:56:59,880 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 6 | train -> loss: 709.16327 | validation -> loss: 264.90787 | accuracy: 87.698410 | precision: 95.800522 | recall: 72.420631 | f2: 76.136841
2023-05-23 15:57:03,954 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 7 | train -> loss: 689.23953 | validation -> loss: 188.39731 | accuracy: 94.682541 | precision: 91.778198 | recall: 95.238098 | f2: 94.525406
2023-05-23 15:57:08,399 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 8 | train -> loss: 618.66011 | validation -> loss: 194.31293 | accuracy: 94.444443 | precision: 89.743591 | recall: 97.222221 | f2: 95.628418
2023-05-23 15:57:13,903 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 9 | train -> loss: 525.37564 | validation -> loss: 286.73737 | accuracy: 86.428574 | precision: 96.638657 | recall: 68.452385 | f2: 72.692795
2023-05-23 15:57:18,123 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 10 | train -> loss: 528.16863 | validation -> loss: 166.09036 | accuracy: 95.476189 | precision: 92.571434 | recall: 96.428574 | f2: 95.631638
2023-05-23 15:57:22,441 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 11 | train -> loss: 607.29135 | validation -> loss: 177.65436 | accuracy: 95.317459 | precision: 91.127541 | recall: 97.817459 | f2: 96.402031
2023-05-23 15:57:26,516 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 12 | train -> loss: 462.56770 | validation -> loss: 156.95186 | accuracy: 95.793655 | precision: 95.555557 | recall: 93.849205 | f2: 94.185585
2023-05-23 15:57:30,757 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 13 | train -> loss: 467.06345 | validation -> loss: 161.61018 | accuracy: 96.190475 | precision: 93.018867 | recall: 97.817459 | f2: 96.818535
2023-05-23 15:57:34,965 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 14 | train -> loss: 472.96169 | validation -> loss: 174.76152 | accuracy: 95.158730 | precision: 90.346085 | recall: 98.412697 | f2: 96.686157
2023-05-23 15:57:39,342 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 15 | train -> loss: 431.73698 | validation -> loss: 154.99591 | accuracy: 95.714279 | precision: 95.546562 | recall: 93.650795 | f2: 94.023911
2023-05-23 15:57:43,479 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 16 | train -> loss: 429.65913 | validation -> loss: 151.52840 | accuracy: 96.190475 | precision: 94.881889 | recall: 95.634918 | f2: 95.483360
2023-05-23 15:57:47,774 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 17 | train -> loss: 394.53911 | validation -> loss: 302.96304 | accuracy: 92.222221 | precision: 84.290543 | recall: 99.007935 | f2: 95.667175
2023-05-23 15:57:52,023 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 18 | train -> loss: 451.30851 | validation -> loss: 151.21646 | accuracy: 96.349205 | precision: 95.078743 | recall: 95.833328 | f2: 95.681458
2023-05-23 15:57:56,099 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 19 | train -> loss: 413.45615 | validation -> loss: 184.11990 | accuracy: 95.396820 | precision: 90.842491 | recall: 98.412697 | f2: 96.799377
2023-05-23 15:58:00,548 | root | INFO | ann.py learn @ 101 : fold: 2 | epoch: 20 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 15:58:00,699 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 20 | train -> loss: 433.27902 | validation -> loss: 189.92827 | accuracy: 95.000000 | precision: 90.018150 | recall: 98.412697 | f2: 96.610832
2023-05-23 15:58:05,744 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 21 | train -> loss: 304.07491 | validation -> loss: 158.00766 | accuracy: 96.587303 | precision: 93.904762 | recall: 97.817459 | f2: 97.009048
2023-05-23 15:58:10,043 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 22 | train -> loss: 287.82040 | validation -> loss: 161.91101 | accuracy: 95.317459 | precision: 96.066254 | recall: 92.063492 | f2: 92.837135
2023-05-23 15:58:14,502 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 23 | train -> loss: 290.27561 | validation -> loss: 152.62891 | accuracy: 96.746033 | precision: 94.433777 | recall: 97.619041 | f2: 96.964920
2023-05-23 15:58:18,828 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 24 | train -> loss: 285.95552 | validation -> loss: 149.82588 | accuracy: 96.666664 | precision: 94.767441 | recall: 97.023811 | f2: 96.563980
2023-05-23 15:58:23,232 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 25 | train -> loss: 289.79750 | validation -> loss: 148.96500 | accuracy: 96.666664 | precision: 94.767441 | recall: 97.023811 | f2: 96.563980
2023-05-23 15:58:27,361 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 26 | train -> loss: 274.19064 | validation -> loss: 148.04674 | accuracy: 96.269836 | precision: 95.069031 | recall: 95.634918 | f2: 95.521202
2023-05-23 15:58:31,806 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 27 | train -> loss: 274.69992 | validation -> loss: 158.02548 | accuracy: 95.555557 | precision: 96.090538 | recall: 92.658730 | f2: 93.325340
2023-05-23 15:58:36,188 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 28 | train -> loss: 271.52468 | validation -> loss: 166.05411 | accuracy: 96.190475 | precision: 92.696632 | recall: 98.214287 | f2: 97.058823
2023-05-23 15:58:40,514 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 29 | train -> loss: 267.61790 | validation -> loss: 151.32271 | accuracy: 95.634918 | precision: 95.537529 | recall: 93.452385 | f2: 93.862099
2023-05-23 15:58:44,685 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 30 | train -> loss: 276.93872 | validation -> loss: 148.95370 | accuracy: 96.349205 | precision: 95.078743 | recall: 95.833328 | f2: 95.681458
2023-05-23 15:58:48,649 | root | INFO | ann.py learn @ 101 : fold: 2 | epoch: 31 | Learning rate changed from: 0.00125 -> 0.0003125
2023-05-23 15:58:48,773 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 31 | train -> loss: 262.06238 | validation -> loss: 162.82202 | accuracy: 96.190475 | precision: 92.857140 | recall: 98.015877 | f2: 96.938774
2023-05-23 15:58:54,721 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 32 | train -> loss: 240.67872 | validation -> loss: 149.58998 | accuracy: 96.666664 | precision: 94.941635 | recall: 96.825394 | f2: 96.442688
2023-05-23 15:58:59,070 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 33 | train -> loss: 239.29261 | validation -> loss: 151.82423 | accuracy: 96.825394 | precision: 94.615379 | recall: 97.619041 | f2: 97.003159
2023-05-23 15:59:03,515 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 34 | train -> loss: 238.77585 | validation -> loss: 151.73071 | accuracy: 96.825394 | precision: 94.615379 | recall: 97.619041 | f2: 97.003159
2023-05-23 15:59:07,802 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 35 | train -> loss: 238.06830 | validation -> loss: 152.03336 | accuracy: 96.825394 | precision: 94.615379 | recall: 97.619041 | f2: 97.003159
2023-05-23 15:59:12,012 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 36 | train -> loss: 237.83635 | validation -> loss: 157.43291 | accuracy: 96.507935 | precision: 93.893127 | recall: 97.619041 | f2: 96.850395
2023-05-23 15:59:16,295 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 37 | train -> loss: 236.76141 | validation -> loss: 155.64638 | accuracy: 96.666664 | precision: 94.252869 | recall: 97.619041 | f2: 96.926712
2023-05-23 15:59:20,634 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 38 | train -> loss: 233.87629 | validation -> loss: 149.90985 | accuracy: 96.666664 | precision: 94.941635 | recall: 96.825394 | f2: 96.442688
2023-05-23 15:59:25,257 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 39 | train -> loss: 236.49114 | validation -> loss: 155.31631 | accuracy: 96.666664 | precision: 94.252869 | recall: 97.619041 | f2: 96.926712
2023-05-23 15:59:29,577 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 40 | train -> loss: 235.83773 | validation -> loss: 155.93404 | accuracy: 96.666664 | precision: 94.252869 | recall: 97.619041 | f2: 96.926712
2023-05-23 15:59:33,877 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 41 | train -> loss: 232.06805 | validation -> loss: 151.07918 | accuracy: 96.825394 | precision: 94.787643 | recall: 97.420631 | f2: 96.882401
2023-05-23 15:59:38,016 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 42 | train -> loss: 232.56174 | validation -> loss: 150.20441 | accuracy: 96.587303 | precision: 94.931778 | recall: 96.626984 | f2: 96.283112
2023-05-23 15:59:42,667 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 43 | train -> loss: 234.06532 | validation -> loss: 151.35669 | accuracy: 96.746033 | precision: 94.605011 | recall: 97.420631 | f2: 96.844185
2023-05-23 15:59:47,894 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 44 | train -> loss: 233.27131 | validation -> loss: 149.60483 | accuracy: 96.666664 | precision: 95.117188 | recall: 96.626984 | f2: 96.321198
2023-05-23 15:59:52,157 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 45 | train -> loss: 233.88565 | validation -> loss: 162.53490 | accuracy: 96.190475 | precision: 93.018867 | recall: 97.817459 | f2: 96.818535
2023-05-23 15:59:56,818 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 46 | train -> loss: 230.81942 | validation -> loss: 153.09241 | accuracy: 96.666664 | precision: 94.423080 | recall: 97.420631 | f2: 96.805992
2023-05-23 16:00:01,512 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 47 | train -> loss: 230.50672 | validation -> loss: 148.96930 | accuracy: 96.428574 | precision: 95.088409 | recall: 96.031746 | f2: 95.841583
2023-05-23 16:00:06,163 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 48 | train -> loss: 228.91413 | validation -> loss: 150.19380 | accuracy: 96.904762 | precision: 94.970993 | recall: 97.420631 | f2: 96.920647
2023-05-23 16:00:10,814 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 49 | train -> loss: 229.48823 | validation -> loss: 152.70451 | accuracy: 96.746033 | precision: 94.605011 | recall: 97.420631 | f2: 96.844185
2023-05-23 16:00:15,423 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 50 | train -> loss: 228.03095 | validation -> loss: 149.29483 | accuracy: 96.666664 | precision: 95.117188 | recall: 96.626984 | f2: 96.321198
2023-05-23 16:00:19,995 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 51 | train -> loss: 229.27596 | validation -> loss: 147.98447 | accuracy: 96.507935 | precision: 95.275589 | recall: 96.031746 | f2: 95.879555
2023-05-23 16:00:24,738 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 52 | train -> loss: 228.72218 | validation -> loss: 151.15244 | accuracy: 96.746033 | precision: 94.605011 | recall: 97.420631 | f2: 96.844185
2023-05-23 16:00:29,127 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 53 | train -> loss: 225.14367 | validation -> loss: 160.66879 | accuracy: 96.190475 | precision: 93.181816 | recall: 97.619041 | f2: 96.698112
2023-05-23 16:00:33,422 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 54 | train -> loss: 227.35807 | validation -> loss: 157.74588 | accuracy: 96.507935 | precision: 93.893127 | recall: 97.619041 | f2: 96.850395
2023-05-23 16:00:38,532 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 55 | train -> loss: 224.92733 | validation -> loss: 159.27530 | accuracy: 96.269836 | precision: 93.358635 | recall: 97.619041 | f2: 96.736137
2023-05-23 16:00:44,733 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 56 | train -> loss: 224.58161 | validation -> loss: 153.38774 | accuracy: 96.666664 | precision: 94.423080 | recall: 97.420631 | f2: 96.805992
2023-05-23 16:00:49,316 | root | INFO | ann.py learn @ 101 : fold: 2 | epoch: 57 | Learning rate changed from: 0.0003125 -> 7.8125e-05
2023-05-23 16:00:49,449 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 57 | train -> loss: 227.54711 | validation -> loss: 151.42860 | accuracy: 96.825394 | precision: 94.787643 | recall: 97.420631 | f2: 96.882401
2023-05-23 16:00:54,179 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 58 | train -> loss: 219.51648 | validation -> loss: 150.85802 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:00:58,885 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 59 | train -> loss: 219.74520 | validation -> loss: 150.00749 | accuracy: 96.666664 | precision: 95.117188 | recall: 96.626984 | f2: 96.321198
2023-05-23 16:01:03,652 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 60 | train -> loss: 219.04557 | validation -> loss: 154.55412 | accuracy: 96.746033 | precision: 94.433777 | recall: 97.619041 | f2: 96.964920
2023-05-23 16:01:08,417 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 61 | train -> loss: 219.60288 | validation -> loss: 150.73033 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:01:13,029 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 62 | train -> loss: 219.36140 | validation -> loss: 151.05548 | accuracy: 96.904762 | precision: 94.970993 | recall: 97.420631 | f2: 96.920647
2023-05-23 16:01:17,703 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 63 | train -> loss: 218.86215 | validation -> loss: 151.84030 | accuracy: 96.825394 | precision: 94.787643 | recall: 97.420631 | f2: 96.882401
2023-05-23 16:01:22,326 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 64 | train -> loss: 218.30545 | validation -> loss: 149.43402 | accuracy: 96.587303 | precision: 95.107635 | recall: 96.428574 | f2: 96.161453
2023-05-23 16:01:26,857 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 65 | train -> loss: 218.45042 | validation -> loss: 151.59227 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:01:30,925 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 66 | train -> loss: 218.59950 | validation -> loss: 151.59131 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:01:37,238 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 67 | train -> loss: 218.49918 | validation -> loss: 152.13167 | accuracy: 96.746033 | precision: 94.605011 | recall: 97.420631 | f2: 96.844185
2023-05-23 16:01:42,086 | root | INFO | ann.py learn @ 101 : fold: 2 | epoch: 68 | Learning rate changed from: 7.8125e-05 -> 1.953125e-05
2023-05-23 16:01:42,217 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 68 | train -> loss: 219.10742 | validation -> loss: 150.93835 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:01:46,840 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 69 | train -> loss: 216.96197 | validation -> loss: 151.60141 | accuracy: 96.825394 | precision: 94.787643 | recall: 97.420631 | f2: 96.882401
2023-05-23 16:01:51,406 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 70 | train -> loss: 217.02613 | validation -> loss: 151.46295 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:01:56,162 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 71 | train -> loss: 216.48809 | validation -> loss: 150.50079 | accuracy: 96.746033 | precision: 94.951454 | recall: 97.023811 | f2: 96.602135
2023-05-23 16:02:00,855 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 72 | train -> loss: 216.95483 | validation -> loss: 151.14333 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:02:05,731 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 73 | train -> loss: 216.81348 | validation -> loss: 151.15816 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:02:10,275 | root | INFO | ann.py learn @ 124 : fold: 2 | epoch: 74 | train -> loss: 216.66275 | validation -> loss: 151.36195 | accuracy: 96.825394 | precision: 94.961235 | recall: 97.222221 | f2: 96.761452
2023-05-23 16:02:10,277 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/weights/f2/model_fold2.pth
2023-05-23 16:02:10,799 | root | INFO | ann.py learn @ 67 : Resetting Optimizer, Learning rate, and Scheduler
2023-05-23 16:02:10,809 | root | INFO | ann.py learn @ 72 : fetching data for fold #3
2023-05-23 16:02:10,809 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters i2h
2023-05-23 16:02:10,809 | root | INFO | ann.py reset_modules @ 53 : resetting module parameters 1.layers
2023-05-23 16:02:15,291 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 0 | train -> loss: 2062.78074 | validation -> loss: 585.73553 | accuracy: 64.495628 | precision: 96.721306 | recall: 11.706349 | f2: 14.203177
2023-05-23 16:02:19,726 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 1 | train -> loss: 1366.94642 | validation -> loss: 384.32129 | accuracy: 86.576645 | precision: 89.786224 | recall: 75.000000 | f2: 77.554367
2023-05-23 16:02:23,903 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 2 | train -> loss: 1050.72769 | validation -> loss: 323.44025 | accuracy: 89.753769 | precision: 85.046730 | recall: 90.277779 | f2: 89.180717
2023-05-23 16:02:29,540 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 3 | train -> loss: 1105.55552 | validation -> loss: 344.77814 | accuracy: 89.277199 | precision: 83.484573 | recall: 91.269836 | f2: 89.598755
2023-05-23 16:02:35,278 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 4 | train -> loss: 938.48873 | validation -> loss: 290.55768 | accuracy: 91.183479 | precision: 87.715927 | recall: 90.674606 | f2: 90.067009
2023-05-23 16:02:40,031 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 5 | train -> loss: 791.71875 | validation -> loss: 262.17682 | accuracy: 91.501198 | precision: 90.927834 | recall: 87.500000 | f2: 88.164734
2023-05-23 16:02:44,945 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 6 | train -> loss: 894.44021 | validation -> loss: 251.07008 | accuracy: 91.818909 | precision: 90.505051 | recall: 88.888893 | f2: 89.207489
2023-05-23 16:02:49,619 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 7 | train -> loss: 750.60308 | validation -> loss: 242.06932 | accuracy: 92.295471 | precision: 94.529541 | recall: 85.714287 | f2: 87.343307
2023-05-23 16:02:54,443 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 8 | train -> loss: 631.13575 | validation -> loss: 225.35883 | accuracy: 93.169182 | precision: 94.279655 | recall: 88.293655 | f2: 89.429260
2023-05-23 16:02:59,195 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 9 | train -> loss: 613.57440 | validation -> loss: 245.56674 | accuracy: 91.104050 | precision: 95.581398 | recall: 81.547615 | f2: 84.014717
2023-05-23 16:03:03,850 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 10 | train -> loss: 583.49772 | validation -> loss: 474.77301 | accuracy: 84.590950 | precision: 72.660820 | recall: 98.611107 | f2: 92.037041
2023-05-23 16:03:08,966 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 11 | train -> loss: 638.22860 | validation -> loss: 202.04311 | accuracy: 94.281174 | precision: 90.909096 | recall: 95.238098 | f2: 94.339622
2023-05-23 16:03:13,885 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 12 | train -> loss: 505.84551 | validation -> loss: 194.82860 | accuracy: 93.566322 | precision: 94.339622 | recall: 89.285713 | f2: 90.252708
2023-05-23 16:03:18,092 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 13 | train -> loss: 457.63107 | validation -> loss: 187.10245 | accuracy: 94.201752 | precision: 94.069527 | recall: 91.269836 | f2: 91.816368
2023-05-23 16:03:24,121 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 14 | train -> loss: 477.68045 | validation -> loss: 302.99033 | accuracy: 91.104050 | precision: 82.885902 | recall: 98.015877 | f2: 94.563553
2023-05-23 16:03:29,851 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 15 | train -> loss: 451.46235 | validation -> loss: 188.07492 | accuracy: 94.201752 | precision: 91.362762 | recall: 94.444443 | f2: 93.811592
2023-05-23 16:03:34,573 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 16 | train -> loss: 437.20056 | validation -> loss: 195.81973 | accuracy: 93.486893 | precision: 94.893616 | recall: 88.492065 | f2: 89.702332
2023-05-23 16:03:39,308 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 17 | train -> loss: 456.28902 | validation -> loss: 197.11157 | accuracy: 93.884033 | precision: 89.174309 | recall: 96.428574 | f2: 94.884811
2023-05-23 16:03:44,041 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 18 | train -> loss: 402.61070 | validation -> loss: 188.84724 | accuracy: 94.201752 | precision: 93.186371 | recall: 92.261902 | f2: 92.445328
2023-05-23 16:03:48,834 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 19 | train -> loss: 400.38463 | validation -> loss: 183.40085 | accuracy: 94.360603 | precision: 93.561371 | recall: 92.261902 | f2: 92.518906
2023-05-23 16:03:53,585 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 20 | train -> loss: 375.67932 | validation -> loss: 216.98001 | accuracy: 93.725182 | precision: 88.426765 | recall: 97.023811 | f2: 95.173225
2023-05-23 16:03:58,400 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 21 | train -> loss: 352.23328 | validation -> loss: 175.50284 | accuracy: 94.598892 | precision: 91.923073 | recall: 94.841270 | f2: 94.242897
2023-05-23 16:04:03,328 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 22 | train -> loss: 421.92793 | validation -> loss: 239.42381 | accuracy: 91.421768 | precision: 95.412842 | recall: 82.539680 | f2: 84.828712
2023-05-23 16:04:08,080 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 23 | train -> loss: 478.72886 | validation -> loss: 346.73932 | accuracy: 83.955521 | precision: 96.036583 | recall: 62.500000 | f2: 67.192833
2023-05-23 16:04:12,313 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 24 | train -> loss: 420.60129 | validation -> loss: 190.50256 | accuracy: 94.201752 | precision: 93.890022 | recall: 91.468254 | f2: 91.942558
2023-05-23 16:04:17,936 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 25 | train -> loss: 375.32339 | validation -> loss: 215.61830 | accuracy: 93.328041 | precision: 95.652176 | recall: 87.301590 | f2: 88.852989
2023-05-23 16:04:23,498 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 26 | train -> loss: 391.54670 | validation -> loss: 193.70168 | accuracy: 94.042892 | precision: 95.348831 | recall: 89.484123 | f2: 90.598640
2023-05-23 16:04:28,044 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 27 | train -> loss: 361.78085 | validation -> loss: 253.17946 | accuracy: 93.010323 | precision: 86.619720 | recall: 97.619041 | f2: 95.201233
2023-05-23 16:04:32,773 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 28 | train -> loss: 365.52417 | validation -> loss: 211.50520 | accuracy: 94.281174 | precision: 90.298508 | recall: 96.031746 | f2: 94.827583
2023-05-23 16:04:37,443 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 29 | train -> loss: 345.17559 | validation -> loss: 187.57375 | accuracy: 93.804611 | precision: 94.560669 | recall: 89.682541 | f2: 90.617485
2023-05-23 16:04:42,077 | root | INFO | ann.py learn @ 101 : fold: 3 | epoch: 30 | Learning rate changed from: 0.005 -> 0.00125
2023-05-23 16:04:42,216 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 30 | train -> loss: 386.82561 | validation -> loss: 242.67970 | accuracy: 90.865768 | precision: 95.764709 | recall: 80.753967 | f2: 83.367470
2023-05-23 16:04:47,041 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 31 | train -> loss: 258.27188 | validation -> loss: 190.94298 | accuracy: 94.519463 | precision: 92.563599 | recall: 93.849205 | f2: 93.589233
2023-05-23 16:04:51,947 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 32 | train -> loss: 257.26004 | validation -> loss: 186.93369 | accuracy: 94.678322 | precision: 92.759293 | recall: 94.047615 | f2: 93.787094
2023-05-23 16:04:56,749 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 33 | train -> loss: 246.66946 | validation -> loss: 189.03238 | accuracy: 94.281174 | precision: 91.538460 | recall: 94.444443 | f2: 93.848579
2023-05-23 16:05:01,683 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 34 | train -> loss: 242.75435 | validation -> loss: 186.61478 | accuracy: 94.281174 | precision: 91.698845 | recall: 94.246033 | f2: 93.725334
2023-05-23 16:05:06,277 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 35 | train -> loss: 244.50038 | validation -> loss: 183.30760 | accuracy: 94.440033 | precision: 92.054268 | recall: 94.246033 | f2: 93.799370
2023-05-23 16:05:10,656 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 36 | train -> loss: 235.02800 | validation -> loss: 189.67369 | accuracy: 94.440033 | precision: 92.217896 | recall: 94.047615 | f2: 93.675888
2023-05-23 16:05:16,650 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 37 | train -> loss: 237.54753 | validation -> loss: 195.66107 | accuracy: 94.678322 | precision: 91.304352 | recall: 95.833328 | f2: 94.891945
2023-05-23 16:05:22,502 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 38 | train -> loss: 242.23278 | validation -> loss: 203.27779 | accuracy: 94.360603 | precision: 90.316574 | recall: 96.230164 | f2: 94.986290
2023-05-23 16:05:27,385 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 39 | train -> loss: 235.62091 | validation -> loss: 248.93622 | accuracy: 93.328041 | precision: 87.102470 | recall: 97.817459 | f2: 95.468628
2023-05-23 16:05:32,151 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 40 | train -> loss: 239.96173 | validation -> loss: 192.12068 | accuracy: 94.598892 | precision: 91.444870 | recall: 95.436508 | f2: 94.610542
2023-05-23 16:05:36,732 | root | INFO | ann.py learn @ 101 : fold: 3 | epoch: 41 | Learning rate changed from: 0.00125 -> 0.0003125
2023-05-23 16:05:36,874 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 41 | train -> loss: 227.25828 | validation -> loss: 186.49365 | accuracy: 94.519463 | precision: 92.563599 | recall: 93.849205 | f2: 93.589233
2023-05-23 16:05:41,754 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 42 | train -> loss: 209.78451 | validation -> loss: 186.48552 | accuracy: 94.916603 | precision: 94.715446 | recall: 92.460320 | f2: 92.902718
2023-05-23 16:05:46,524 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 43 | train -> loss: 209.82393 | validation -> loss: 188.05798 | accuracy: 94.837173 | precision: 92.292870 | recall: 95.039680 | f2: 94.477318
2023-05-23 16:05:51,328 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 44 | train -> loss: 209.51160 | validation -> loss: 185.92892 | accuracy: 94.440033 | precision: 92.217896 | recall: 94.047615 | f2: 93.675888
2023-05-23 16:05:56,008 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 45 | train -> loss: 209.92437 | validation -> loss: 192.23993 | accuracy: 94.598892 | precision: 91.444870 | recall: 95.436508 | f2: 94.610542
2023-05-23 16:06:00,742 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 46 | train -> loss: 209.26673 | validation -> loss: 182.81593 | accuracy: 94.757744 | precision: 93.625496 | recall: 93.253967 | f2: 93.328041
2023-05-23 16:06:05,103 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 47 | train -> loss: 207.67151 | validation -> loss: 183.62985 | accuracy: 94.996033 | precision: 93.663368 | recall: 93.849205 | f2: 93.811974
2023-05-23 16:06:11,506 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 48 | train -> loss: 208.09482 | validation -> loss: 186.83086 | accuracy: 94.519463 | precision: 92.233009 | recall: 94.246033 | f2: 93.836426
2023-05-23 16:06:16,913 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 49 | train -> loss: 207.22675 | validation -> loss: 182.96149 | accuracy: 94.678322 | precision: 92.927307 | recall: 93.849205 | f2: 93.663368
2023-05-23 16:06:21,799 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 50 | train -> loss: 206.75138 | validation -> loss: 188.91055 | accuracy: 94.678322 | precision: 91.938576 | recall: 95.039680 | f2: 94.402840
2023-05-23 16:06:26,702 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 51 | train -> loss: 205.92068 | validation -> loss: 182.88316 | accuracy: 94.757744 | precision: 93.110237 | recall: 93.849205 | f2: 93.700478
2023-05-23 16:06:31,599 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 52 | train -> loss: 205.79390 | validation -> loss: 185.81544 | accuracy: 94.598892 | precision: 92.248062 | recall: 94.444443 | f2: 93.996841
2023-05-23 16:06:36,308 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 53 | train -> loss: 203.91650 | validation -> loss: 182.39380 | accuracy: 94.757744 | precision: 93.110237 | recall: 93.849205 | f2: 93.700478
2023-05-23 16:06:41,102 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 54 | train -> loss: 204.10658 | validation -> loss: 188.86147 | accuracy: 94.837173 | precision: 92.292870 | recall: 95.039680 | f2: 94.477318
2023-05-23 16:06:45,927 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 55 | train -> loss: 206.38163 | validation -> loss: 184.59354 | accuracy: 94.598892 | precision: 92.578125 | recall: 94.047615 | f2: 93.750000
2023-05-23 16:06:50,759 | root | INFO | ann.py learn @ 101 : fold: 3 | epoch: 56 | Learning rate changed from: 0.0003125 -> 7.8125e-05
2023-05-23 16:06:50,872 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 56 | train -> loss: 203.11073 | validation -> loss: 188.59094 | accuracy: 94.757744 | precision: 92.277992 | recall: 94.841270 | f2: 94.317284
2023-05-23 16:06:55,402 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 57 | train -> loss: 199.18191 | validation -> loss: 188.63594 | accuracy: 94.837173 | precision: 92.292870 | recall: 95.039680 | f2: 94.477318
2023-05-23 16:06:59,752 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 58 | train -> loss: 198.56186 | validation -> loss: 186.54817 | accuracy: 94.678322 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 16:07:06,098 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 59 | train -> loss: 198.52134 | validation -> loss: 183.08386 | accuracy: 94.757744 | precision: 93.110237 | recall: 93.849205 | f2: 93.700478
2023-05-23 16:07:11,425 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 60 | train -> loss: 197.49420 | validation -> loss: 185.66469 | accuracy: 94.678322 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 16:07:16,578 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 61 | train -> loss: 197.59093 | validation -> loss: 187.06677 | accuracy: 94.757744 | precision: 92.277992 | recall: 94.841270 | f2: 94.317284
2023-05-23 16:07:21,480 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 62 | train -> loss: 198.19399 | validation -> loss: 186.15022 | accuracy: 94.678322 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 16:07:26,193 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 63 | train -> loss: 197.72794 | validation -> loss: 183.04701 | accuracy: 94.757744 | precision: 93.110237 | recall: 93.849205 | f2: 93.700478
2023-05-23 16:07:31,108 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 64 | train -> loss: 197.25104 | validation -> loss: 185.14519 | accuracy: 94.598892 | precision: 92.248062 | recall: 94.444443 | f2: 93.996841
2023-05-23 16:07:35,863 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 65 | train -> loss: 197.69233 | validation -> loss: 184.60193 | accuracy: 94.598892 | precision: 92.412453 | recall: 94.246033 | f2: 93.873520
2023-05-23 16:07:40,766 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 66 | train -> loss: 197.11347 | validation -> loss: 185.80835 | accuracy: 94.678322 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 16:07:45,345 | root | INFO | ann.py learn @ 101 : fold: 3 | epoch: 67 | Learning rate changed from: 7.8125e-05 -> 1.953125e-05
2023-05-23 16:07:45,458 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 67 | train -> loss: 197.81215 | validation -> loss: 186.20961 | accuracy: 94.678322 | precision: 92.263054 | recall: 94.642860 | f2: 94.157120
2023-05-23 16:07:49,923 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 68 | train -> loss: 196.22329 | validation -> loss: 184.86903 | accuracy: 94.519463 | precision: 92.233009 | recall: 94.246033 | f2: 93.836426
2023-05-23 16:07:54,558 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 69 | train -> loss: 195.80873 | validation -> loss: 185.35034 | accuracy: 94.598892 | precision: 92.248062 | recall: 94.444443 | f2: 93.996841
2023-05-23 16:08:01,147 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 70 | train -> loss: 195.63458 | validation -> loss: 183.79941 | accuracy: 94.757744 | precision: 92.941177 | recall: 94.047615 | f2: 93.824226
2023-05-23 16:08:06,136 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 71 | train -> loss: 195.75127 | validation -> loss: 185.33916 | accuracy: 94.598892 | precision: 92.248062 | recall: 94.444443 | f2: 93.996841
2023-05-23 16:08:10,970 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 72 | train -> loss: 195.98601 | validation -> loss: 185.00467 | accuracy: 94.519463 | precision: 92.233009 | recall: 94.246033 | f2: 93.836426
2023-05-23 16:08:15,715 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 73 | train -> loss: 195.58029 | validation -> loss: 183.70012 | accuracy: 94.757744 | precision: 92.941177 | recall: 94.047615 | f2: 93.824226
2023-05-23 16:08:20,400 | root | INFO | ann.py learn @ 124 : fold: 3 | epoch: 74 | train -> loss: 195.83365 | validation -> loss: 184.00375 | accuracy: 94.598892 | precision: 92.578125 | recall: 94.047615 | f2: 93.750000
2023-05-23 16:08:20,410 | root | INFO | ann.py save @ 176 : saving model at output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/weights/f3/model_fold3.pth
2023-05-23 16:08:20,929 | root | INFO | ann.py learn @ 143 : best model of cross validation for current training phase: fold #2 with metric value of '0.9722222089767456'
2023-05-23 16:08:20,949 | root | INFO | main.py run @ 84 : started new command `test` of session `balanced-v2-04`
2023-05-23 16:08:20,959 | root | INFO | dataset.py preprocess @ 189 : trying to load tokens from file
2023-05-23 16:08:21,259 | root | INFO | dataset.py __vectorize__ @ 103 : loading vectors from file
2023-05-23 16:08:27,809 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-23 16:08:27,880 | root | INFO | ann.py __init__ @ 213 : dimension list of nodes: [32, 1]
2023-05-23 16:08:27,880 | root | INFO | ann.py __init__ @ 214 : dropout list: [0.0]
2023-05-23 16:08:28,661 | root | INFO | ann.py test @ 168 : predictions are saved at output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/preds.pkl.
2023-05-23 16:08:28,671 | root | INFO | ann.py test @ 171 : targets are saved at output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/targets.pkl.
2023-05-23 16:08:28,671 | root | WARNING | main.py run @ 83 : no dataset was specified.
2023-05-23 16:08:28,671 | root | INFO | main.py run @ 84 : started new command `eval` of session `balanced-v2-04`
2023-05-23 16:08:28,671 | root | INFO | ann.py __init__ @ 213 : dimension list of nodes: [32, 1]
2023-05-23 16:08:28,671 | root | INFO | ann.py __init__ @ 214 : dropout list: [0.0]
2023-05-23 16:08:29,191 | root | INFO | baseline.py evaluate @ 67 : saving ROC curve at: output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/ROC-curve.png
2023-05-23 16:08:29,997 | root | INFO | baseline.py evaluate @ 74 : saving precision-recall curve at: output/05-23-2023-15-44-08-balanced-v2-04/ann/conversation-bow/rr.idr-0.005-32.1-0.0/precision-recall-curve.png
2023-05-23 16:08:30,015 | root | INFO | baseline.py evaluate @ 77 : test set -> AUCROC: 0.9805629 | AUCPR: 0.9581877 | accuracy: 0.9426247 | precision: 0.9146374 | recall: 0.9403026
