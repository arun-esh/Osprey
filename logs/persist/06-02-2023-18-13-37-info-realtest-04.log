2023-06-02 18:13:37,729 | root | INFO | main.py run @ 50 : processing unit: cuda
2023-06-02 18:13:37,730 | root | INFO | main.py run @ 68 : train dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/train.csv', 'output_path': 'data/preprocessed/dataset-v2/', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-06-02 18:13:37,730 | root | INFO | main.py run @ 69 : test dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/test.csv', 'output_path': 'data/preprocessed/dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-06-02 18:13:37,731 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,732 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,815 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-06-02 18:13:37,816 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-test-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-06-02 18:13:37,816 | root | INFO | main.py run @ 68 : train dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,817 | root | INFO | main.py run @ 69 : test dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,818 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,818 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,819 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,820 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,820 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,821 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,821 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,822 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,823 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,823 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,824 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,824 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,825 | root | INFO | main.py run @ 68 : train dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,825 | root | INFO | main.py run @ 69 : test dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,828 | root | INFO | main.py run @ 68 : train dataset `temporal-sequential-conversation-v2-dataset-onehot-04`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,828 | root | INFO | main.py run @ 69 : test dataset `temporal-sequential-conversation-v2-dataset-onehot-04`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,831 | root | INFO | main.py run @ 68 : train dataset `temporal-sequential-conversation-v2-dataset-onehot-03`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-03.csv', 'output_path': 'data/preprocessed/sequential-v2-03/', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,832 | root | INFO | main.py run @ 69 : test dataset `temporal-sequential-conversation-v2-dataset-onehot-03`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-03.csv', 'output_path': 'data/preprocessed/sequential-v2-03/test-', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,834 | root | INFO | main.py run @ 68 : train dataset `temporal-sequential-conversation-v2-dataset-onehot-02`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-02.csv', 'output_path': 'data/preprocessed/sequential-v2-02/', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 11000}
2023-06-02 18:13:37,834 | root | INFO | main.py run @ 69 : test dataset `temporal-sequential-conversation-v2-dataset-onehot-02`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-02.csv', 'output_path': 'data/preprocessed/sequential-v2-02/test-', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 11000}
2023-06-02 18:13:37,836 | root | INFO | main.py run @ 68 : train dataset `temporal-sequential-conversation-v2-dataset-onehot-01`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-01.csv', 'output_path': 'data/preprocessed/sequential-v2-01/', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,837 | root | INFO | main.py run @ 69 : test dataset `temporal-sequential-conversation-v2-dataset-onehot-01`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-01.csv', 'output_path': 'data/preprocessed/sequential-v2-01/test-', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,839 | root | INFO | main.py run @ 68 : train dataset `temporal-sequential-conversation-v2-dataset-onehot-03-realtest`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-03.csv', 'output_path': 'data/preprocessed/sequential-v2-03/', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,840 | root | INFO | main.py run @ 69 : test dataset `temporal-sequential-conversation-v2-dataset-onehot-03-realtest`, shortname: `temporal-sequential` kwargs -> {'data_path': 'data/dataset-v2/test.csv', 'output_path': 'data/preprocessed/sequential-v2/test-', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,842 | root | INFO | main.py run @ 68 : train dataset `sequential-conversation-v2-dataset-onehot-03`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-03.csv', 'output_path': 'data/preprocessed/sequential-v2-03/', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,842 | root | INFO | main.py run @ 69 : test dataset `sequential-conversation-v2-dataset-onehot-03`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-03.csv', 'output_path': 'data/preprocessed/sequential-v2-03/test-', 'load_from_pkl': True, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 13000}
2023-06-02 18:13:37,844 | root | INFO | main.py run @ 68 : train dataset `sequential-conversation-v2-dataset-onehot-02`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-02.csv', 'output_path': 'data/preprocessed/sequential-v2-02/', 'load_from_pkl': False, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 7500}
2023-06-02 18:13:37,845 | root | INFO | main.py run @ 69 : test dataset `sequential-conversation-v2-dataset-onehot-02`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-02.csv', 'output_path': 'data/preprocessed/sequential-v2-02/test-', 'load_from_pkl': False, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 7500}
2023-06-02 18:13:37,847 | root | INFO | main.py run @ 68 : train dataset `sequential-conversation-v2-dataset-onehot-01`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-01.csv', 'output_path': 'data/preprocessed/sequential-v2-01/', 'load_from_pkl': False, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 7500}
2023-06-02 18:13:37,848 | root | INFO | main.py run @ 69 : test dataset `sequential-conversation-v2-dataset-onehot-01`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-01.csv', 'output_path': 'data/preprocessed/sequential-v2-01/test-', 'load_from_pkl': False, 'preprocessings': ['sw', 'rr', 'idr'], 'persist_data': True, 'vector_size': 7500}
2023-06-02 18:13:37,849 | root | INFO | main.py run @ 68 : train dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,849 | root | INFO | main.py run @ 69 : test dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,850 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,850 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-06-02 18:13:37,851 | root | INFO | main.py run @ 68 : train dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,851 | root | INFO | main.py run @ 69 : test dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,852 | root | INFO | main.py run @ 68 : train dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-train-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,853 | root | INFO | main.py run @ 69 : test dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-test-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-06-02 18:13:37,853 | root | INFO | main.py run @ 73 : started new session: lstm-balanced-v2-04-temporal-realtest
2023-06-02 18:13:37,853 | root | INFO | main.py create_model_configs @ 37 : activation module kwargs: {}
2023-06-02 18:13:37,855 | root | INFO | main.py create_model_configs @ 38 : loss module kwargs: {'reduction': 'sum', 'pos_weight': tensor(2.3330)}
2023-06-02 18:13:37,856 | root | INFO | main.py run @ 84 : started new command `test` of session `lstm-balanced-v2-04-temporal-realtest`
2023-06-02 18:13:37,856 | root | INFO | dataset.py preprocess @ 582 : generating tokens from scratch
2023-06-02 18:14:11,793 | root | INFO | dataset.py preprocess @ 585 : applying preprocessing modules
2023-06-02 18:14:11,794 | root | INFO | dataset.py preprocess @ 587 : applying nltk stopwords remover
2023-06-02 18:21:05,629 | root | INFO | dataset.py preprocess @ 587 : applying repetition remover
2023-06-02 18:21:07,828 | root | INFO | dataset.py preprocess @ 587 : applying author id replacer
2023-06-02 18:21:08,484 | root | INFO | dataset.py init_encoder @ 526 : started generating bag of words vector encoder
2023-06-02 18:21:09,309 | root | INFO | dataset.py __vectorize__ @ 109 : trying to create vectors from scratch
2023-06-02 18:21:40,923 | root | INFO | dataset.py prepare @ 223 : saving tokens as pickle at data/preprocessed/sequential-v2-03/temporal-sequential/psw.rr.idr-v13002/tokens.pkl
2023-06-02 18:21:41,272 | root | INFO | dataset.py prepare @ 228 : saving vectors as pickle at data/preprocessed/sequential-v2-03/temporal-sequential/psw.rr.idr-v13002/vectors.pkl
2023-06-02 18:21:48,962 | root | INFO | dataset.py prepare @ 233 : saving encoder as pickle at data/preprocessed/sequential-v2-03/temporal-sequential/psw.rr.idr-v13002/encoder.pkl
2023-06-02 18:21:57,735 | root | INFO | dataset.py prepare @ 242 : data preparation finished
2023-06-02 18:21:57,784 | root | INFO | dataset.py preprocess @ 582 : generating tokens from scratch
2023-06-02 18:26:16,488 | root | INFO | dataset.py preprocess @ 585 : applying preprocessing modules
2023-06-02 18:26:16,489 | root | INFO | dataset.py preprocess @ 587 : applying nltk stopwords remover
2023-06-02 18:50:37,822 | root | INFO | dataset.py preprocess @ 587 : applying repetition remover
2023-06-02 18:50:56,645 | root | INFO | dataset.py preprocess @ 587 : applying author id replacer
2023-06-02 18:51:03,005 | root | INFO | dataset.py __vectorize__ @ 109 : trying to create vectors from scratch
2023-06-02 18:54:55,152 | root | INFO | dataset.py prepare @ 223 : saving tokens as pickle at data/preprocessed/sequential-v2/test-temporal-sequential/psw.rr.idr-v13002/tokens.pkl
2023-06-02 18:54:58,535 | root | INFO | dataset.py prepare @ 228 : saving vectors as pickle at data/preprocessed/sequential-v2/test-temporal-sequential/psw.rr.idr-v13002/vectors.pkl
2023-06-02 18:55:52,091 | root | INFO | dataset.py prepare @ 242 : data preparation finished
2023-06-02 18:55:52,519 | root | INFO | main.py run @ 104 : dataset short-name: temporal-sequential/psw.rr.idr-v13002
2023-06-02 18:55:56,317 | root | INFO | rnn.py load_params @ 204 : loaded model weights from file: output\06-01-2023-17-54-36-lstm-balanced-v2-04-temporal\lstm\temporal-sequential\psw.rr.idr-v13002-lr0.000500-h1024-l1\weights\best_model.pth
2023-06-02 19:04:44,873 | root | INFO | rnn.py test @ 192 : predictions are saved at: output/06-02-2023-18-13-37-lstm-balanced-v2-04-temporal-realtest/lstm/temporal-sequential/psw.rr.idr-v13002-lr0.000900-h1024-l1/preds.pkl
2023-06-02 19:04:44,877 | root | INFO | rnn.py test @ 195 : targets are saved at: output/06-02-2023-18-13-37-lstm-balanced-v2-04-temporal-realtest/lstm/temporal-sequential/psw.rr.idr-v13002-lr0.000900-h1024-l1/targets.pkl
2023-06-02 19:04:44,879 | root | WARNING | main.py run @ 83 : no dataset was specified.
2023-06-02 19:04:44,879 | root | INFO | main.py run @ 84 : started new command `eval` of session `lstm-balanced-v2-04-temporal-realtest`
2023-06-02 19:04:49,919 | root | INFO | baseline.py evaluate @ 67 : saving ROC curve at: output/06-02-2023-18-13-37-lstm-balanced-v2-04-temporal-realtest/lstm/temporal-sequential/psw.rr.idr-v13002-lr0.000900-h1024-l1/ROC-curve.png
2023-06-02 19:04:54,961 | root | INFO | baseline.py evaluate @ 74 : saving precision-recall curve at: output/06-02-2023-18-13-37-lstm-balanced-v2-04-temporal-realtest/lstm/temporal-sequential/psw.rr.idr-v13002-lr0.000900-h1024-l1/precision-recall-curve.png
2023-06-02 19:04:54,994 | root | INFO | baseline.py evaluate @ 77 : test set -> AUCROC: 0.7768513 | AUCPR: 0.1034566 | accuracy: 0.6849118 | precision: 0.7382928 | recall: 0.0544611
