2023-05-24 13:12:01,144 | root | INFO | main.py run @ 50 : processing unit: cuda
2023-05-24 13:12:01,145 | root | INFO | main.py run @ 68 : train dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/train.csv', 'output_path': 'data/preprocessed/dataset-v2/', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-05-24 13:12:01,146 | root | INFO | main.py run @ 69 : test dataset `v2-dataset-onehot`, shortname: `bow` kwargs -> {'data_path': 'data/dataset-v2/test.csv', 'output_path': 'data/preprocessed/dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': [], 'persist_data': False}
2023-05-24 13:12:01,148 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,149 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,247 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-05-24 13:12:01,249 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/toy-test-', 'load_from_pkl': True, 'preprocessings': ['pr', 'sw', 'rr'], 'persist_data': True}
2023-05-24 13:12:01,250 | root | INFO | main.py run @ 68 : train dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,251 | root | INFO | main.py run @ 69 : test dataset `cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test.csv', 'output_path': 'data/preprocessed/conversation-dataset-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,252 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,253 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-balanced-04`, shortname: `conversation-bow-cleaned` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-test-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,254 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/train-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,254 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/test-v2.csv', 'output_path': 'data/preprocessed/conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,256 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,257 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,257 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,258 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-03`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-03.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-03/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,260 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,262 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-02`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-02.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-02/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,263 | root | INFO | main.py run @ 68 : train dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,264 | root | INFO | main.py run @ 69 : test dataset `conversation-v2-dataset-onehot-raw-balanced-01`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-01.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-01/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,265 | root | INFO | main.py run @ 68 : train dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/train-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,266 | root | INFO | main.py run @ 69 : test dataset `sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/test-04.csv', 'output_path': 'data/preprocessed/sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,267 | root | INFO | main.py run @ 68 : train dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,268 | root | INFO | main.py run @ 69 : test dataset `conversation-with-index-v2-dataset-onehot-raw-balanced-04`, shortname: `conversation-bow-with-triple` kwargs -> {'data_path': 'data/dataset-v2/conversation/balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/conversation-balanced-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,269 | root | INFO | main.py run @ 68 : train dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,270 | root | INFO | main.py run @ 69 : test dataset `toy-conversation-v2-dataset-onehot-raw`, shortname: `conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': True, 'preprocessings': ['rr', 'idr'], 'persist_data': True}
2023-05-24 13:12:01,270 | root | INFO | main.py run @ 68 : train dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-train-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,271 | root | INFO | main.py run @ 69 : test dataset `toy-cnn-conversation-v2-dataset-onehot`, shortname: `cnn-conversation-bow` kwargs -> {'data_path': 'data/dataset-v2/conversation/toy-balanced-test-v2-04.csv', 'output_path': 'data/preprocessed/toy-conversation-v2/test-', 'load_from_pkl': False, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,272 | root | INFO | main.py run @ 68 : train dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-train-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,273 | root | INFO | main.py run @ 69 : test dataset `toy-sequential-conversation-v2-dataset-onehot`, shortname: `basic-sequential` kwargs -> {'data_path': 'data/dataset-v2/toy-test-04.csv', 'output_path': 'data/preprocessed/toy-sequential-v2-04/test-', 'load_from_pkl': True, 'preprocessings': ['rr'], 'persist_data': True}
2023-05-24 13:12:01,274 | root | INFO | main.py run @ 73 : started new session: rnn-balanced-v2-04
2023-05-24 13:12:01,274 | root | INFO | main.py create_model_configs @ 37 : activation module kwargs: {}
2023-05-24 13:12:01,277 | root | INFO | main.py create_model_configs @ 38 : loss module kwargs: {'reduction': 'sum', 'pos_weight': tensor(1.2000)}
2023-05-24 13:12:01,278 | root | INFO | main.py run @ 84 : started new command `train` of session `rnn-balanced-v2-04`
2023-05-24 13:12:01,279 | root | INFO | dataset.py preprocess @ 503 : trying to load tokens from file
2023-05-24 13:12:09,254 | root | INFO | dataset.py __vectorize__ @ 103 : loading vectors from file
2023-05-24 13:12:11,628 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-24 13:12:13,697 | root | INFO | dataset.py split_dataset_by_label @ 158 : loading splits from: data/preprocessed/sequential-v2-04/basic-sequential/rr.idr/splits-n5stratified.pkl
2023-05-24 13:12:20,028 | root | INFO | rnn.py learn @ 78 : training phase started
2023-05-24 13:12:20,029 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 13:12:20,032 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD17FCAC0>
2023-05-24 13:12:20,033 | root | INFO | rnn.py learn @ 85 : fetching data for fold #0
2023-05-24 13:12:20,035 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 13:12:20,035 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 13:12:20,037 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 13:12:20,037 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 13:13:05,904 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 1 | train -> loss: 3101.63367 | validation -> loss: 763.76338 | accuracy: 49.404762 | precision: 39.059303 | recall: 47.394543 | f2: 45.454548
2023-05-24 13:13:47,773 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 2 | train -> loss: 3054.16564 | validation -> loss: 760.06765 | accuracy: 52.380955 | precision: 42.158859 | recall: 51.364761 | f2: 49.215405
2023-05-24 13:14:30,465 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 3 | train -> loss: 3038.32057 | validation -> loss: 762.44096 | accuracy: 47.321430 | precision: 39.710609 | recall: 61.290325 | f2: 55.282001
2023-05-24 13:15:12,435 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 4 | train -> loss: 3042.50430 | validation -> loss: 759.09449 | accuracy: 48.412697 | precision: 37.086094 | recall: 41.687347 | f2: 40.677963
2023-05-24 13:15:55,483 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 5 | train -> loss: 3029.07000 | validation -> loss: 750.32949 | accuracy: 55.059521 | precision: 41.438354 | recall: 30.024815 | f2: 31.775209
2023-05-24 13:16:38,816 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 6 | train -> loss: 3023.03300 | validation -> loss: 764.17342 | accuracy: 54.464287 | precision: 41.860466 | recall: 35.732010 | f2: 36.809818
2023-05-24 13:17:21,098 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 7 | train -> loss: 3030.51405 | validation -> loss: 748.65242 | accuracy: 60.317463 | precision: 100.000000 | recall: 0.744417 | f2: 0.928793
2023-05-24 13:18:03,471 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 8 | train -> loss: 3034.33300 | validation -> loss: 767.62772 | accuracy: 49.404762 | precision: 38.641186 | recall: 45.161289 | f2: 43.686989
2023-05-24 13:18:45,346 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 9 | train -> loss: 3030.19392 | validation -> loss: 753.14942 | accuracy: 55.555557 | precision: 35.483871 | recall: 13.647643 | f2: 15.563101
2023-05-24 13:19:27,029 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 10 | train -> loss: 3025.76178 | validation -> loss: 762.51860 | accuracy: 56.547619 | precision: 42.222221 | recall: 23.573200 | f2: 25.857376
2023-05-24 13:20:08,683 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 11 | train -> loss: 3027.78586 | validation -> loss: 745.22149 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.248139 | f2: 0.309981
2023-05-24 13:20:50,358 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 12 | train -> loss: 3025.73553 | validation -> loss: 748.35711 | accuracy: 59.325397 | precision: 46.153847 | recall: 10.421837 | f2: 12.331181
2023-05-24 13:21:31,972 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 13 | train -> loss: 3030.49293 | validation -> loss: 748.46545 | accuracy: 56.746029 | precision: 44.554455 | recall: 33.498756 | f2: 35.248039
2023-05-24 13:22:13,758 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 14 | train -> loss: 3033.28862 | validation -> loss: 758.72106 | accuracy: 57.738094 | precision: 36.781609 | recall: 7.940446 | f2: 9.417304
2023-05-24 13:22:56,093 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 15 | train -> loss: 3017.56750 | validation -> loss: 755.53147 | accuracy: 55.753971 | precision: 37.572254 | recall: 16.129032 | f2: 18.207283
2023-05-24 13:23:38,898 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 16 | train -> loss: 3023.59967 | validation -> loss: 749.97849 | accuracy: 57.341270 | precision: 42.285713 | recall: 18.362282 | f2: 20.705091
2023-05-24 13:24:21,327 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 17 | train -> loss: 3024.36155 | validation -> loss: 750.05251 | accuracy: 55.158730 | precision: 33.557049 | recall: 12.406948 | f2: 14.196480
2023-05-24 13:25:03,246 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 18 | train -> loss: 3037.67128 | validation -> loss: 763.90608 | accuracy: 51.785713 | precision: 40.459770 | recall: 43.672459 | f2: 42.989738
2023-05-24 13:25:45,873 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 19 | train -> loss: 3027.90207 | validation -> loss: 773.04597 | accuracy: 49.404762 | precision: 36.455696 | recall: 35.732010 | f2: 35.874439
2023-05-24 13:26:28,584 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 20 | train -> loss: 3035.18847 | validation -> loss: 765.92275 | accuracy: 49.900795 | precision: 38.028168 | recall: 40.198509 | f2: 39.744846
2023-05-24 13:27:11,780 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 21 | train -> loss: 3025.96291 | validation -> loss: 749.08456 | accuracy: 57.341270 | precision: 35.483871 | recall: 8.188586 | f2: 9.677419
2023-05-24 13:27:11,781 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 13:27:54,168 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 22 | train -> loss: 2990.87193 | validation -> loss: 745.60434 | accuracy: 61.210316 | precision: 100.000000 | recall: 2.977668 | f2: 3.694581
2023-05-24 13:28:36,434 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 23 | train -> loss: 2987.37619 | validation -> loss: 747.94118 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.248139 | f2: 0.309981
2023-05-24 13:29:18,893 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 24 | train -> loss: 2991.65653 | validation -> loss: 746.90238 | accuracy: 61.111111 | precision: 82.352943 | recall: 3.473945 | f2: 4.297115
2023-05-24 13:30:02,128 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 25 | train -> loss: 2981.06166 | validation -> loss: 741.20776 | accuracy: 59.424603 | precision: 48.255814 | recall: 20.595533 | f2: 23.262333
2023-05-24 13:30:45,002 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 26 | train -> loss: 2995.21046 | validation -> loss: 744.36213 | accuracy: 60.317463 | precision: 100.000000 | recall: 0.744417 | f2: 0.928793
2023-05-24 13:31:26,971 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 27 | train -> loss: 2984.62622 | validation -> loss: 744.64933 | accuracy: 60.218258 | precision: 100.000000 | recall: 0.496278 | f2: 0.619579
2023-05-24 13:32:08,819 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 28 | train -> loss: 2985.87725 | validation -> loss: 745.08314 | accuracy: 60.515873 | precision: 100.000000 | recall: 1.240695 | f2: 1.546073
2023-05-24 13:32:51,850 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 29 | train -> loss: 2982.45548 | validation -> loss: 742.41301 | accuracy: 61.210316 | precision: 100.000000 | recall: 2.977668 | f2: 3.694581
2023-05-24 13:33:35,503 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 30 | train -> loss: 2978.59866 | validation -> loss: 746.70681 | accuracy: 61.706345 | precision: 94.736847 | recall: 4.466501 | f2: 5.518087
2023-05-24 13:34:19,429 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 31 | train -> loss: 2973.87559 | validation -> loss: 743.99023 | accuracy: 61.210316 | precision: 100.000000 | recall: 2.977668 | f2: 3.694581
2023-05-24 13:35:02,660 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 32 | train -> loss: 2967.07323 | validation -> loss: 762.43742 | accuracy: 58.134918 | precision: 40.776699 | recall: 10.421837 | f2: 12.244898
2023-05-24 13:35:46,037 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 33 | train -> loss: 2973.03165 | validation -> loss: 741.58647 | accuracy: 61.210316 | precision: 92.857140 | recall: 3.225806 | f2: 3.997540
2023-05-24 13:36:28,070 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 34 | train -> loss: 2967.98488 | validation -> loss: 735.68519 | accuracy: 62.500000 | precision: 93.103447 | recall: 6.699752 | f2: 8.226691
2023-05-24 13:37:12,966 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 35 | train -> loss: 2973.35812 | validation -> loss: 736.06536 | accuracy: 62.698410 | precision: 96.551720 | recall: 6.947891 | f2: 8.531384
2023-05-24 13:37:57,635 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 36 | train -> loss: 2962.36534 | validation -> loss: 744.00026 | accuracy: 62.996029 | precision: 94.117645 | recall: 7.940446 | f2: 9.720535
2023-05-24 13:38:41,786 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 37 | train -> loss: 2960.84947 | validation -> loss: 730.68781 | accuracy: 62.500000 | precision: 87.878784 | recall: 7.196030 | f2: 8.814590
2023-05-24 13:39:25,728 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 38 | train -> loss: 2962.33760 | validation -> loss: 733.80420 | accuracy: 61.309521 | precision: 54.676258 | recall: 18.858561 | f2: 21.701885
2023-05-24 13:40:08,603 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 39 | train -> loss: 2949.66299 | validation -> loss: 740.78977 | accuracy: 61.507935 | precision: 54.437870 | recall: 22.828785 | f2: 25.828186
2023-05-24 13:40:51,851 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 40 | train -> loss: 2936.33686 | validation -> loss: 729.31123 | accuracy: 64.583328 | precision: 97.916672 | recall: 11.662531 | f2: 14.156626
2023-05-24 13:41:35,266 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 41 | train -> loss: 2933.44941 | validation -> loss: 730.52271 | accuracy: 64.583328 | precision: 92.592590 | recall: 12.406948 | f2: 15.006002
2023-05-24 13:42:18,911 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 42 | train -> loss: 2930.73159 | validation -> loss: 730.41828 | accuracy: 64.583328 | precision: 89.655174 | recall: 12.903225 | f2: 15.568863
2023-05-24 13:43:02,518 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 43 | train -> loss: 2928.91786 | validation -> loss: 738.54972 | accuracy: 65.277779 | precision: 98.181824 | recall: 13.399504 | f2: 16.196760
2023-05-24 13:43:45,758 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 44 | train -> loss: 2917.42877 | validation -> loss: 728.31077 | accuracy: 65.773811 | precision: 88.157890 | recall: 16.625311 | f2: 19.845972
2023-05-24 13:44:29,592 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 45 | train -> loss: 2735.57218 | validation -> loss: 554.12361 | accuracy: 79.464287 | precision: 69.599998 | recall: 86.352364 | f2: 82.386360
2023-05-24 13:45:12,790 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 46 | train -> loss: 2615.93390 | validation -> loss: 647.97967 | accuracy: 66.369041 | precision: 54.507042 | recall: 96.029778 | f2: 83.333328
2023-05-24 13:45:56,489 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 47 | train -> loss: 2778.99193 | validation -> loss: 729.53113 | accuracy: 64.484123 | precision: 95.918365 | recall: 11.662531 | f2: 14.148104
2023-05-24 13:45:56,489 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 13:46:39,695 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 48 | train -> loss: 2906.40977 | validation -> loss: 721.58924 | accuracy: 64.980164 | precision: 96.296295 | recall: 12.903225 | f2: 15.606242
2023-05-24 13:47:21,976 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 49 | train -> loss: 2888.68028 | validation -> loss: 732.26103 | accuracy: 64.285713 | precision: 90.566040 | recall: 11.910670 | f2: 14.414414
2023-05-24 13:48:04,322 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 50 | train -> loss: 2882.18105 | validation -> loss: 721.97646 | accuracy: 65.079369 | precision: 94.736847 | recall: 13.399504 | f2: 16.177351
2023-05-24 13:48:48,088 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 51 | train -> loss: 2885.42663 | validation -> loss: 726.19679 | accuracy: 64.682541 | precision: 96.078430 | recall: 12.158809 | f2: 14.732411
2023-05-24 13:49:30,708 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 52 | train -> loss: 2868.74360 | validation -> loss: 712.66904 | accuracy: 65.773811 | precision: 96.774193 | recall: 14.888337 | f2: 17.921146
2023-05-24 13:50:12,931 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 53 | train -> loss: 2848.47991 | validation -> loss: 717.45002 | accuracy: 64.583328 | precision: 87.096771 | recall: 13.399504 | f2: 16.129032
2023-05-24 13:50:56,212 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 54 | train -> loss: 2819.82176 | validation -> loss: 568.81830 | accuracy: 78.273811 | precision: 68.181816 | recall: 85.607941 | f2: 81.444756
2023-05-24 13:51:39,994 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 55 | train -> loss: 2089.88777 | validation -> loss: 475.59343 | accuracy: 84.920631 | precision: 80.535278 | recall: 82.133995 | f2: 81.809196
2023-05-24 13:52:23,064 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 56 | train -> loss: 1986.54775 | validation -> loss: 468.47960 | accuracy: 85.019836 | precision: 80.882355 | recall: 81.885857 | f2: 81.683174
2023-05-24 13:53:05,782 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 57 | train -> loss: 1971.54346 | validation -> loss: 461.46922 | accuracy: 85.218254 | precision: 81.127457 | recall: 82.133995 | f2: 81.930695
2023-05-24 13:53:50,593 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 58 | train -> loss: 1976.53239 | validation -> loss: 459.01955 | accuracy: 85.515877 | precision: 81.728394 | recall: 82.133995 | f2: 82.052551
2023-05-24 13:54:34,061 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 59 | train -> loss: 1937.80539 | validation -> loss: 456.54700 | accuracy: 85.615082 | precision: 82.250000 | recall: 81.637718 | f2: 81.759438
2023-05-24 13:55:17,517 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 60 | train -> loss: 1926.50737 | validation -> loss: 453.62139 | accuracy: 85.515877 | precision: 82.044891 | recall: 81.637718 | f2: 81.718826
2023-05-24 13:56:00,511 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 61 | train -> loss: 1889.19015 | validation -> loss: 439.94096 | accuracy: 86.706345 | precision: 85.117493 | recall: 80.893303 | f2: 81.704262
2023-05-24 13:56:43,706 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 62 | train -> loss: 1869.87363 | validation -> loss: 456.76505 | accuracy: 85.912697 | precision: 85.558578 | recall: 77.915634 | f2: 79.332993
2023-05-24 13:57:27,497 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 63 | train -> loss: 1840.20894 | validation -> loss: 441.96706 | accuracy: 86.607140 | precision: 85.263153 | recall: 80.397018 | f2: 81.325302
2023-05-24 13:58:11,165 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 64 | train -> loss: 1841.87049 | validation -> loss: 467.35933 | accuracy: 85.515877 | precision: 85.205475 | recall: 77.171219 | f2: 78.654526
2023-05-24 13:58:54,353 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 65 | train -> loss: 1905.50220 | validation -> loss: 458.17611 | accuracy: 85.615082 | precision: 81.773399 | recall: 82.382133 | f2: 82.259659
2023-05-24 13:59:37,225 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 66 | train -> loss: 1866.37837 | validation -> loss: 445.25424 | accuracy: 86.011902 | precision: 82.750000 | recall: 82.133995 | f2: 82.256462
2023-05-24 14:00:21,615 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 67 | train -> loss: 1852.00528 | validation -> loss: 448.72550 | accuracy: 85.912697 | precision: 82.382133 | recall: 82.382133 | f2: 82.382133
2023-05-24 14:01:04,806 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 68 | train -> loss: 1835.91001 | validation -> loss: 434.74938 | accuracy: 86.904762 | precision: 84.832909 | recall: 81.885857 | f2: 82.458771
2023-05-24 14:01:48,318 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 69 | train -> loss: 1830.24833 | validation -> loss: 431.79751 | accuracy: 86.805557 | precision: 84.615387 | recall: 81.885857 | f2: 82.417587
2023-05-24 14:02:32,905 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 70 | train -> loss: 1834.43179 | validation -> loss: 455.19356 | accuracy: 85.912697 | precision: 85.175201 | recall: 78.411911 | f2: 79.677254
2023-05-24 14:03:16,836 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 71 | train -> loss: 1814.34569 | validation -> loss: 426.94025 | accuracy: 87.202385 | precision: 84.948982 | recall: 82.630272 | f2: 83.083832
2023-05-24 14:03:59,620 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 72 | train -> loss: 1890.40127 | validation -> loss: 494.68322 | accuracy: 84.821426 | precision: 90.584412 | recall: 69.230774 | f2: 72.656250
2023-05-24 14:04:43,955 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 73 | train -> loss: 2007.10366 | validation -> loss: 487.12208 | accuracy: 85.218254 | precision: 91.233765 | recall: 69.727043 | f2: 73.177078
2023-05-24 14:04:43,956 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 14:05:27,695 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 74 | train -> loss: 1973.22787 | validation -> loss: 482.73173 | accuracy: 85.416672 | precision: 91.290321 | recall: 70.223328 | f2: 73.621223
2023-05-24 14:06:11,413 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 75 | train -> loss: 1957.17862 | validation -> loss: 483.19974 | accuracy: 85.416672 | precision: 91.025635 | recall: 70.471466 | f2: 73.804573
2023-05-24 14:06:54,954 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 76 | train -> loss: 1938.24369 | validation -> loss: 480.71092 | accuracy: 85.416672 | precision: 90.764328 | recall: 70.719604 | f2: 73.987541
2023-05-24 14:07:38,315 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 77 | train -> loss: 1900.97201 | validation -> loss: 476.52759 | accuracy: 85.515877 | precision: 90.536278 | recall: 71.215881 | f2: 74.390877
2023-05-24 14:08:21,233 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 78 | train -> loss: 1898.28027 | validation -> loss: 478.04004 | accuracy: 85.515877 | precision: 90.536278 | recall: 71.215881 | f2: 74.390877
2023-05-24 14:09:03,078 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 79 | train -> loss: 1893.77871 | validation -> loss: 482.09325 | accuracy: 85.317459 | precision: 90.220818 | recall: 70.967743 | f2: 74.131676
2023-05-24 14:09:44,453 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 80 | train -> loss: 1886.63446 | validation -> loss: 477.20002 | accuracy: 85.615082 | precision: 90.312500 | recall: 71.712158 | f2: 74.792961
2023-05-24 14:10:27,012 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 81 | train -> loss: 1889.92442 | validation -> loss: 469.48648 | accuracy: 85.813492 | precision: 90.372673 | recall: 72.208435 | f2: 75.232681
2023-05-24 14:11:09,354 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 82 | train -> loss: 1889.76354 | validation -> loss: 468.41579 | accuracy: 85.813492 | precision: 90.372673 | recall: 72.208435 | f2: 75.232681
2023-05-24 14:11:50,864 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 83 | train -> loss: 1872.77447 | validation -> loss: 471.19877 | accuracy: 85.813492 | precision: 90.372673 | recall: 72.208435 | f2: 75.232681
2023-05-24 14:12:32,274 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 84 | train -> loss: 1886.28203 | validation -> loss: 465.94862 | accuracy: 85.813492 | precision: 90.372673 | recall: 72.208435 | f2: 75.232681
2023-05-24 14:13:14,280 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 85 | train -> loss: 1852.77339 | validation -> loss: 463.51878 | accuracy: 86.011902 | precision: 89.939026 | recall: 73.200996 | f2: 76.030930
2023-05-24 14:13:57,046 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 86 | train -> loss: 1843.63893 | validation -> loss: 468.78333 | accuracy: 85.813492 | precision: 89.634148 | recall: 72.952858 | f2: 75.773201
2023-05-24 14:14:39,142 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 87 | train -> loss: 1849.77591 | validation -> loss: 464.17224 | accuracy: 86.111107 | precision: 89.728096 | recall: 73.697266 | f2: 76.428207
2023-05-24 14:15:20,694 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 88 | train -> loss: 1839.29217 | validation -> loss: 457.71031 | accuracy: 86.111107 | precision: 89.728096 | recall: 73.697266 | f2: 76.428207
2023-05-24 14:16:02,914 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 89 | train -> loss: 1827.35985 | validation -> loss: 458.60904 | accuracy: 86.111107 | precision: 89.489487 | recall: 73.945412 | f2: 76.606682
2023-05-24 14:16:45,187 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 90 | train -> loss: 1813.16693 | validation -> loss: 465.75134 | accuracy: 85.813492 | precision: 89.877304 | recall: 72.704712 | f2: 75.593391
2023-05-24 14:17:27,516 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 91 | train -> loss: 1821.26974 | validation -> loss: 464.06908 | accuracy: 85.912697 | precision: 89.908257 | recall: 72.952858 | f2: 75.812271
2023-05-24 14:18:09,342 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 92 | train -> loss: 1809.99972 | validation -> loss: 459.92020 | accuracy: 86.111107 | precision: 89.969604 | recall: 73.449127 | f2: 76.249352
2023-05-24 14:18:50,494 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 93 | train -> loss: 1812.62281 | validation -> loss: 460.36051 | accuracy: 86.111107 | precision: 89.969604 | recall: 73.449127 | f2: 76.249352
2023-05-24 14:19:32,776 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 94 | train -> loss: 1800.52444 | validation -> loss: 459.19775 | accuracy: 86.111107 | precision: 89.969604 | recall: 73.449127 | f2: 76.249352
2023-05-24 14:20:15,011 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 95 | train -> loss: 1786.77555 | validation -> loss: 459.52935 | accuracy: 86.111107 | precision: 89.728096 | recall: 73.697266 | f2: 76.428207
2023-05-24 14:20:57,450 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 96 | train -> loss: 1768.28786 | validation -> loss: 466.39001 | accuracy: 85.615082 | precision: 88.392860 | recall: 73.697266 | f2: 76.232033
2023-05-24 14:21:39,625 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 97 | train -> loss: 1765.80455 | validation -> loss: 467.10537 | accuracy: 85.714287 | precision: 88.427299 | recall: 73.945412 | f2: 76.449463
2023-05-24 14:22:21,573 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 98 | train -> loss: 1773.80367 | validation -> loss: 471.32377 | accuracy: 85.515877 | precision: 89.296638 | recall: 72.456573 | f2: 75.296547
2023-05-24 14:23:02,871 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 99 | train -> loss: 1763.92711 | validation -> loss: 459.67126 | accuracy: 86.111107 | precision: 89.728096 | recall: 73.697266 | f2: 76.428207
2023-05-24 14:23:02,871 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 14:23:44,620 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 100 | train -> loss: 1752.34937 | validation -> loss: 461.27175 | accuracy: 86.111107 | precision: 89.728096 | recall: 73.697266 | f2: 76.428207
2023-05-24 14:23:44,753 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f0/model_fold0.pth
2023-05-24 14:23:45,582 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 14:23:45,586 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD20D0CD0>
2023-05-24 14:23:45,587 | root | INFO | rnn.py learn @ 85 : fetching data for fold #1
2023-05-24 14:23:45,588 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 14:23:45,589 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 14:23:45,590 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 14:23:45,591 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 14:24:29,112 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 1 | train -> loss: 3122.81654 | validation -> loss: 754.78314 | accuracy: 53.174603 | precision: 40.170940 | recall: 34.987595 | f2: 35.914417
2023-05-24 14:25:12,076 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 2 | train -> loss: 3051.34355 | validation -> loss: 750.52747 | accuracy: 58.928574 | precision: 46.258503 | recall: 16.873449 | f2: 19.329165
2023-05-24 14:25:54,532 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 3 | train -> loss: 3052.69336 | validation -> loss: 755.68977 | accuracy: 49.801590 | precision: 35.158501 | recall: 30.272951 | f2: 31.138336
2023-05-24 14:26:37,195 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 4 | train -> loss: 3037.03815 | validation -> loss: 758.15651 | accuracy: 54.464287 | precision: 41.194969 | recall: 32.506203 | f2: 33.937824
2023-05-24 14:27:19,823 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 5 | train -> loss: 3033.03293 | validation -> loss: 761.08439 | accuracy: 53.769840 | precision: 40.366970 | recall: 32.754345 | f2: 34.038166
2023-05-24 14:28:02,248 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 6 | train -> loss: 3051.75535 | validation -> loss: 746.34586 | accuracy: 58.928574 | precision: 46.308727 | recall: 17.121588 | f2: 19.591141
2023-05-24 14:28:44,028 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 7 | train -> loss: 3023.45461 | validation -> loss: 747.55986 | accuracy: 60.615082 | precision: 87.500000 | recall: 1.736973 | f2: 2.160494
2023-05-24 14:29:26,271 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 8 | train -> loss: 3019.84857 | validation -> loss: 753.77793 | accuracy: 54.960316 | precision: 42.735043 | recall: 37.220844 | f2: 38.206829
2023-05-24 14:30:08,812 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 9 | train -> loss: 3027.52382 | validation -> loss: 756.85817 | accuracy: 49.206348 | precision: 39.334637 | recall: 49.875931 | f2: 47.338669
2023-05-24 14:30:50,616 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 10 | train -> loss: 3036.19357 | validation -> loss: 750.49858 | accuracy: 62.400795 | precision: 92.857140 | recall: 6.451612 | f2: 7.926829
2023-05-24 14:31:33,022 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 11 | train -> loss: 3028.22731 | validation -> loss: 752.35763 | accuracy: 60.218258 | precision: 75.000000 | recall: 0.744417 | f2: 0.928218
2023-05-24 14:32:15,799 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 12 | train -> loss: 3057.65438 | validation -> loss: 746.04658 | accuracy: 60.317463 | precision: 100.000000 | recall: 0.744417 | f2: 0.928793
2023-05-24 14:32:59,276 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 13 | train -> loss: 3020.01870 | validation -> loss: 764.72823 | accuracy: 61.309521 | precision: 93.333336 | recall: 3.473945 | f2: 4.302397
2023-05-24 14:33:42,089 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 14 | train -> loss: 3030.59380 | validation -> loss: 746.42781 | accuracy: 60.019840 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-24 14:34:24,299 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 15 | train -> loss: 3008.61642 | validation -> loss: 748.68702 | accuracy: 60.019840 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-24 14:35:05,413 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 16 | train -> loss: 3015.83726 | validation -> loss: 746.06866 | accuracy: 60.019840 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-24 14:35:49,679 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 17 | train -> loss: 3027.99416 | validation -> loss: 779.36691 | accuracy: 38.690479 | precision: 39.174221 | recall: 96.526054 | f2: 74.664108
2023-05-24 14:36:32,247 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 18 | train -> loss: 3030.11485 | validation -> loss: 746.02066 | accuracy: 61.011906 | precision: 91.666672 | recall: 2.729529 | f2: 3.386699
2023-05-24 14:37:14,849 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 19 | train -> loss: 3019.71359 | validation -> loss: 748.36386 | accuracy: 61.111111 | precision: 92.307693 | recall: 2.977668 | f2: 3.692308
2023-05-24 14:37:58,946 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 20 | train -> loss: 3012.66095 | validation -> loss: 761.42017 | accuracy: 61.011906 | precision: 91.666672 | recall: 2.729529 | f2: 3.386699
2023-05-24 14:38:42,905 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 21 | train -> loss: 3036.15998 | validation -> loss: 748.12291 | accuracy: 60.019840 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-24 14:38:42,905 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 14:39:26,193 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 22 | train -> loss: 2993.68175 | validation -> loss: 745.73367 | accuracy: 61.011906 | precision: 91.666672 | recall: 2.729529 | f2: 3.386699
2023-05-24 14:40:08,086 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 23 | train -> loss: 2994.72000 | validation -> loss: 746.46649 | accuracy: 60.019840 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-24 14:40:50,114 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 24 | train -> loss: 2988.56238 | validation -> loss: 746.33573 | accuracy: 60.019840 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-24 14:41:33,517 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 25 | train -> loss: 2986.73145 | validation -> loss: 747.30047 | accuracy: 60.615082 | precision: 100.000000 | recall: 1.488834 | f2: 1.854141
2023-05-24 14:42:17,684 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 26 | train -> loss: 2978.82083 | validation -> loss: 742.76987 | accuracy: 60.218258 | precision: 100.000000 | recall: 0.496278 | f2: 0.619579
2023-05-24 14:43:00,993 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 27 | train -> loss: 2989.87728 | validation -> loss: 744.93547 | accuracy: 61.111111 | precision: 92.307693 | recall: 2.977668 | f2: 3.692308
2023-05-24 14:43:44,563 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 28 | train -> loss: 2989.26967 | validation -> loss: 742.18154 | accuracy: 61.309521 | precision: 93.333336 | recall: 3.473945 | f2: 4.302397
2023-05-24 14:44:28,136 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 29 | train -> loss: 2987.21339 | validation -> loss: 741.32815 | accuracy: 60.714287 | precision: 100.000000 | recall: 1.736973 | f2: 2.161828
2023-05-24 14:45:11,085 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 30 | train -> loss: 2975.54155 | validation -> loss: 741.12318 | accuracy: 61.011906 | precision: 100.000000 | recall: 2.481390 | f2: 3.082614
2023-05-24 14:45:54,282 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 31 | train -> loss: 2968.79241 | validation -> loss: 740.41944 | accuracy: 63.392860 | precision: 92.500000 | recall: 9.181141 | f2: 11.198547
2023-05-24 14:46:37,236 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 32 | train -> loss: 2949.60599 | validation -> loss: 729.34019 | accuracy: 64.583328 | precision: 92.592590 | recall: 12.406948 | f2: 15.006002
2023-05-24 14:47:22,204 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 33 | train -> loss: 2967.45501 | validation -> loss: 737.78166 | accuracy: 63.095238 | precision: 94.285713 | recall: 8.188586 | f2: 10.018214
2023-05-24 14:48:06,335 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 34 | train -> loss: 2955.20623 | validation -> loss: 728.79250 | accuracy: 64.583328 | precision: 97.916672 | recall: 11.662531 | f2: 14.156626
2023-05-24 14:48:50,020 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 35 | train -> loss: 2972.24233 | validation -> loss: 742.58439 | accuracy: 62.003971 | precision: 88.461533 | recall: 5.707196 | f2: 7.020757
2023-05-24 14:49:34,260 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 36 | train -> loss: 2962.26865 | validation -> loss: 733.11559 | accuracy: 64.087303 | precision: 91.836731 | recall: 11.166253 | f2: 13.546057
2023-05-24 14:50:17,710 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 37 | train -> loss: 2921.96874 | validation -> loss: 725.48786 | accuracy: 64.285713 | precision: 92.156860 | recall: 11.662531 | f2: 14.131088
2023-05-24 14:51:01,920 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 38 | train -> loss: 2919.45126 | validation -> loss: 948.55146 | accuracy: 38.988094 | precision: 39.271255 | recall: 96.277916 | f2: 74.615387
2023-05-24 14:51:45,338 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 39 | train -> loss: 2984.01956 | validation -> loss: 742.86468 | accuracy: 63.591270 | precision: 97.368416 | recall: 9.181141 | f2: 11.212121
2023-05-24 14:52:28,713 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 40 | train -> loss: 2811.11072 | validation -> loss: 571.29640 | accuracy: 80.654762 | precision: 84.437088 | recall: 63.275433 | f2: 66.614418
2023-05-24 14:53:10,953 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 41 | train -> loss: 2485.98419 | validation -> loss: 740.01152 | accuracy: 62.400795 | precision: 96.153847 | recall: 6.203474 | f2: 7.631258
2023-05-24 14:53:54,630 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 42 | train -> loss: 2894.89393 | validation -> loss: 744.06134 | accuracy: 60.317463 | precision: 100.000000 | recall: 0.744417 | f2: 0.928793
2023-05-24 14:54:37,864 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 43 | train -> loss: 2977.23054 | validation -> loss: 744.23644 | accuracy: 60.416668 | precision: 100.000000 | recall: 0.992556 | f2: 1.237624
2023-05-24 14:55:21,542 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 44 | train -> loss: 2983.08518 | validation -> loss: 743.62457 | accuracy: 61.111111 | precision: 73.913040 | recall: 4.218362 | f2: 5.198777
2023-05-24 14:56:04,424 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 45 | train -> loss: 2977.95307 | validation -> loss: 744.28683 | accuracy: 60.615082 | precision: 100.000000 | recall: 1.488834 | f2: 1.854141
2023-05-24 14:56:48,757 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 46 | train -> loss: 2972.95929 | validation -> loss: 742.66059 | accuracy: 61.309521 | precision: 93.333336 | recall: 3.473945 | f2: 4.302397
2023-05-24 14:57:33,151 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 47 | train -> loss: 2973.67473 | validation -> loss: 751.13682 | accuracy: 64.384918 | precision: 92.307693 | recall: 11.910670 | f2: 14.423077
2023-05-24 14:57:33,152 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 14:58:16,292 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 48 | train -> loss: 2965.61089 | validation -> loss: 741.87834 | accuracy: 62.103176 | precision: 95.652176 | recall: 5.459057 | f2: 6.727829
2023-05-24 14:58:59,407 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 49 | train -> loss: 2961.23426 | validation -> loss: 739.90319 | accuracy: 61.408730 | precision: 76.923080 | recall: 4.962779 | f2: 6.105006
2023-05-24 14:59:42,959 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 50 | train -> loss: 2961.09363 | validation -> loss: 739.74918 | accuracy: 62.698410 | precision: 96.551720 | recall: 6.947891 | f2: 8.531384
2023-05-24 15:00:26,887 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 51 | train -> loss: 2963.54974 | validation -> loss: 740.41186 | accuracy: 61.507935 | precision: 94.117645 | recall: 3.970223 | f2: 4.910988
2023-05-24 15:01:11,029 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 52 | train -> loss: 2956.93836 | validation -> loss: 741.22978 | accuracy: 63.591270 | precision: 95.000000 | recall: 9.429280 | f2: 11.501211
2023-05-24 15:01:54,278 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 53 | train -> loss: 2958.51430 | validation -> loss: 738.55880 | accuracy: 62.797619 | precision: 88.888893 | recall: 7.940446 | f2: 9.708737
2023-05-24 15:02:38,387 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 54 | train -> loss: 2952.60994 | validation -> loss: 737.09645 | accuracy: 63.392860 | precision: 94.736847 | recall: 8.933002 | f2: 10.909091
2023-05-24 15:03:21,918 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 55 | train -> loss: 2955.00601 | validation -> loss: 743.10793 | accuracy: 64.285713 | precision: 90.566040 | recall: 11.910670 | f2: 14.414414
2023-05-24 15:04:04,835 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 56 | train -> loss: 2956.83474 | validation -> loss: 736.97532 | accuracy: 63.690479 | precision: 93.023262 | recall: 9.925558 | f2: 12.084592
2023-05-24 15:04:48,849 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 57 | train -> loss: 2948.26347 | validation -> loss: 734.36846 | accuracy: 63.888889 | precision: 95.348831 | recall: 10.173697 | f2: 12.386707
2023-05-24 15:05:32,923 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 58 | train -> loss: 2941.86378 | validation -> loss: 731.07945 | accuracy: 64.980164 | precision: 100.000000 | recall: 12.406948 | f2: 15.042117
2023-05-24 15:06:16,924 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 59 | train -> loss: 2921.35089 | validation -> loss: 725.46376 | accuracy: 65.674606 | precision: 90.140846 | recall: 15.880893 | f2: 19.013666
2023-05-24 15:07:00,805 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 60 | train -> loss: 2906.96738 | validation -> loss: 728.02985 | accuracy: 64.781746 | precision: 96.153847 | recall: 12.406948 | f2: 15.024039
2023-05-24 15:07:45,811 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 61 | train -> loss: 2914.51915 | validation -> loss: 723.18831 | accuracy: 64.682541 | precision: 89.830505 | recall: 13.151364 | f2: 15.858768
2023-05-24 15:08:29,398 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 62 | train -> loss: 2931.79554 | validation -> loss: 744.28593 | accuracy: 60.813492 | precision: 100.000000 | recall: 1.985112 | f2: 2.469136
2023-05-24 15:09:11,980 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 63 | train -> loss: 2981.34483 | validation -> loss: 744.79760 | accuracy: 60.416668 | precision: 60.000004 | recall: 2.977668 | f2: 3.676471
2023-05-24 15:09:54,432 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 64 | train -> loss: 2979.11160 | validation -> loss: 745.13517 | accuracy: 60.515873 | precision: 100.000000 | recall: 1.240695 | f2: 1.546073
2023-05-24 15:10:38,723 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 65 | train -> loss: 2978.15456 | validation -> loss: 744.46234 | accuracy: 60.515873 | precision: 69.230774 | recall: 2.233251 | f2: 2.769231
2023-05-24 15:11:22,172 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 66 | train -> loss: 2981.21076 | validation -> loss: 743.64521 | accuracy: 60.912697 | precision: 100.000000 | recall: 2.233251 | f2: 2.776064
2023-05-24 15:12:05,839 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 67 | train -> loss: 2976.96924 | validation -> loss: 743.85491 | accuracy: 61.011906 | precision: 100.000000 | recall: 2.481390 | f2: 3.082614
2023-05-24 15:12:49,498 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 68 | train -> loss: 2975.68357 | validation -> loss: 743.76858 | accuracy: 61.309521 | precision: 100.000000 | recall: 3.225806 | f2: 4.000000
2023-05-24 15:13:31,859 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 69 | train -> loss: 2972.51046 | validation -> loss: 742.88606 | accuracy: 61.111111 | precision: 100.000000 | recall: 2.729529 | f2: 3.388786
2023-05-24 15:14:14,708 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 70 | train -> loss: 2972.65511 | validation -> loss: 743.73414 | accuracy: 61.111111 | precision: 100.000000 | recall: 2.729529 | f2: 3.388786
2023-05-24 15:14:57,292 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 71 | train -> loss: 2972.07717 | validation -> loss: 742.25558 | accuracy: 61.111111 | precision: 100.000000 | recall: 2.729529 | f2: 3.388786
2023-05-24 15:15:39,460 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 72 | train -> loss: 2970.32514 | validation -> loss: 742.73145 | accuracy: 61.309521 | precision: 88.235298 | recall: 3.722084 | f2: 4.604052
2023-05-24 15:16:21,928 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 73 | train -> loss: 2966.92659 | validation -> loss: 740.08168 | accuracy: 62.103176 | precision: 95.652176 | recall: 5.459057 | f2: 6.727829
2023-05-24 15:16:21,929 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 15:17:06,625 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 74 | train -> loss: 2958.60457 | validation -> loss: 740.04091 | accuracy: 62.698410 | precision: 93.548386 | recall: 7.196030 | f2: 8.825319
2023-05-24 15:17:49,084 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 75 | train -> loss: 2958.25904 | validation -> loss: 739.06359 | accuracy: 62.400795 | precision: 100.000000 | recall: 5.955335 | f2: 7.334963
2023-05-24 15:18:31,877 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 76 | train -> loss: 2953.63613 | validation -> loss: 739.85369 | accuracy: 62.400795 | precision: 90.000000 | recall: 6.699752 | f2: 8.221681
2023-05-24 15:19:16,033 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 77 | train -> loss: 2955.05205 | validation -> loss: 737.32752 | accuracy: 63.690479 | precision: 97.435898 | recall: 9.429280 | f2: 11.508177
2023-05-24 15:19:59,819 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 78 | train -> loss: 2944.40691 | validation -> loss: 735.59224 | accuracy: 63.888889 | precision: 89.795914 | recall: 10.918115 | f2: 13.245032
2023-05-24 15:20:43,190 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 79 | train -> loss: 2944.28003 | validation -> loss: 734.63490 | accuracy: 64.583328 | precision: 97.916672 | recall: 11.662531 | f2: 14.156626
2023-05-24 15:21:27,584 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 80 | train -> loss: 2929.83451 | validation -> loss: 729.26644 | accuracy: 64.384918 | precision: 97.826088 | recall: 11.166253 | f2: 13.570566
2023-05-24 15:22:10,667 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 81 | train -> loss: 2900.01671 | validation -> loss: 725.68438 | accuracy: 63.789684 | precision: 86.538467 | recall: 11.166253 | f2: 13.521634
2023-05-24 15:22:55,652 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 82 | train -> loss: 2870.78489 | validation -> loss: 714.63415 | accuracy: 66.269836 | precision: 94.366196 | recall: 16.625311 | f2: 19.904932
2023-05-24 15:23:38,858 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 83 | train -> loss: 2878.77576 | validation -> loss: 715.57388 | accuracy: 66.071426 | precision: 94.202896 | recall: 16.129032 | f2: 19.333731
2023-05-24 15:24:21,650 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 84 | train -> loss: 2869.02465 | validation -> loss: 713.24318 | accuracy: 65.972221 | precision: 92.857140 | recall: 16.129032 | f2: 19.322235
2023-05-24 15:25:03,738 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 85 | train -> loss: 2862.76993 | validation -> loss: 706.24442 | accuracy: 66.964287 | precision: 96.052628 | recall: 18.114143 | f2: 21.623222
2023-05-24 15:25:46,323 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 86 | train -> loss: 2851.26393 | validation -> loss: 701.96679 | accuracy: 68.551590 | precision: 89.814812 | recall: 24.069479 | f2: 28.197674
2023-05-24 15:26:29,671 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 87 | train -> loss: 2847.41465 | validation -> loss: 711.97228 | accuracy: 66.369041 | precision: 97.058823 | recall: 16.377172 | f2: 19.642857
2023-05-24 15:27:13,241 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 88 | train -> loss: 2834.61848 | validation -> loss: 719.45711 | accuracy: 66.170631 | precision: 100.000000 | recall: 15.384616 | f2: 18.518518
2023-05-24 15:27:55,589 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 89 | train -> loss: 2855.06426 | validation -> loss: 705.37102 | accuracy: 66.865082 | precision: 73.793098 | recall: 26.550869 | f2: 30.449629
2023-05-24 15:28:37,850 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 90 | train -> loss: 2830.90395 | validation -> loss: 704.20301 | accuracy: 67.460320 | precision: 95.180717 | recall: 19.602978 | f2: 23.303835
2023-05-24 15:29:20,495 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 91 | train -> loss: 2893.78606 | validation -> loss: 736.06428 | accuracy: 60.218258 | precision: 50.150150 | recall: 82.878410 | f2: 73.309921
2023-05-24 15:30:03,422 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 92 | train -> loss: 2773.41494 | validation -> loss: 740.45332 | accuracy: 67.261902 | precision: 97.402596 | recall: 18.610422 | f2: 22.202488
2023-05-24 15:30:46,668 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 93 | train -> loss: 2669.38949 | validation -> loss: 651.87735 | accuracy: 68.551590 | precision: 57.846714 | recall: 78.660049 | f2: 73.379631
2023-05-24 15:31:29,295 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 94 | train -> loss: 2618.94040 | validation -> loss: 696.16115 | accuracy: 59.821426 | precision: 49.854229 | recall: 84.863525 | f2: 74.412529
2023-05-24 15:32:11,786 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 95 | train -> loss: 2672.26559 | validation -> loss: 661.78185 | accuracy: 65.476189 | precision: 54.486130 | recall: 82.878410 | f2: 75.056175
2023-05-24 15:32:54,576 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 96 | train -> loss: 2624.83993 | validation -> loss: 653.35273 | accuracy: 67.361107 | precision: 56.379311 | recall: 81.141441 | f2: 74.589417
2023-05-24 15:33:37,361 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 97 | train -> loss: 2622.05336 | validation -> loss: 661.01483 | accuracy: 65.773811 | precision: 54.882156 | recall: 80.893303 | f2: 73.889389
2023-05-24 15:34:19,419 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 98 | train -> loss: 2719.26551 | validation -> loss: 649.29782 | accuracy: 69.146820 | precision: 58.745247 | recall: 76.674942 | f2: 72.263794
2023-05-24 15:35:02,290 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 99 | train -> loss: 2704.97862 | validation -> loss: 697.33145 | accuracy: 57.539684 | precision: 48.294678 | recall: 87.841187 | f2: 75.479744
2023-05-24 15:35:02,291 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 15:35:45,432 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 100 | train -> loss: 2696.27238 | validation -> loss: 688.43071 | accuracy: 59.027779 | precision: 49.295773 | recall: 86.848633 | f2: 75.366058
2023-05-24 15:35:45,578 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f1/model_fold1.pth
2023-05-24 15:35:45,839 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 15:35:45,842 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD226BFA0>
2023-05-24 15:35:45,844 | root | INFO | rnn.py learn @ 85 : fetching data for fold #2
2023-05-24 15:35:45,845 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 15:35:45,845 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 15:35:45,846 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 15:35:45,847 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 15:36:29,389 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 1 | train -> loss: 2614.82241 | validation -> loss: 569.84787 | accuracy: 80.952385 | precision: 87.544479 | recall: 61.042183 | f2: 64.976227
2023-05-24 15:37:11,573 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 2 | train -> loss: 2271.52395 | validation -> loss: 541.54754 | accuracy: 79.960320 | precision: 71.428574 | recall: 83.126549 | f2: 80.490150
2023-05-24 15:37:55,241 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 3 | train -> loss: 2688.10979 | validation -> loss: 750.16990 | accuracy: 60.515873 | precision: 100.000000 | recall: 1.240695 | f2: 1.546073
2023-05-24 15:38:39,293 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 4 | train -> loss: 3003.93663 | validation -> loss: 768.74054 | accuracy: 60.813492 | precision: 100.000000 | recall: 1.985112 | f2: 2.469136
2023-05-24 15:39:21,785 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 5 | train -> loss: 2996.09283 | validation -> loss: 761.30834 | accuracy: 60.714287 | precision: 88.888893 | recall: 1.985112 | f2: 2.467613
2023-05-24 15:40:04,964 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 6 | train -> loss: 3010.73548 | validation -> loss: 763.08629 | accuracy: 38.888889 | precision: 39.209728 | recall: 96.029778 | f2: 74.451714
2023-05-24 15:40:47,620 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 7 | train -> loss: 2980.96452 | validation -> loss: 741.41126 | accuracy: 61.408730 | precision: 85.000000 | recall: 4.218362 | f2: 5.208333
2023-05-24 15:41:30,553 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 8 | train -> loss: 2963.42800 | validation -> loss: 756.32016 | accuracy: 62.301590 | precision: 92.592590 | recall: 6.203474 | f2: 7.626601
2023-05-24 15:42:13,365 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 9 | train -> loss: 2971.19967 | validation -> loss: 735.23426 | accuracy: 62.896824 | precision: 93.939392 | recall: 7.692308 | f2: 9.422492
2023-05-24 15:42:56,202 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 10 | train -> loss: 2965.24312 | validation -> loss: 758.12522 | accuracy: 40.277779 | precision: 40.099503 | recall: 100.000000 | f2: 76.996559
2023-05-24 15:43:38,915 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 11 | train -> loss: 2995.21612 | validation -> loss: 731.92320 | accuracy: 63.690479 | precision: 93.023262 | recall: 9.925558 | f2: 12.084592
2023-05-24 15:44:22,590 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 12 | train -> loss: 2962.50958 | validation -> loss: 744.34145 | accuracy: 63.492065 | precision: 88.888893 | recall: 9.925558 | f2: 12.070006
2023-05-24 15:45:05,870 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 13 | train -> loss: 2963.47439 | validation -> loss: 755.14561 | accuracy: 62.400795 | precision: 72.222221 | recall: 9.677419 | f2: 11.704681
2023-05-24 15:45:48,404 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 14 | train -> loss: 2978.12433 | validation -> loss: 743.42274 | accuracy: 63.392860 | precision: 80.357140 | recall: 11.166253 | f2: 13.489209
2023-05-24 15:46:30,323 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 15 | train -> loss: 2974.05826 | validation -> loss: 735.99797 | accuracy: 62.202381 | precision: 77.500000 | recall: 7.692308 | f2: 9.382566
2023-05-24 15:47:12,727 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 16 | train -> loss: 2945.85549 | validation -> loss: 729.48949 | accuracy: 65.873016 | precision: 89.333328 | recall: 16.625311 | f2: 19.857737
2023-05-24 15:47:55,162 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 17 | train -> loss: 2925.58462 | validation -> loss: 735.30812 | accuracy: 66.865082 | precision: 84.848488 | recall: 20.843674 | f2: 24.547049
2023-05-24 15:48:37,133 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 18 | train -> loss: 2894.87197 | validation -> loss: 733.45341 | accuracy: 66.865082 | precision: 84.158417 | recall: 21.091812 | f2: 24.810274
2023-05-24 15:49:19,771 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 19 | train -> loss: 2911.76499 | validation -> loss: 735.18666 | accuracy: 66.765877 | precision: 80.357140 | recall: 22.332506 | f2: 26.102087
2023-05-24 15:50:02,250 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 20 | train -> loss: 2874.96688 | validation -> loss: 717.77563 | accuracy: 65.575394 | precision: 85.000000 | recall: 16.873449 | f2: 20.094563
2023-05-24 15:50:44,647 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 21 | train -> loss: 2854.74434 | validation -> loss: 734.73140 | accuracy: 53.968258 | precision: 44.925125 | recall: 66.997513 | f2: 61.003159
2023-05-24 15:50:44,648 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 15:51:26,322 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 22 | train -> loss: 2787.43591 | validation -> loss: 707.89660 | accuracy: 66.865082 | precision: 85.567009 | recall: 20.595533 | f2: 24.283207
2023-05-24 15:52:08,543 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 23 | train -> loss: 2767.51715 | validation -> loss: 709.15101 | accuracy: 66.468254 | precision: 82.178215 | recall: 20.595533 | f2: 24.226503
2023-05-24 15:52:51,805 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 24 | train -> loss: 2778.10056 | validation -> loss: 705.90576 | accuracy: 66.567459 | precision: 78.947372 | recall: 22.332506 | f2: 26.071844
2023-05-24 15:53:34,084 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 25 | train -> loss: 2750.91052 | validation -> loss: 701.83285 | accuracy: 67.460320 | precision: 80.487808 | recall: 24.565756 | f2: 28.530258
2023-05-24 15:54:16,915 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 26 | train -> loss: 2737.12524 | validation -> loss: 703.82652 | accuracy: 67.658730 | precision: 81.300812 | recall: 24.813896 | f2: 28.818443
2023-05-24 15:54:58,973 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 27 | train -> loss: 2732.27549 | validation -> loss: 698.15148 | accuracy: 67.857140 | precision: 81.599998 | recall: 25.310173 | f2: 29.360968
2023-05-24 15:55:41,083 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 28 | train -> loss: 2728.85491 | validation -> loss: 693.46486 | accuracy: 68.055557 | precision: 83.471069 | recall: 25.062033 | f2: 29.140219
2023-05-24 15:56:23,766 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 29 | train -> loss: 2711.81406 | validation -> loss: 700.52553 | accuracy: 67.460320 | precision: 78.195488 | recall: 25.806450 | f2: 29.799425
2023-05-24 15:57:06,352 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 30 | train -> loss: 2725.40427 | validation -> loss: 710.48995 | accuracy: 66.567459 | precision: 84.375000 | recall: 20.099255 | f2: 23.711945
2023-05-24 15:57:49,033 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 31 | train -> loss: 2734.99684 | validation -> loss: 699.72736 | accuracy: 67.063492 | precision: 85.148514 | recall: 21.339951 | f2: 25.102160
2023-05-24 15:58:31,532 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 32 | train -> loss: 2739.05815 | validation -> loss: 704.74388 | accuracy: 66.765877 | precision: 80.909088 | recall: 22.084368 | f2: 25.842043
2023-05-24 15:59:14,547 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 33 | train -> loss: 2736.39592 | validation -> loss: 707.89123 | accuracy: 66.468254 | precision: 82.828285 | recall: 20.347395 | f2: 23.962595
2023-05-24 15:59:57,316 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 34 | train -> loss: 2729.14055 | validation -> loss: 719.43900 | accuracy: 65.674606 | precision: 73.949585 | recall: 21.836229 | f2: 25.418833
2023-05-24 16:00:39,908 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 35 | train -> loss: 2751.30643 | validation -> loss: 728.69470 | accuracy: 40.873016 | precision: 39.852787 | recall: 94.044670 | f2: 73.936790
2023-05-24 16:01:21,856 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 36 | train -> loss: 2762.38761 | validation -> loss: 707.43095 | accuracy: 66.170631 | precision: 83.695648 | recall: 19.106699 | f2: 22.593897
2023-05-24 16:02:03,918 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 37 | train -> loss: 2776.12643 | validation -> loss: 710.36022 | accuracy: 65.178574 | precision: 79.545456 | recall: 17.369728 | f2: 20.588236
2023-05-24 16:02:46,232 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 38 | train -> loss: 2780.67246 | validation -> loss: 716.13164 | accuracy: 64.980164 | precision: 81.250000 | recall: 16.129032 | f2: 19.208038
2023-05-24 16:03:28,430 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 39 | train -> loss: 2765.64168 | validation -> loss: 745.53832 | accuracy: 64.781746 | precision: 83.333328 | recall: 14.888337 | f2: 17.814728
2023-05-24 16:04:10,618 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 40 | train -> loss: 2758.10240 | validation -> loss: 720.30130 | accuracy: 64.384918 | precision: 76.190475 | recall: 15.880893 | f2: 18.867926
2023-05-24 16:04:52,726 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 41 | train -> loss: 2750.90084 | validation -> loss: 714.94226 | accuracy: 65.376984 | precision: 82.926826 | recall: 16.873449 | f2: 20.070839
2023-05-24 16:05:34,838 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 42 | train -> loss: 2752.34525 | validation -> loss: 716.82258 | accuracy: 65.376984 | precision: 82.142860 | recall: 17.121588 | f2: 20.341980
2023-05-24 16:06:16,473 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 43 | train -> loss: 2752.48647 | validation -> loss: 724.40380 | accuracy: 63.988094 | precision: 72.727272 | recall: 15.880893 | f2: 18.823530
2023-05-24 16:06:58,454 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 44 | train -> loss: 2766.79990 | validation -> loss: 725.85034 | accuracy: 61.507935 | precision: 52.650177 | recall: 36.972706 | f2: 39.313984
2023-05-24 16:07:39,470 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 45 | train -> loss: 2779.89409 | validation -> loss: 725.66995 | accuracy: 63.789684 | precision: 79.687500 | recall: 12.655087 | f2: 15.214798
2023-05-24 16:08:21,713 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 46 | train -> loss: 2823.14544 | validation -> loss: 727.03098 | accuracy: 63.492065 | precision: 84.313728 | recall: 10.669975 | f2: 12.928443
2023-05-24 16:09:03,089 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 47 | train -> loss: 2833.53356 | validation -> loss: 728.86462 | accuracy: 63.392860 | precision: 86.956520 | recall: 9.925558 | f2: 12.062726
2023-05-24 16:09:03,089 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 16:09:44,731 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 48 | train -> loss: 2815.49037 | validation -> loss: 726.45045 | accuracy: 63.591270 | precision: 84.615387 | recall: 10.918115 | f2: 13.221153
2023-05-24 16:10:26,362 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 49 | train -> loss: 2796.15178 | validation -> loss: 730.93996 | accuracy: 63.293655 | precision: 82.352943 | recall: 10.421837 | f2: 12.627781
2023-05-24 16:11:09,110 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 50 | train -> loss: 2795.08551 | validation -> loss: 732.58279 | accuracy: 62.400795 | precision: 67.647057 | recall: 11.414392 | f2: 13.690476
2023-05-24 16:11:51,193 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 51 | train -> loss: 2790.69370 | validation -> loss: 730.38586 | accuracy: 63.492065 | precision: 87.234047 | recall: 10.173697 | f2: 12.356842
2023-05-24 16:12:33,166 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 52 | train -> loss: 2790.67350 | validation -> loss: 730.56558 | accuracy: 62.797619 | precision: 81.818184 | recall: 8.933002 | f2: 10.869565
2023-05-24 16:13:15,099 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 53 | train -> loss: 2798.92042 | validation -> loss: 733.67441 | accuracy: 62.599205 | precision: 74.074074 | recall: 9.925558 | f2: 12.004802
2023-05-24 16:13:57,165 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 54 | train -> loss: 2798.27405 | validation -> loss: 726.98071 | accuracy: 63.492065 | precision: 81.818184 | recall: 11.166253 | f2: 13.497300
2023-05-24 16:14:38,922 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 55 | train -> loss: 2794.01650 | validation -> loss: 743.12101 | accuracy: 62.599205 | precision: 69.117645 | recall: 11.662531 | f2: 13.988095
2023-05-24 16:15:21,929 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 56 | train -> loss: 2785.80342 | validation -> loss: 727.49409 | accuracy: 63.392860 | precision: 82.692307 | recall: 10.669975 | f2: 12.920673
2023-05-24 16:16:04,090 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 57 | train -> loss: 2791.14133 | validation -> loss: 737.19652 | accuracy: 62.698410 | precision: 75.471703 | recall: 9.925558 | f2: 12.012012
2023-05-24 16:16:46,345 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 58 | train -> loss: 2790.01727 | validation -> loss: 732.49544 | accuracy: 62.996029 | precision: 82.608696 | recall: 9.429280 | f2: 11.459590
2023-05-24 16:17:29,002 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 59 | train -> loss: 2786.01095 | validation -> loss: 731.22140 | accuracy: 62.996029 | precision: 78.846153 | recall: 10.173697 | f2: 12.319712
2023-05-24 16:18:11,036 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 60 | train -> loss: 2785.16420 | validation -> loss: 728.36306 | accuracy: 63.392860 | precision: 85.416672 | recall: 10.173697 | f2: 12.349398
2023-05-24 16:18:53,042 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 61 | train -> loss: 2784.00161 | validation -> loss: 725.80651 | accuracy: 63.392860 | precision: 79.310349 | recall: 11.414392 | f2: 13.772455
2023-05-24 16:19:35,565 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 62 | train -> loss: 2779.48268 | validation -> loss: 727.51473 | accuracy: 63.392860 | precision: 81.481483 | recall: 10.918115 | f2: 13.205282
2023-05-24 16:20:17,715 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 63 | train -> loss: 2783.16618 | validation -> loss: 730.98518 | accuracy: 62.400795 | precision: 71.428574 | recall: 9.925558 | f2: 11.990408
2023-05-24 16:20:58,715 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 64 | train -> loss: 2801.03027 | validation -> loss: 722.37810 | accuracy: 63.492065 | precision: 83.018867 | recall: 10.918115 | f2: 13.213213
2023-05-24 16:21:40,764 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 65 | train -> loss: 2784.22538 | validation -> loss: 728.30492 | accuracy: 63.293655 | precision: 80.000000 | recall: 10.918115 | f2: 13.197361
2023-05-24 16:22:22,772 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 66 | train -> loss: 2791.53546 | validation -> loss: 738.09194 | accuracy: 62.996029 | precision: 77.777779 | recall: 10.421837 | f2: 12.605042
2023-05-24 16:23:05,108 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 67 | train -> loss: 2791.39905 | validation -> loss: 719.10331 | accuracy: 63.591270 | precision: 83.333328 | recall: 11.166253 | f2: 13.505403
2023-05-24 16:23:48,149 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 68 | train -> loss: 2790.53882 | validation -> loss: 723.56292 | accuracy: 63.492065 | precision: 84.313728 | recall: 10.669975 | f2: 12.928443
2023-05-24 16:24:30,589 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 69 | train -> loss: 2776.61334 | validation -> loss: 729.66217 | accuracy: 63.293655 | precision: 72.602737 | recall: 13.151364 | f2: 15.727003
2023-05-24 16:25:12,437 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 70 | train -> loss: 2782.87768 | validation -> loss: 739.33249 | accuracy: 62.698410 | precision: 76.470589 | recall: 9.677419 | f2: 11.725797
2023-05-24 16:25:54,900 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 71 | train -> loss: 2779.55897 | validation -> loss: 732.23494 | accuracy: 62.599205 | precision: 74.074074 | recall: 9.925558 | f2: 12.004802
2023-05-24 16:26:36,766 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 72 | train -> loss: 2781.13291 | validation -> loss: 718.94272 | accuracy: 63.888889 | precision: 88.235298 | recall: 11.166253 | f2: 13.529766
2023-05-24 16:27:19,373 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 73 | train -> loss: 2798.37235 | validation -> loss: 729.08335 | accuracy: 63.392860 | precision: 78.333336 | recall: 11.662531 | f2: 14.055024
2023-05-24 16:27:19,374 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 16:28:01,720 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 74 | train -> loss: 2774.31449 | validation -> loss: 725.70572 | accuracy: 63.888889 | precision: 89.795914 | recall: 10.918115 | f2: 13.245032
2023-05-24 16:28:44,461 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 75 | train -> loss: 2781.26329 | validation -> loss: 721.02967 | accuracy: 64.186508 | precision: 87.500000 | recall: 12.158809 | f2: 14.688249
2023-05-24 16:29:26,828 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 76 | train -> loss: 2771.29015 | validation -> loss: 724.52602 | accuracy: 63.591270 | precision: 82.142860 | recall: 11.414392 | f2: 13.788968
2023-05-24 16:30:08,427 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 77 | train -> loss: 2774.49014 | validation -> loss: 723.57958 | accuracy: 63.392860 | precision: 79.310349 | recall: 11.414392 | f2: 13.772455
2023-05-24 16:30:51,341 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 78 | train -> loss: 2779.10380 | validation -> loss: 727.23519 | accuracy: 63.789684 | precision: 80.645164 | recall: 12.406948 | f2: 14.934290
2023-05-24 16:31:33,558 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 79 | train -> loss: 2775.98316 | validation -> loss: 727.49253 | accuracy: 63.492065 | precision: 83.018867 | recall: 10.918115 | f2: 13.213213
2023-05-24 16:32:15,788 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 80 | train -> loss: 2771.32022 | validation -> loss: 726.69607 | accuracy: 63.591270 | precision: 82.142860 | recall: 11.414392 | f2: 13.788968
2023-05-24 16:32:57,452 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 81 | train -> loss: 2778.64392 | validation -> loss: 729.34767 | accuracy: 63.095238 | precision: 76.271187 | recall: 11.166253 | f2: 13.464992
2023-05-24 16:33:39,471 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 82 | train -> loss: 2770.31356 | validation -> loss: 726.68746 | accuracy: 64.087303 | precision: 81.538460 | recall: 13.151364 | f2: 15.802028
2023-05-24 16:34:20,675 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 83 | train -> loss: 2780.52837 | validation -> loss: 729.44705 | accuracy: 62.896824 | precision: 79.591835 | recall: 9.677419 | f2: 11.739916
2023-05-24 16:35:02,556 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 84 | train -> loss: 2783.88051 | validation -> loss: 726.85881 | accuracy: 63.095238 | precision: 77.192978 | recall: 10.918115 | f2: 13.181546
2023-05-24 16:35:44,304 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 85 | train -> loss: 2781.66770 | validation -> loss: 729.71128 | accuracy: 63.095238 | precision: 71.830986 | recall: 12.655087 | f2: 15.151516
2023-05-24 16:36:26,054 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 86 | train -> loss: 2776.29887 | validation -> loss: 722.64851 | accuracy: 63.591270 | precision: 81.034485 | recall: 11.662531 | f2: 14.071856
2023-05-24 16:37:08,397 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 87 | train -> loss: 2770.58334 | validation -> loss: 722.47597 | accuracy: 63.591270 | precision: 79.032257 | recall: 12.158809 | f2: 14.635603
2023-05-24 16:37:49,718 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 88 | train -> loss: 2770.80300 | validation -> loss: 721.86927 | accuracy: 63.392860 | precision: 77.419350 | recall: 11.910670 | f2: 14.336918
2023-05-24 16:38:31,873 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 89 | train -> loss: 2773.09502 | validation -> loss: 719.83649 | accuracy: 63.789684 | precision: 80.645164 | recall: 12.406948 | f2: 14.934290
2023-05-24 16:39:14,856 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 90 | train -> loss: 2770.17326 | validation -> loss: 735.67500 | accuracy: 63.095238 | precision: 75.409836 | recall: 11.414392 | f2: 13.747759
2023-05-24 16:39:57,821 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 91 | train -> loss: 2769.73671 | validation -> loss: 729.98296 | accuracy: 63.392860 | precision: 79.310349 | recall: 11.414392 | f2: 13.772455
2023-05-24 16:40:40,708 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 92 | train -> loss: 2777.56040 | validation -> loss: 726.87845 | accuracy: 63.690479 | precision: 82.456139 | recall: 11.662531 | f2: 14.080288
2023-05-24 16:41:23,230 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 93 | train -> loss: 2763.33622 | validation -> loss: 732.32561 | accuracy: 62.599205 | precision: 72.413788 | recall: 10.421837 | f2: 12.574850
2023-05-24 16:42:05,045 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 94 | train -> loss: 2766.55747 | validation -> loss: 720.01974 | accuracy: 63.591270 | precision: 81.034485 | recall: 11.662531 | f2: 14.071856
2023-05-24 16:42:46,620 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 95 | train -> loss: 2775.29899 | validation -> loss: 724.02819 | accuracy: 63.789684 | precision: 81.666664 | recall: 12.158809 | f2: 14.653111
2023-05-24 16:43:28,739 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 96 | train -> loss: 2776.93474 | validation -> loss: 720.20812 | accuracy: 63.988094 | precision: 82.258064 | recall: 12.655087 | f2: 15.232974
2023-05-24 16:44:10,588 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 97 | train -> loss: 2776.06274 | validation -> loss: 735.81741 | accuracy: 62.797619 | precision: 73.333336 | recall: 10.918115 | f2: 13.157895
2023-05-24 16:44:52,308 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 98 | train -> loss: 2776.63132 | validation -> loss: 726.50358 | accuracy: 63.789684 | precision: 83.928574 | recall: 11.662531 | f2: 14.088729
2023-05-24 16:45:34,952 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 99 | train -> loss: 2772.76245 | validation -> loss: 738.21076 | accuracy: 62.202381 | precision: 67.187500 | recall: 10.669975 | f2: 12.828162
2023-05-24 16:45:34,953 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 16:46:17,851 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 100 | train -> loss: 2762.32286 | validation -> loss: 735.44492 | accuracy: 63.095238 | precision: 78.181824 | recall: 10.669975 | f2: 12.897420
2023-05-24 16:46:17,958 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f2/model_fold2.pth
2023-05-24 16:46:18,288 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 16:46:18,291 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD213CE50>
2023-05-24 16:46:18,293 | root | INFO | rnn.py learn @ 85 : fetching data for fold #3
2023-05-24 16:46:18,293 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 16:46:18,294 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 16:46:18,295 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 16:46:18,296 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 16:47:00,483 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 1 | train -> loss: 2967.45627 | validation -> loss: 723.46089 | accuracy: 64.682541 | precision: 91.379311 | recall: 13.118813 | f2: 15.830347
2023-05-24 16:47:43,200 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 2 | train -> loss: 2873.32869 | validation -> loss: 729.96908 | accuracy: 63.591270 | precision: 89.361702 | recall: 10.396040 | f2: 12.627781
2023-05-24 16:48:26,222 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 3 | train -> loss: 3093.68567 | validation -> loss: 761.56814 | accuracy: 55.952381 | precision: 45.145630 | recall: 46.039604 | f2: 45.857986
2023-05-24 16:49:09,086 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 4 | train -> loss: 2971.74277 | validation -> loss: 737.62812 | accuracy: 61.111111 | precision: 51.595749 | recall: 48.019802 | f2: 48.694782
2023-05-24 16:49:51,883 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 5 | train -> loss: 2911.11681 | validation -> loss: 714.79470 | accuracy: 65.079369 | precision: 57.926826 | recall: 47.029705 | f2: 48.868313
2023-05-24 16:50:34,746 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 6 | train -> loss: 2892.93720 | validation -> loss: 708.39777 | accuracy: 65.178574 | precision: 58.054710 | recall: 47.277225 | f2: 49.100258
2023-05-24 16:51:18,035 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 7 | train -> loss: 2897.50913 | validation -> loss: 709.13363 | accuracy: 65.773811 | precision: 58.858860 | recall: 48.514851 | f2: 50.282200
2023-05-24 16:52:00,906 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 8 | train -> loss: 2878.14214 | validation -> loss: 735.22486 | accuracy: 65.575394 | precision: 58.456974 | recall: 48.762375 | f2: 50.435226
2023-05-24 16:52:43,777 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 9 | train -> loss: 2901.79078 | validation -> loss: 718.92853 | accuracy: 63.591270 | precision: 55.124653 | recall: 49.257423 | f2: 50.328781
2023-05-24 16:53:26,661 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 10 | train -> loss: 3015.39642 | validation -> loss: 748.68344 | accuracy: 54.365082 | precision: 44.444447 | recall: 55.445545 | f2: 52.830189
2023-05-24 16:54:09,932 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 11 | train -> loss: 3024.67116 | validation -> loss: 754.72214 | accuracy: 55.456345 | precision: 41.245136 | recall: 26.237625 | f2: 28.296848
2023-05-24 16:54:53,981 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 12 | train -> loss: 3049.08977 | validation -> loss: 781.04089 | accuracy: 53.769840 | precision: 37.295082 | recall: 22.524754 | f2: 24.462366
2023-05-24 16:55:37,014 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 13 | train -> loss: 3051.80610 | validation -> loss: 750.67737 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.495050 | f2: 0.618047
2023-05-24 16:56:19,865 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 14 | train -> loss: 3019.45495 | validation -> loss: 751.37609 | accuracy: 54.464287 | precision: 39.926739 | recall: 26.980198 | f2: 28.851244
2023-05-24 16:57:02,614 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 15 | train -> loss: 3025.95994 | validation -> loss: 752.78572 | accuracy: 54.265873 | precision: 39.325844 | recall: 25.990099 | f2: 27.881041
2023-05-24 16:57:45,369 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 16 | train -> loss: 3030.79168 | validation -> loss: 771.12123 | accuracy: 49.007938 | precision: 39.341087 | recall: 50.247528 | f2: 47.607880
2023-05-24 16:58:27,873 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 17 | train -> loss: 3034.55117 | validation -> loss: 774.95046 | accuracy: 47.718254 | precision: 38.589981 | recall: 51.485149 | f2: 48.259861
2023-05-24 16:59:11,525 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 18 | train -> loss: 3019.57445 | validation -> loss: 748.95744 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.495050 | f2: 0.618047
2023-05-24 16:59:53,907 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 19 | train -> loss: 3024.78716 | validation -> loss: 748.97641 | accuracy: 57.242065 | precision: 45.090908 | recall: 30.693069 | f2: 32.786884
2023-05-24 17:00:36,390 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 20 | train -> loss: 3011.51408 | validation -> loss: 749.12676 | accuracy: 57.043655 | precision: 42.786072 | recall: 21.287128 | f2: 23.665382
2023-05-24 17:01:18,647 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 21 | train -> loss: 3037.51918 | validation -> loss: 759.34121 | accuracy: 54.960316 | precision: 39.919357 | recall: 24.504951 | f2: 26.555794
2023-05-24 17:01:18,647 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 17:02:02,125 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 22 | train -> loss: 3000.91877 | validation -> loss: 745.45191 | accuracy: 60.019840 | precision: 100.000000 | recall: 0.247525 | f2: 0.309215
2023-05-24 17:02:44,605 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 23 | train -> loss: 2989.95194 | validation -> loss: 746.48933 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.495050 | f2: 0.618047
2023-05-24 17:03:27,820 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 24 | train -> loss: 2989.86347 | validation -> loss: 746.87770 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.495050 | f2: 0.618047
2023-05-24 17:04:11,998 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 25 | train -> loss: 2981.49761 | validation -> loss: 743.76676 | accuracy: 60.317463 | precision: 100.000000 | recall: 0.990099 | f2: 1.234568
2023-05-24 17:04:55,670 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 26 | train -> loss: 2985.79709 | validation -> loss: 746.70065 | accuracy: 61.706345 | precision: 100.000000 | recall: 4.455446 | f2: 5.507956
2023-05-24 17:05:40,008 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 27 | train -> loss: 2979.81842 | validation -> loss: 748.71937 | accuracy: 56.746029 | precision: 43.495934 | recall: 26.485147 | f2: 28.732544
2023-05-24 17:06:24,026 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 28 | train -> loss: 2989.24028 | validation -> loss: 754.21776 | accuracy: 62.896824 | precision: 96.875000 | recall: 7.673267 | f2: 9.405339
2023-05-24 17:07:08,284 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 29 | train -> loss: 2976.58387 | validation -> loss: 745.96966 | accuracy: 61.805557 | precision: 91.304352 | recall: 5.198020 | f2: 6.406345
2023-05-24 17:07:52,085 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 30 | train -> loss: 2986.87124 | validation -> loss: 753.92485 | accuracy: 62.003971 | precision: 86.206894 | recall: 6.188119 | f2: 7.598784
2023-05-24 17:08:36,937 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 31 | train -> loss: 2970.34070 | validation -> loss: 732.94013 | accuracy: 63.789684 | precision: 95.348831 | recall: 10.148515 | f2: 12.356842
2023-05-24 17:09:21,464 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 32 | train -> loss: 2958.93571 | validation -> loss: 729.28677 | accuracy: 60.912697 | precision: 51.865673 | recall: 34.405941 | f2: 36.889599
2023-05-24 17:10:05,573 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 33 | train -> loss: 2947.68783 | validation -> loss: 729.35452 | accuracy: 64.583328 | precision: 94.339622 | recall: 12.376238 | f2: 14.979029
2023-05-24 17:10:49,450 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 34 | train -> loss: 2827.48980 | validation -> loss: 757.33424 | accuracy: 56.150795 | precision: 42.213116 | recall: 25.495049 | f2: 27.688173
2023-05-24 17:11:33,067 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 35 | train -> loss: 2929.07869 | validation -> loss: 747.93708 | accuracy: 55.952381 | precision: 43.630573 | recall: 33.910892 | f2: 35.492229
2023-05-24 17:12:17,298 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 36 | train -> loss: 2934.62840 | validation -> loss: 732.54257 | accuracy: 63.988094 | precision: 78.873238 | recall: 13.861386 | f2: 16.597511
2023-05-24 17:13:01,536 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 37 | train -> loss: 2795.61823 | validation -> loss: 661.91545 | accuracy: 67.559525 | precision: 57.809330 | recall: 70.544556 | f2: 67.567566
2023-05-24 17:13:46,410 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 38 | train -> loss: 2968.69121 | validation -> loss: 751.00531 | accuracy: 52.678574 | precision: 38.338657 | recall: 29.702971 | f2: 31.104198
2023-05-24 17:14:29,702 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 39 | train -> loss: 2948.33624 | validation -> loss: 731.96830 | accuracy: 64.880959 | precision: 94.642860 | recall: 13.118813 | f2: 15.849282
2023-05-24 17:15:13,605 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 40 | train -> loss: 2897.99260 | validation -> loss: 722.53857 | accuracy: 65.575394 | precision: 91.304352 | recall: 15.594059 | f2: 18.694363
2023-05-24 17:15:57,630 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 41 | train -> loss: 2668.15043 | validation -> loss: 594.89532 | accuracy: 75.297615 | precision: 64.116577 | recall: 87.128708 | f2: 81.293304
2023-05-24 17:16:42,042 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 42 | train -> loss: 2482.16268 | validation -> loss: 736.54518 | accuracy: 58.234127 | precision: 47.176083 | recall: 35.148518 | f2: 37.037037
2023-05-24 17:17:26,010 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 43 | train -> loss: 2900.19987 | validation -> loss: 715.35987 | accuracy: 65.376984 | precision: 92.307693 | recall: 14.851485 | f2: 17.846519
2023-05-24 17:18:10,604 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 44 | train -> loss: 2456.87214 | validation -> loss: 583.62325 | accuracy: 75.000000 | precision: 63.194443 | recall: 90.099014 | f2: 83.029198
2023-05-24 17:18:54,999 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 45 | train -> loss: 2277.25324 | validation -> loss: 451.62132 | accuracy: 85.912697 | precision: 80.751175 | recall: 85.148514 | f2: 84.231148
2023-05-24 17:19:38,467 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 46 | train -> loss: 2034.47334 | validation -> loss: 518.36456 | accuracy: 80.456345 | precision: 70.495049 | recall: 88.118813 | f2: 83.922676
2023-05-24 17:20:22,370 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 47 | train -> loss: 2049.36396 | validation -> loss: 502.31138 | accuracy: 82.738098 | precision: 77.777779 | recall: 79.702965 | f2: 79.310349
2023-05-24 17:20:22,371 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 17:21:04,920 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 48 | train -> loss: 1963.99800 | validation -> loss: 491.95340 | accuracy: 83.234123 | precision: 78.588806 | recall: 79.950493 | f2: 79.674393
2023-05-24 17:21:49,163 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 49 | train -> loss: 1907.44414 | validation -> loss: 487.82268 | accuracy: 83.234123 | precision: 77.389275 | recall: 82.178215 | f2: 81.173592
2023-05-24 17:22:32,336 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 50 | train -> loss: 1890.27122 | validation -> loss: 481.22340 | accuracy: 83.630959 | precision: 78.117645 | recall: 82.178215 | f2: 81.332680
2023-05-24 17:23:17,497 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 51 | train -> loss: 1940.00426 | validation -> loss: 529.44245 | accuracy: 82.440475 | precision: 83.284454 | recall: 70.297035 | f2: 72.560043
2023-05-24 17:24:01,019 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 52 | train -> loss: 1946.57533 | validation -> loss: 484.88695 | accuracy: 84.424606 | precision: 82.758621 | recall: 77.227722 | f2: 78.273956
2023-05-24 17:24:45,161 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 53 | train -> loss: 1914.05135 | validation -> loss: 497.41635 | accuracy: 83.829369 | precision: 83.013702 | recall: 75.000000 | f2: 76.476524
2023-05-24 17:25:29,182 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 54 | train -> loss: 1911.05809 | validation -> loss: 485.55977 | accuracy: 84.325394 | precision: 82.712761 | recall: 76.980194 | f2: 78.062248
2023-05-24 17:26:13,537 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 55 | train -> loss: 1894.83674 | validation -> loss: 469.16279 | accuracy: 85.119041 | precision: 83.246078 | recall: 78.712868 | f2: 79.579582
2023-05-24 17:26:57,000 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 56 | train -> loss: 1780.17157 | validation -> loss: 449.89219 | accuracy: 85.615082 | precision: 81.975311 | recall: 82.178215 | f2: 82.137558
2023-05-24 17:27:41,297 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 57 | train -> loss: 1706.22986 | validation -> loss: 432.50252 | accuracy: 86.408730 | precision: 80.831406 | recall: 86.633667 | f2: 85.407516
2023-05-24 17:28:29,448 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 58 | train -> loss: 1620.36436 | validation -> loss: 458.46139 | accuracy: 85.218254 | precision: 80.141846 | recall: 83.910889 | f2: 83.128983
2023-05-24 17:29:15,839 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 59 | train -> loss: 1684.59254 | validation -> loss: 442.10634 | accuracy: 85.714287 | precision: 80.516434 | recall: 84.900986 | f2: 83.986290
2023-05-24 17:30:00,772 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 60 | train -> loss: 1703.34388 | validation -> loss: 452.67341 | accuracy: 84.623016 | precision: 77.362640 | recall: 87.128708 | f2: 84.983101
2023-05-24 17:30:45,398 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 61 | train -> loss: 1705.34028 | validation -> loss: 463.10558 | accuracy: 84.027779 | precision: 76.821190 | recall: 86.138611 | f2: 84.098595
2023-05-24 17:31:31,014 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 62 | train -> loss: 1726.33232 | validation -> loss: 444.36795 | accuracy: 85.317459 | precision: 78.828827 | recall: 86.633667 | f2: 84.951454
2023-05-24 17:32:16,869 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 63 | train -> loss: 1819.72872 | validation -> loss: 485.37737 | accuracy: 83.730164 | precision: 78.037384 | recall: 82.673271 | f2: 81.702545
2023-05-24 17:33:02,236 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 64 | train -> loss: 1808.19981 | validation -> loss: 448.43765 | accuracy: 85.218254 | precision: 79.582367 | recall: 84.900986 | f2: 83.781143
2023-05-24 17:33:47,737 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 65 | train -> loss: 1735.11949 | validation -> loss: 453.29186 | accuracy: 85.019836 | precision: 79.350349 | recall: 84.653465 | f2: 83.536880
2023-05-24 17:34:32,129 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 66 | train -> loss: 1703.83332 | validation -> loss: 446.26434 | accuracy: 85.416672 | precision: 79.540230 | recall: 85.643562 | f2: 84.349098
2023-05-24 17:35:17,176 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 67 | train -> loss: 1709.69908 | validation -> loss: 441.66062 | accuracy: 85.615082 | precision: 79.770111 | recall: 85.891090 | f2: 84.592880
2023-05-24 17:36:00,940 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 68 | train -> loss: 1694.98032 | validation -> loss: 434.91762 | accuracy: 86.011902 | precision: 80.369514 | recall: 86.138611 | f2: 84.919472
2023-05-24 17:36:45,611 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 69 | train -> loss: 1674.82650 | validation -> loss: 429.15241 | accuracy: 86.507935 | precision: 81.753555 | recall: 85.396042 | f2: 84.641808
2023-05-24 17:37:30,184 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 70 | train -> loss: 1654.39281 | validation -> loss: 419.15626 | accuracy: 86.706345 | precision: 81.990524 | recall: 85.643562 | f2: 84.887146
2023-05-24 17:38:15,438 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 71 | train -> loss: 1666.45707 | validation -> loss: 432.74116 | accuracy: 86.111107 | precision: 80.697670 | recall: 85.891090 | f2: 84.799614
2023-05-24 17:38:58,813 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 72 | train -> loss: 1666.69410 | validation -> loss: 445.01026 | accuracy: 85.019836 | precision: 77.559914 | recall: 88.118813 | f2: 85.783127
2023-05-24 17:39:43,986 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 73 | train -> loss: 1653.73971 | validation -> loss: 427.51417 | accuracy: 85.813492 | precision: 78.681320 | recall: 88.613861 | f2: 86.431679
2023-05-24 17:39:43,987 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 17:40:30,276 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 74 | train -> loss: 1613.12263 | validation -> loss: 416.52771 | accuracy: 86.607140 | precision: 80.224716 | recall: 88.366333 | f2: 86.608437
2023-05-24 17:41:15,277 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 75 | train -> loss: 1627.90844 | validation -> loss: 410.41416 | accuracy: 87.003967 | precision: 81.524246 | recall: 87.376236 | f2: 86.139580
2023-05-24 17:41:59,686 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 76 | train -> loss: 1590.92661 | validation -> loss: 410.04441 | accuracy: 87.202385 | precision: 82.201401 | recall: 86.881187 | f2: 85.903084
2023-05-24 17:42:44,556 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 77 | train -> loss: 1577.38834 | validation -> loss: 414.70751 | accuracy: 87.003967 | precision: 82.117645 | recall: 86.386139 | f2: 85.497307
2023-05-24 17:43:30,205 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 78 | train -> loss: 1570.81119 | validation -> loss: 418.86655 | accuracy: 86.904762 | precision: 82.075470 | recall: 86.138611 | f2: 85.294113
2023-05-24 17:44:15,674 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 79 | train -> loss: 1546.67681 | validation -> loss: 407.63462 | accuracy: 87.301590 | precision: 82.701424 | recall: 86.386139 | f2: 85.623154
2023-05-24 17:45:00,543 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 80 | train -> loss: 1539.90408 | validation -> loss: 412.48015 | accuracy: 87.301590 | precision: 83.014351 | recall: 85.891090 | f2: 85.299904
2023-05-24 17:45:46,810 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 81 | train -> loss: 2002.77762 | validation -> loss: 688.36674 | accuracy: 67.162697 | precision: 93.975899 | recall: 19.306931 | f2: 22.954678
2023-05-24 17:46:31,547 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 82 | train -> loss: 2737.18073 | validation -> loss: 696.67062 | accuracy: 65.277779 | precision: 90.909096 | recall: 14.851485 | f2: 17.835909
2023-05-24 17:47:14,744 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 83 | train -> loss: 2771.52317 | validation -> loss: 693.23690 | accuracy: 65.773811 | precision: 94.029846 | recall: 15.594059 | f2: 18.716578
2023-05-24 17:47:58,171 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 84 | train -> loss: 2647.85801 | validation -> loss: 639.76661 | accuracy: 69.742065 | precision: 93.805305 | recall: 26.237625 | f2: 30.653557
2023-05-24 17:48:39,894 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 85 | train -> loss: 1747.01564 | validation -> loss: 401.67794 | accuracy: 87.599205 | precision: 82.978729 | recall: 86.881187 | f2: 86.071602
2023-05-24 17:49:23,377 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 86 | train -> loss: 1532.77933 | validation -> loss: 416.80485 | accuracy: 86.904762 | precision: 81.336403 | recall: 87.376236 | f2: 86.097565
2023-05-24 17:50:06,458 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 87 | train -> loss: 1535.35793 | validation -> loss: 401.19361 | accuracy: 87.599205 | precision: 82.517479 | recall: 87.623764 | f2: 86.552567
2023-05-24 17:50:51,322 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 88 | train -> loss: 1536.96811 | validation -> loss: 406.85329 | accuracy: 87.301590 | precision: 82.093025 | recall: 87.376236 | f2: 86.265884
2023-05-24 17:51:36,112 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 89 | train -> loss: 1525.84104 | validation -> loss: 405.61684 | accuracy: 87.301590 | precision: 81.944443 | recall: 87.623764 | f2: 86.425781
2023-05-24 17:52:22,068 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 90 | train -> loss: 1518.52109 | validation -> loss: 405.37243 | accuracy: 87.301590 | precision: 81.944443 | recall: 87.623764 | f2: 86.425781
2023-05-24 17:53:07,472 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 91 | train -> loss: 1559.64287 | validation -> loss: 410.96475 | accuracy: 87.500000 | precision: 84.068626 | recall: 84.900986 | f2: 84.733200
2023-05-24 17:53:53,576 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 92 | train -> loss: 1516.68599 | validation -> loss: 396.23405 | accuracy: 87.996033 | precision: 83.770882 | recall: 86.881187 | f2: 86.240784
2023-05-24 17:54:42,209 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 93 | train -> loss: 1535.72395 | validation -> loss: 412.66751 | accuracy: 87.103180 | precision: 81.566826 | recall: 87.623764 | f2: 86.341461
2023-05-24 17:55:28,701 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 94 | train -> loss: 1528.65541 | validation -> loss: 416.54763 | accuracy: 86.805557 | precision: 81.006866 | recall: 87.623764 | f2: 86.215294
2023-05-24 17:56:14,106 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 95 | train -> loss: 1525.42358 | validation -> loss: 411.38998 | accuracy: 87.003967 | precision: 81.379311 | recall: 87.623764 | f2: 86.299362
2023-05-24 17:56:58,063 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 96 | train -> loss: 1530.35610 | validation -> loss: 414.15749 | accuracy: 87.003967 | precision: 81.524246 | recall: 87.376236 | f2: 86.139580
2023-05-24 17:57:42,509 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 97 | train -> loss: 1513.55621 | validation -> loss: 408.15328 | accuracy: 87.500000 | precision: 82.629105 | recall: 87.128708 | f2: 86.190010
2023-05-24 17:58:28,432 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 98 | train -> loss: 1535.20384 | validation -> loss: 398.23594 | accuracy: 87.896820 | precision: 83.098587 | recall: 87.623764 | f2: 86.679726
2023-05-24 17:59:14,603 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 99 | train -> loss: 1520.32424 | validation -> loss: 395.60997 | accuracy: 87.896820 | precision: 83.254715 | recall: 87.376236 | f2: 86.519608
2023-05-24 17:59:14,604 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 17:59:58,331 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 100 | train -> loss: 1516.25801 | validation -> loss: 395.39220 | accuracy: 87.896820 | precision: 83.254715 | recall: 87.376236 | f2: 86.519608
2023-05-24 17:59:58,446 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f3/model_fold3.pth
2023-05-24 17:59:58,786 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 17:59:58,789 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD2281EB0>
2023-05-24 17:59:58,789 | root | INFO | rnn.py learn @ 85 : fetching data for fold #4
2023-05-24 17:59:58,792 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 17:59:58,793 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 17:59:58,795 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 17:59:58,796 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 18:00:45,484 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 1 | train -> loss: 2985.42214 | validation -> loss: 737.51136 | accuracy: 63.753723 | precision: 91.304352 | recall: 10.421837 | f2: 12.665862
2023-05-24 18:01:31,160 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 2 | train -> loss: 3066.52118 | validation -> loss: 750.76621 | accuracy: 52.135056 | precision: 42.147118 | recall: 52.605457 | f2: 50.118202
2023-05-24 18:02:15,810 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 3 | train -> loss: 3094.42015 | validation -> loss: 764.22986 | accuracy: 50.248260 | precision: 40.040649 | recall: 48.883377 | f2: 46.815590
2023-05-24 18:03:01,742 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 4 | train -> loss: 2964.46602 | validation -> loss: 714.63021 | accuracy: 65.739822 | precision: 54.084511 | recall: 95.285362 | f2: 82.687340
2023-05-24 18:03:47,681 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 5 | train -> loss: 3047.21605 | validation -> loss: 784.10299 | accuracy: 51.042702 | precision: 42.077465 | recall: 59.305210 | f2: 54.816513
2023-05-24 18:04:35,341 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 6 | train -> loss: 3017.18295 | validation -> loss: 783.67425 | accuracy: 51.539223 | precision: 42.286751 | recall: 57.816376 | f2: 53.860378
2023-05-24 18:05:24,401 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 7 | train -> loss: 3025.08629 | validation -> loss: 731.58186 | accuracy: 64.448860 | precision: 92.452827 | recall: 12.158809 | f2: 14.714715
2023-05-24 18:06:09,427 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 8 | train -> loss: 2591.67934 | validation -> loss: 765.97842 | accuracy: 61.072495 | precision: 50.713360 | recall: 97.022331 | f2: 82.039444
2023-05-24 18:06:55,817 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 9 | train -> loss: 2907.75931 | validation -> loss: 722.06218 | accuracy: 65.739822 | precision: 100.000000 | recall: 14.392060 | f2: 17.365269
2023-05-24 18:07:41,278 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 10 | train -> loss: 2974.73176 | validation -> loss: 785.69158 | accuracy: 48.857994 | precision: 38.571430 | recall: 46.898262 | f2: 44.957184
2023-05-24 18:08:27,149 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 11 | train -> loss: 3009.14539 | validation -> loss: 746.41109 | accuracy: 62.661369 | precision: 96.551720 | recall: 6.947891 | f2: 8.531384
2023-05-24 18:09:13,862 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 12 | train -> loss: 2982.22811 | validation -> loss: 767.85668 | accuracy: 50.248260 | precision: 40.684410 | recall: 53.101738 | f2: 50.046772
2023-05-24 18:09:59,057 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 13 | train -> loss: 2815.88472 | validation -> loss: 743.64256 | accuracy: 60.675274 | precision: 100.000000 | recall: 1.736973 | f2: 2.161828
2023-05-24 18:10:44,143 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 14 | train -> loss: 2997.09094 | validation -> loss: 753.84724 | accuracy: 63.555115 | precision: 90.909096 | recall: 9.925558 | f2: 12.077295
2023-05-24 18:11:28,849 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 15 | train -> loss: 2944.48296 | validation -> loss: 783.05483 | accuracy: 49.851044 | precision: 39.759037 | recall: 49.131512 | f2: 46.919434
2023-05-24 18:12:14,177 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 16 | train -> loss: 2955.22405 | validation -> loss: 744.86959 | accuracy: 64.250252 | precision: 83.076927 | recall: 13.399504 | f2: 16.100178
2023-05-24 18:12:58,190 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 17 | train -> loss: 2791.09250 | validation -> loss: 726.93554 | accuracy: 65.342598 | precision: 89.705887 | recall: 15.136476 | f2: 18.154760
2023-05-24 18:13:43,794 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 18 | train -> loss: 2854.73375 | validation -> loss: 715.45816 | accuracy: 68.222443 | precision: 87.387390 | recall: 24.069479 | f2: 28.148577
2023-05-24 18:14:30,692 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 19 | train -> loss: 2687.58439 | validation -> loss: 716.41535 | accuracy: 65.243301 | precision: 96.491226 | recall: 13.647643 | f2: 16.476933
2023-05-24 18:15:18,118 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 20 | train -> loss: 2330.25462 | validation -> loss: 751.53392 | accuracy: 49.056606 | precision: 38.911289 | recall: 47.890820 | f2: 45.777988
2023-05-24 18:16:04,141 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 21 | train -> loss: 2996.74870 | validation -> loss: 731.96967 | accuracy: 63.654415 | precision: 93.023262 | recall: 9.925558 | f2: 12.084592
2023-05-24 18:16:04,142 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 18:16:49,064 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 22 | train -> loss: 2945.00964 | validation -> loss: 731.79815 | accuracy: 64.250252 | precision: 93.877556 | recall: 11.414392 | f2: 13.847080
2023-05-24 18:17:32,448 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 23 | train -> loss: 2907.09933 | validation -> loss: 714.72036 | accuracy: 66.037735 | precision: 92.957748 | recall: 16.377172 | f2: 19.607843
2023-05-24 18:18:15,645 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 24 | train -> loss: 2148.56331 | validation -> loss: 740.74864 | accuracy: 61.866932 | precision: 91.304352 | recall: 5.210918 | f2: 6.422018
2023-05-24 18:18:58,971 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 25 | train -> loss: 2962.33586 | validation -> loss: 740.06643 | accuracy: 63.058590 | precision: 91.891891 | recall: 8.436725 | f2: 10.309278
2023-05-24 18:19:42,342 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 26 | train -> loss: 2936.28402 | validation -> loss: 730.00447 | accuracy: 64.746773 | precision: 92.857140 | recall: 12.903225 | f2: 15.587529
2023-05-24 18:20:24,644 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 27 | train -> loss: 2767.75105 | validation -> loss: 424.40113 | accuracy: 85.898712 | precision: 77.944328 | recall: 90.322578 | f2: 87.542084
2023-05-24 18:21:07,917 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 28 | train -> loss: 1652.51223 | validation -> loss: 418.75418 | accuracy: 86.395233 | precision: 79.424782 | recall: 89.081886 | f2: 86.967056
2023-05-24 18:21:51,931 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 29 | train -> loss: 1595.75697 | validation -> loss: 392.33627 | accuracy: 87.288979 | precision: 79.826462 | recall: 91.315140 | f2: 88.760254
2023-05-24 18:22:35,378 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 30 | train -> loss: 1562.52045 | validation -> loss: 448.79820 | accuracy: 86.593842 | precision: 83.004929 | recall: 83.622833 | f2: 83.498512
2023-05-24 18:23:20,234 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 31 | train -> loss: 1615.58849 | validation -> loss: 390.80044 | accuracy: 87.785500 | precision: 82.110092 | recall: 88.833748 | f2: 87.402344
2023-05-24 18:24:05,553 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 32 | train -> loss: 1588.12038 | validation -> loss: 390.89088 | accuracy: 87.984108 | precision: 82.045456 | recall: 89.578163 | f2: 87.962959
2023-05-24 18:24:51,597 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 33 | train -> loss: 1540.25408 | validation -> loss: 379.15552 | accuracy: 88.480637 | precision: 82.539680 | recall: 90.322578 | f2: 88.650757
2023-05-24 18:25:36,922 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 34 | train -> loss: 1520.12956 | validation -> loss: 375.96934 | accuracy: 88.579941 | precision: 83.333328 | recall: 89.330025 | f2: 88.062622
2023-05-24 18:26:22,357 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 35 | train -> loss: 1671.03869 | validation -> loss: 417.11339 | accuracy: 85.600792 | precision: 76.434425 | recall: 92.555832 | f2: 88.809525
2023-05-24 18:27:08,782 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 36 | train -> loss: 1562.38759 | validation -> loss: 391.04905 | accuracy: 87.686195 | precision: 81.632652 | recall: 89.330025 | f2: 87.676575
2023-05-24 18:27:52,360 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 37 | train -> loss: 1534.93939 | validation -> loss: 390.43697 | accuracy: 87.884811 | precision: 82.004555 | recall: 89.330025 | f2: 87.762070
2023-05-24 18:28:36,016 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 38 | train -> loss: 1526.40845 | validation -> loss: 387.48428 | accuracy: 87.984108 | precision: 82.045456 | recall: 89.578163 | f2: 87.962959
2023-05-24 18:29:22,151 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 39 | train -> loss: 1511.93927 | validation -> loss: 381.42822 | accuracy: 87.586891 | precision: 79.828331 | recall: 92.307693 | f2: 89.509140
2023-05-24 18:30:07,235 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 40 | train -> loss: 1477.31438 | validation -> loss: 372.75946 | accuracy: 87.984108 | precision: 80.652168 | recall: 92.059555 | f2: 89.527031
2023-05-24 18:30:52,239 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 41 | train -> loss: 1469.24543 | validation -> loss: 365.30844 | accuracy: 88.480637 | precision: 81.677704 | recall: 91.811409 | f2: 89.588379
2023-05-24 18:31:36,928 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 42 | train -> loss: 2002.09462 | validation -> loss: 707.05714 | accuracy: 64.548164 | precision: 88.333336 | recall: 13.151364 | f2: 15.849282
2023-05-24 18:32:20,456 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 43 | train -> loss: 2124.20575 | validation -> loss: 411.54226 | accuracy: 85.700104 | precision: 76.267746 | recall: 93.300247 | f2: 89.311165
2023-05-24 18:33:03,369 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 44 | train -> loss: 1542.47935 | validation -> loss: 382.00276 | accuracy: 87.487587 | precision: 79.657387 | recall: 92.307693 | f2: 89.466087
2023-05-24 18:33:47,625 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 45 | train -> loss: 1489.78798 | validation -> loss: 378.47141 | accuracy: 87.984108 | precision: 80.786026 | recall: 91.811409 | f2: 89.371979
2023-05-24 18:34:31,495 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 46 | train -> loss: 1478.82091 | validation -> loss: 374.40181 | accuracy: 88.381332 | precision: 81.497795 | recall: 91.811409 | f2: 89.545021
2023-05-24 18:35:14,522 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 47 | train -> loss: 1487.13476 | validation -> loss: 349.50241 | accuracy: 89.771599 | precision: 84.883720 | recall: 90.570717 | f2: 89.373169
2023-05-24 18:35:14,523 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 18:35:57,564 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 48 | train -> loss: 1419.53488 | validation -> loss: 351.58973 | accuracy: 89.572990 | precision: 84.490738 | recall: 90.570717 | f2: 89.285713
2023-05-24 18:36:40,589 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 49 | train -> loss: 1414.68342 | validation -> loss: 347.32580 | accuracy: 89.870903 | precision: 85.081581 | recall: 90.570717 | f2: 89.416954
2023-05-24 18:37:23,351 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 50 | train -> loss: 1411.05794 | validation -> loss: 353.45680 | accuracy: 89.473686 | precision: 84.295616 | recall: 90.570717 | f2: 89.242050
2023-05-24 18:38:07,233 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 51 | train -> loss: 1394.89998 | validation -> loss: 356.30384 | accuracy: 88.877853 | precision: 82.119202 | recall: 92.307693 | f2: 90.072639
2023-05-24 18:38:49,271 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 52 | train -> loss: 1428.39457 | validation -> loss: 358.11703 | accuracy: 88.778549 | precision: 82.222221 | recall: 91.811409 | f2: 89.718719
2023-05-24 18:39:31,733 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 53 | train -> loss: 1386.92549 | validation -> loss: 345.68650 | accuracy: 89.672295 | precision: 84.054665 | recall: 91.563271 | f2: 89.956116
2023-05-24 18:40:14,677 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 54 | train -> loss: 1368.86792 | validation -> loss: 344.68971 | accuracy: 89.870903 | precision: 84.282455 | recall: 91.811409 | f2: 90.199898
2023-05-24 18:40:57,027 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 55 | train -> loss: 1376.75652 | validation -> loss: 352.04646 | accuracy: 89.275070 | precision: 83.295708 | recall: 91.563271 | f2: 89.781021
2023-05-24 18:41:39,158 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 56 | train -> loss: 1370.16082 | validation -> loss: 344.00443 | accuracy: 89.771599 | precision: 84.246574 | recall: 91.563271 | f2: 90.000000
2023-05-24 18:42:21,881 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 57 | train -> loss: 1363.81379 | validation -> loss: 352.96931 | accuracy: 89.374382 | precision: 83.333328 | recall: 91.811409 | f2: 89.980545
2023-05-24 18:43:04,211 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 58 | train -> loss: 1401.91106 | validation -> loss: 352.91658 | accuracy: 89.275070 | precision: 83.446709 | recall: 91.315140 | f2: 89.624939
2023-05-24 18:43:45,567 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 59 | train -> loss: 1372.98775 | validation -> loss: 340.99853 | accuracy: 89.870903 | precision: 85.081581 | recall: 90.570717 | f2: 89.416954
2023-05-24 18:44:28,890 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 60 | train -> loss: 1371.56256 | validation -> loss: 346.30111 | accuracy: 90.069511 | precision: 85.480095 | recall: 90.570717 | f2: 89.504662
2023-05-24 18:45:11,763 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 61 | train -> loss: 1364.26886 | validation -> loss: 344.94485 | accuracy: 89.870903 | precision: 84.918793 | recall: 90.818855 | f2: 89.574158
2023-05-24 18:45:53,767 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 62 | train -> loss: 1385.79829 | validation -> loss: 338.18628 | accuracy: 90.168816 | precision: 85.680756 | recall: 90.570717 | f2: 89.548576
2023-05-24 18:46:36,351 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 63 | train -> loss: 1355.98744 | validation -> loss: 346.73696 | accuracy: 90.168816 | precision: 86.363640 | recall: 89.578163 | f2: 88.916252
2023-05-24 18:47:18,907 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 64 | train -> loss: 1378.34331 | validation -> loss: 334.71622 | accuracy: 90.268120 | precision: 86.223282 | recall: 90.074448 | f2: 89.276924
2023-05-24 18:48:01,203 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 65 | train -> loss: 1473.12285 | validation -> loss: 740.09045 | accuracy: 87.090370 | precision: 83.870964 | recall: 83.870964 | f2: 83.870964
2023-05-24 18:48:44,256 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 66 | train -> loss: 1802.96561 | validation -> loss: 381.37629 | accuracy: 89.473686 | precision: 87.786255 | recall: 85.607941 | f2: 86.034912
2023-05-24 18:49:27,292 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 67 | train -> loss: 1382.07030 | validation -> loss: 339.22550 | accuracy: 90.963257 | precision: 89.593910 | recall: 87.593056 | f2: 87.986038
2023-05-24 18:50:10,197 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 68 | train -> loss: 1365.49902 | validation -> loss: 347.01930 | accuracy: 90.665344 | precision: 89.514069 | recall: 86.848633 | f2: 87.368950
2023-05-24 18:50:52,449 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 69 | train -> loss: 1369.18932 | validation -> loss: 334.80865 | accuracy: 90.963257 | precision: 89.000000 | recall: 88.337471 | f2: 88.469185
2023-05-24 18:51:35,717 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 70 | train -> loss: 1347.33482 | validation -> loss: 336.32046 | accuracy: 90.863953 | precision: 88.778053 | recall: 88.337471 | f2: 88.425240
2023-05-24 18:52:18,661 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 71 | train -> loss: 1358.61867 | validation -> loss: 342.61209 | accuracy: 90.268120 | precision: 86.396179 | recall: 89.826302 | f2: 89.118660
2023-05-24 18:53:00,568 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 72 | train -> loss: 1361.26788 | validation -> loss: 337.87069 | accuracy: 90.566040 | precision: 87.019226 | recall: 89.826302 | f2: 89.250496
2023-05-24 18:53:43,821 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 73 | train -> loss: 1341.39721 | validation -> loss: 342.45495 | accuracy: 90.367432 | precision: 86.956520 | recall: 89.330025 | f2: 88.845016
2023-05-24 18:53:43,822 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 18:54:26,548 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 74 | train -> loss: 1340.01249 | validation -> loss: 350.22108 | accuracy: 89.870903 | precision: 85.918854 | recall: 89.330025 | f2: 88.626297
2023-05-24 18:55:09,645 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 75 | train -> loss: 1341.30973 | validation -> loss: 342.91221 | accuracy: 90.268120 | precision: 86.396179 | recall: 89.826302 | f2: 89.118660
2023-05-24 18:55:51,128 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 76 | train -> loss: 1343.53776 | validation -> loss: 340.64296 | accuracy: 90.466728 | precision: 86.987953 | recall: 89.578163 | f2: 89.047852
2023-05-24 18:56:34,109 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 77 | train -> loss: 1337.70210 | validation -> loss: 343.01914 | accuracy: 90.268120 | precision: 86.570747 | recall: 89.578163 | f2: 88.960083
2023-05-24 18:57:15,917 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 78 | train -> loss: 1331.13440 | validation -> loss: 349.93264 | accuracy: 90.069511 | precision: 86.506027 | recall: 89.081886 | f2: 88.554512
2023-05-24 18:57:58,569 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 79 | train -> loss: 1317.20200 | validation -> loss: 339.79274 | accuracy: 90.566040 | precision: 87.745102 | recall: 88.833748 | f2: 88.613861
2023-05-24 18:58:42,086 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 80 | train -> loss: 1284.61917 | validation -> loss: 307.52437 | accuracy: 90.466728 | precision: 87.530563 | recall: 88.833748 | f2: 88.570015
2023-05-24 18:59:25,604 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 81 | train -> loss: 1189.36929 | validation -> loss: 300.24522 | accuracy: 90.466728 | precision: 87.530563 | recall: 88.833748 | f2: 88.570015
2023-05-24 19:00:08,963 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 82 | train -> loss: 1254.39870 | validation -> loss: 301.82422 | accuracy: 90.168816 | precision: 87.438423 | recall: 88.089333 | f2: 87.958374
2023-05-24 19:00:52,434 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 83 | train -> loss: 1164.64227 | validation -> loss: 301.38641 | accuracy: 90.069511 | precision: 87.223587 | recall: 88.089333 | f2: 87.914810
2023-05-24 19:01:35,522 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 84 | train -> loss: 1154.56241 | validation -> loss: 298.41376 | accuracy: 90.069511 | precision: 87.593056 | recall: 87.593056 | f2: 87.593056
2023-05-24 19:02:19,216 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 85 | train -> loss: 1147.96796 | validation -> loss: 298.43743 | accuracy: 90.168816 | precision: 87.810944 | recall: 87.593056 | f2: 87.636543
2023-05-24 19:03:01,851 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 86 | train -> loss: 1147.43043 | validation -> loss: 296.61301 | accuracy: 90.069511 | precision: 87.780548 | recall: 87.344917 | f2: 87.431694
2023-05-24 19:03:44,591 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 87 | train -> loss: 1155.37640 | validation -> loss: 291.61073 | accuracy: 90.466728 | precision: 88.860764 | recall: 87.096771 | f2: 87.443947
2023-05-24 19:04:26,873 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 88 | train -> loss: 1137.47188 | validation -> loss: 300.55778 | accuracy: 90.069511 | precision: 88.161209 | recall: 86.848633 | f2: 87.108017
2023-05-24 19:05:09,566 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 89 | train -> loss: 1250.02582 | validation -> loss: 295.38709 | accuracy: 90.466728 | precision: 88.471184 | recall: 87.593056 | f2: 87.767281
2023-05-24 19:05:51,798 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 90 | train -> loss: 1141.19870 | validation -> loss: 296.15436 | accuracy: 90.168816 | precision: 87.810944 | recall: 87.593056 | f2: 87.636543
2023-05-24 19:06:34,735 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 91 | train -> loss: 1136.76988 | validation -> loss: 291.53293 | accuracy: 90.268120 | precision: 88.220551 | recall: 87.344917 | f2: 87.518654
2023-05-24 19:07:17,181 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 92 | train -> loss: 1139.26172 | validation -> loss: 290.44624 | accuracy: 90.268120 | precision: 88.220551 | recall: 87.344917 | f2: 87.518654
2023-05-24 19:08:00,306 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 93 | train -> loss: 1228.21143 | validation -> loss: 370.62906 | accuracy: 90.466728 | precision: 88.089333 | recall: 88.089333 | f2: 88.089333
2023-05-24 19:08:43,119 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 94 | train -> loss: 1348.68249 | validation -> loss: 342.12898 | accuracy: 90.764648 | precision: 88.366333 | recall: 88.585609 | f2: 88.541672
2023-05-24 19:09:25,190 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 95 | train -> loss: 1283.16330 | validation -> loss: 305.19666 | accuracy: 89.870903 | precision: 86.440674 | recall: 88.585609 | f2: 88.148148
2023-05-24 19:10:07,398 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 96 | train -> loss: 1149.39615 | validation -> loss: 297.61146 | accuracy: 89.970207 | precision: 87.376236 | recall: 87.593056 | f2: 87.549606
2023-05-24 19:10:49,659 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 97 | train -> loss: 1178.92394 | validation -> loss: 359.43288 | accuracy: 90.466728 | precision: 88.471184 | recall: 87.593056 | f2: 87.767281
2023-05-24 19:11:31,019 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 98 | train -> loss: 1246.91003 | validation -> loss: 300.96055 | accuracy: 90.069511 | precision: 88.161209 | recall: 86.848633 | f2: 87.108017
2023-05-24 19:12:13,332 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 99 | train -> loss: 1133.76291 | validation -> loss: 288.41057 | accuracy: 90.367432 | precision: 88.250000 | recall: 87.593056 | f2: 87.723663
2023-05-24 19:12:13,333 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 19:12:54,829 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 100 | train -> loss: 1121.89620 | validation -> loss: 289.17367 | accuracy: 90.268120 | precision: 88.220551 | recall: 87.344917 | f2: 87.518654
2023-05-24 19:12:54,945 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f4/model_fold4.pth
2023-05-24 19:12:55,274 | root | INFO | rnn.py learn @ 166 : best model of cross validation for current training phase: fold #3 with metric value of '0.8737623691558838'
2023-05-24 19:12:55,339 | root | INFO | main.py run @ 84 : started new command `test` of session `rnn-balanced-v2-04`
2023-05-24 19:12:55,357 | root | INFO | dataset.py preprocess @ 503 : trying to load tokens from file
2023-05-24 19:12:56,161 | root | INFO | dataset.py __vectorize__ @ 103 : loading vectors from file
2023-05-24 19:13:01,101 | root | INFO | dataset.py prepare @ 239 : data preparation finished
2023-05-24 19:13:06,779 | root | INFO | rnn.py load_params @ 202 : loaded model weights from file: output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/best_model.pth
2023-05-24 19:14:13,550 | root | INFO | rnn.py test @ 190 : predictions are saved at: output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/preds.pkl
2023-05-24 19:14:13,552 | root | INFO | rnn.py test @ 193 : targets are saved at: output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/targets.pkl
2023-05-24 19:14:13,552 | root | WARNING | main.py run @ 83 : no dataset was specified.
2023-05-24 19:14:13,553 | root | INFO | main.py run @ 84 : started new command `eval` of session `rnn-balanced-v2-04`
2023-05-24 19:14:13,803 | root | INFO | baseline.py evaluate @ 67 : saving ROC curve at: output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/ROC-curve.png
2023-05-24 19:14:13,970 | root | INFO | baseline.py evaluate @ 74 : saving precision-recall curve at: output/05-24-2023-13-12-01-rnn-balanced-v2-04/base-rnn/basic-sequential/rr.idr-lr0.000500-h512-l1/precision-recall-curve.png
2023-05-24 19:14:13,987 | root | INFO | baseline.py evaluate @ 77 : test set -> AUCROC: 0.8499330 | AUCPR: 0.8026983 | accuracy: 0.8600942 | precision: 0.8142895 | recall: 0.8323304
2023-05-24 19:14:13,988 | root | INFO | main.py run @ 73 : started new session: lstm-balanced-v2-04
2023-05-24 19:14:13,988 | root | INFO | main.py create_model_configs @ 37 : activation module kwargs: {}
2023-05-24 19:14:13,990 | root | INFO | main.py create_model_configs @ 38 : loss module kwargs: {'reduction': 'sum', 'pos_weight': tensor(1.2000)}
2023-05-24 19:14:13,991 | root | INFO | main.py run @ 84 : started new command `train` of session `lstm-balanced-v2-04`
2023-05-24 19:14:14,002 | root | INFO | dataset.py split_dataset_by_label @ 158 : loading splits from: data/preprocessed/sequential-v2-04/basic-sequential/rr.idr/splits-n5stratified.pkl
2023-05-24 19:14:14,767 | root | INFO | rnn.py learn @ 78 : training phase started
2023-05-24 19:14:14,768 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 19:14:14,769 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBC75030D0>
2023-05-24 19:14:14,770 | root | INFO | rnn.py learn @ 85 : fetching data for fold #0
2023-05-24 19:14:14,770 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 19:14:14,771 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 19:14:14,772 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 19:14:14,772 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 19:15:07,498 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 1 | train -> loss: 2495.46477 | validation -> loss: 521.05960 | accuracy: 81.944443 | precision: 89.045937 | recall: 62.531017 | f2: 66.490761
2023-05-24 19:15:59,549 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 2 | train -> loss: 2027.50786 | validation -> loss: 854.60585 | accuracy: 60.019840 | precision: 0.000000 | recall: 0.000000 | f2: 0.000000
2023-05-24 19:16:52,697 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 3 | train -> loss: 3037.02563 | validation -> loss: 744.84651 | accuracy: 60.714287 | precision: 100.000000 | recall: 1.736973 | f2: 2.161828
2023-05-24 19:17:45,259 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 4 | train -> loss: 2980.94657 | validation -> loss: 753.67627 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.248139 | f2: 0.309981
2023-05-24 19:18:37,929 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 5 | train -> loss: 3018.28083 | validation -> loss: 751.67288 | accuracy: 54.761906 | precision: 34.857143 | recall: 15.136476 | f2: 17.067711
2023-05-24 19:19:30,810 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 6 | train -> loss: 2992.42605 | validation -> loss: 747.24189 | accuracy: 60.218258 | precision: 100.000000 | recall: 0.496278 | f2: 0.619579
2023-05-24 19:20:22,373 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 7 | train -> loss: 2987.17751 | validation -> loss: 744.77623 | accuracy: 61.011906 | precision: 81.250000 | recall: 3.225806 | f2: 3.992629
2023-05-24 19:21:13,601 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 8 | train -> loss: 2979.95729 | validation -> loss: 746.96083 | accuracy: 59.623016 | precision: 48.823528 | recall: 20.595533 | f2: 23.288439
2023-05-24 19:22:05,960 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 9 | train -> loss: 2568.92444 | validation -> loss: 554.41881 | accuracy: 77.380959 | precision: 66.990295 | recall: 85.607941 | f2: 81.100143
2023-05-24 19:22:58,036 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 10 | train -> loss: 2215.70246 | validation -> loss: 610.71599 | accuracy: 83.234123 | precision: 72.941177 | recall: 92.307693 | f2: 87.653160
2023-05-24 19:23:50,574 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 11 | train -> loss: 1733.08059 | validation -> loss: 297.66968 | accuracy: 90.079369 | precision: 87.407410 | recall: 87.841187 | f2: 87.754089
2023-05-24 19:24:42,834 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 12 | train -> loss: 854.14994 | validation -> loss: 241.11637 | accuracy: 91.071426 | precision: 82.672234 | recall: 98.263023 | f2: 94.691536
2023-05-24 19:25:35,150 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 13 | train -> loss: 512.83152 | validation -> loss: 280.88871 | accuracy: 89.285713 | precision: 79.797974 | recall: 98.014893 | f2: 93.735168
2023-05-24 19:26:27,326 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 14 | train -> loss: 363.36827 | validation -> loss: 326.38747 | accuracy: 88.591270 | precision: 78.235291 | recall: 99.007446 | f2: 94.015083
2023-05-24 19:27:20,315 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 15 | train -> loss: 323.26735 | validation -> loss: 300.65339 | accuracy: 89.186508 | precision: 80.882355 | recall: 95.533493 | f2: 92.193481
2023-05-24 19:28:12,769 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 16 | train -> loss: 249.72065 | validation -> loss: 469.59457 | accuracy: 87.202385 | precision: 76.757812 | recall: 97.518608 | f2: 92.514122
2023-05-24 19:29:04,319 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 17 | train -> loss: 222.00450 | validation -> loss: 458.60108 | accuracy: 88.095238 | precision: 78.470825 | recall: 96.774193 | f2: 92.460884
2023-05-24 19:29:56,737 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 18 | train -> loss: 203.08331 | validation -> loss: 401.62953 | accuracy: 87.599205 | precision: 77.800003 | recall: 96.526054 | f2: 92.092804
2023-05-24 19:30:48,358 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 19 | train -> loss: 186.44169 | validation -> loss: 385.74900 | accuracy: 88.888893 | precision: 79.275658 | recall: 97.766754 | f2: 93.409195
2023-05-24 19:31:40,677 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 20 | train -> loss: 138.61163 | validation -> loss: 472.88383 | accuracy: 87.797615 | precision: 77.559052 | recall: 97.766754 | f2: 92.924530
2023-05-24 19:32:32,973 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 21 | train -> loss: 174.61014 | validation -> loss: 379.86778 | accuracy: 89.880959 | precision: 81.288979 | recall: 97.022331 | f2: 93.406593
2023-05-24 19:32:32,974 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 19:33:24,880 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 22 | train -> loss: 107.60211 | validation -> loss: 472.14061 | accuracy: 88.690475 | precision: 79.310349 | recall: 97.022331 | f2: 92.874107
2023-05-24 19:34:17,063 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 23 | train -> loss: 122.93319 | validation -> loss: 390.45666 | accuracy: 89.384918 | precision: 80.962341 | recall: 96.029778 | f2: 92.583733
2023-05-24 19:35:08,801 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 24 | train -> loss: 93.54352 | validation -> loss: 458.54655 | accuracy: 89.583328 | precision: 80.912865 | recall: 96.774193 | f2: 93.123207
2023-05-24 19:36:00,825 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 25 | train -> loss: 84.36529 | validation -> loss: 498.88231 | accuracy: 89.484123 | precision: 81.663116 | recall: 95.037224 | f2: 92.023071
2023-05-24 19:36:52,944 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 26 | train -> loss: 90.39611 | validation -> loss: 593.44601 | accuracy: 87.797615 | precision: 77.888451 | recall: 97.022331 | f2: 92.478714
2023-05-24 19:37:44,949 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 27 | train -> loss: 80.24037 | validation -> loss: 510.35487 | accuracy: 88.789680 | precision: 80.590721 | recall: 94.789085 | f2: 91.562805
2023-05-24 19:38:37,326 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 28 | train -> loss: 72.89840 | validation -> loss: 552.00196 | accuracy: 88.392860 | precision: 79.668053 | recall: 95.285362 | f2: 91.690544
2023-05-24 19:39:30,342 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 29 | train -> loss: 68.48978 | validation -> loss: 621.48847 | accuracy: 88.492065 | precision: 79.710144 | recall: 95.533493 | f2: 91.885445
2023-05-24 19:40:22,978 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 30 | train -> loss: 66.71787 | validation -> loss: 650.18910 | accuracy: 87.896820 | precision: 78.269615 | recall: 96.526054 | f2: 92.223808
2023-05-24 19:41:15,864 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 31 | train -> loss: 58.16378 | validation -> loss: 752.53044 | accuracy: 87.896820 | precision: 78.383842 | recall: 96.277916 | f2: 92.074036
2023-05-24 19:42:08,259 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 32 | train -> loss: 60.38109 | validation -> loss: 554.00027 | accuracy: 89.087303 | precision: 80.842110 | recall: 95.285362 | f2: 91.998085
2023-05-24 19:42:59,699 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 33 | train -> loss: 67.39135 | validation -> loss: 635.11848 | accuracy: 88.988098 | precision: 80.290451 | recall: 96.029778 | f2: 92.406876
2023-05-24 19:43:51,446 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 34 | train -> loss: 82.48860 | validation -> loss: 585.90350 | accuracy: 88.492065 | precision: 79.466118 | recall: 96.029778 | f2: 92.186752
2023-05-24 19:44:43,981 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 35 | train -> loss: 50.54207 | validation -> loss: 688.19890 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 19:45:36,797 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 36 | train -> loss: 45.36951 | validation -> loss: 657.98421 | accuracy: 88.492065 | precision: 79.587624 | recall: 95.781639 | f2: 92.036240
2023-05-24 19:46:28,646 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 37 | train -> loss: 39.21022 | validation -> loss: 858.25017 | accuracy: 87.797615 | precision: 78.455284 | recall: 95.781639 | f2: 91.730042
2023-05-24 19:47:20,912 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 38 | train -> loss: 37.67833 | validation -> loss: 808.26032 | accuracy: 88.492065 | precision: 79.710144 | recall: 95.533493 | f2: 91.885445
2023-05-24 19:48:12,116 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 39 | train -> loss: 85.16071 | validation -> loss: 540.94138 | accuracy: 89.682541 | precision: 81.473686 | recall: 96.029778 | f2: 92.716820
2023-05-24 19:49:03,881 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 40 | train -> loss: 48.32440 | validation -> loss: 638.29089 | accuracy: 90.277779 | precision: 82.655243 | recall: 95.781639 | f2: 92.833099
2023-05-24 19:49:56,176 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 41 | train -> loss: 40.19371 | validation -> loss: 754.64692 | accuracy: 89.880959 | precision: 81.818184 | recall: 96.029778 | f2: 92.805756
2023-05-24 19:50:48,413 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 42 | train -> loss: 36.49845 | validation -> loss: 778.00304 | accuracy: 89.186508 | precision: 80.625000 | recall: 96.029778 | f2: 92.495224
2023-05-24 19:51:41,106 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 43 | train -> loss: 47.46721 | validation -> loss: 636.41706 | accuracy: 89.583328 | precision: 81.171547 | recall: 96.277916 | f2: 92.822968
2023-05-24 19:52:33,281 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 44 | train -> loss: 40.92353 | validation -> loss: 729.30417 | accuracy: 89.087303 | precision: 80.457382 | recall: 96.029778 | f2: 92.451027
2023-05-24 19:53:25,269 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 45 | train -> loss: 41.45114 | validation -> loss: 664.51386 | accuracy: 89.682541 | precision: 82.570801 | recall: 94.044670 | f2: 91.501686
2023-05-24 19:54:17,529 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 46 | train -> loss: 53.11382 | validation -> loss: 850.25586 | accuracy: 87.003967 | precision: 76.771652 | recall: 96.774193 | f2: 91.981133
2023-05-24 19:55:09,839 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 47 | train -> loss: 51.37324 | validation -> loss: 691.59363 | accuracy: 88.392860 | precision: 79.791664 | recall: 95.037224 | f2: 91.539200
2023-05-24 19:55:09,840 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 19:56:01,915 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 48 | train -> loss: 34.19917 | validation -> loss: 722.03710 | accuracy: 88.690475 | precision: 79.793816 | recall: 96.029778 | f2: 92.274681
2023-05-24 19:56:54,212 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 49 | train -> loss: 35.37341 | validation -> loss: 780.77514 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 19:57:46,444 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 50 | train -> loss: 31.23268 | validation -> loss: 778.01397 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 19:58:38,526 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 51 | train -> loss: 29.81312 | validation -> loss: 794.79584 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 19:59:30,412 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 52 | train -> loss: 31.17428 | validation -> loss: 784.68594 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:00:23,439 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 53 | train -> loss: 32.70954 | validation -> loss: 821.06990 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:01:15,466 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 54 | train -> loss: 29.88460 | validation -> loss: 855.67370 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:02:06,794 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 55 | train -> loss: 32.19835 | validation -> loss: 861.16319 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:02:58,824 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 56 | train -> loss: 31.10619 | validation -> loss: 852.54149 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:03:51,043 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 57 | train -> loss: 31.11725 | validation -> loss: 882.26513 | accuracy: 87.797615 | precision: 78.225807 | recall: 96.277916 | f2: 92.030357
2023-05-24 20:04:42,304 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 58 | train -> loss: 30.61146 | validation -> loss: 858.82716 | accuracy: 88.392860 | precision: 79.183670 | recall: 96.277916 | f2: 92.293053
2023-05-24 20:05:33,888 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 59 | train -> loss: 31.73300 | validation -> loss: 850.72343 | accuracy: 88.194443 | precision: 78.979591 | recall: 96.029778 | f2: 92.055183
2023-05-24 20:06:26,263 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 60 | train -> loss: 28.93162 | validation -> loss: 866.29288 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:07:18,523 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 61 | train -> loss: 26.95039 | validation -> loss: 903.40312 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:08:09,646 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 62 | train -> loss: 28.25460 | validation -> loss: 904.56383 | accuracy: 88.095238 | precision: 78.818741 | recall: 96.029778 | f2: 92.011414
2023-05-24 20:09:01,671 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 63 | train -> loss: 26.88013 | validation -> loss: 911.91288 | accuracy: 88.095238 | precision: 78.701820 | recall: 96.277916 | f2: 92.161522
2023-05-24 20:09:53,057 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 64 | train -> loss: 28.83980 | validation -> loss: 940.29325 | accuracy: 87.797615 | precision: 78.225807 | recall: 96.277916 | f2: 92.030357
2023-05-24 20:10:45,334 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 65 | train -> loss: 25.61621 | validation -> loss: 908.43589 | accuracy: 88.095238 | precision: 78.701820 | recall: 96.277916 | f2: 92.161522
2023-05-24 20:11:36,747 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 66 | train -> loss: 28.24855 | validation -> loss: 963.50173 | accuracy: 87.698410 | precision: 78.068413 | recall: 96.277916 | f2: 91.986725
2023-05-24 20:12:29,410 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 67 | train -> loss: 26.16851 | validation -> loss: 956.03974 | accuracy: 87.797615 | precision: 78.225807 | recall: 96.277916 | f2: 92.030357
2023-05-24 20:13:21,788 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 68 | train -> loss: 25.45183 | validation -> loss: 1009.88951 | accuracy: 87.698410 | precision: 78.068413 | recall: 96.277916 | f2: 91.986725
2023-05-24 20:14:13,920 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 69 | train -> loss: 26.54517 | validation -> loss: 969.03186 | accuracy: 87.698410 | precision: 78.068413 | recall: 96.277916 | f2: 91.986725
2023-05-24 20:15:05,805 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 70 | train -> loss: 25.29584 | validation -> loss: 1016.50825 | accuracy: 87.698410 | precision: 78.068413 | recall: 96.277916 | f2: 91.986725
2023-05-24 20:15:58,391 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 71 | train -> loss: 24.35932 | validation -> loss: 998.67577 | accuracy: 87.698410 | precision: 78.181824 | recall: 96.029778 | f2: 91.836731
2023-05-24 20:16:50,227 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 72 | train -> loss: 35.99183 | validation -> loss: 948.47148 | accuracy: 88.095238 | precision: 79.055443 | recall: 95.533493 | f2: 91.710342
2023-05-24 20:17:42,318 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 73 | train -> loss: 23.61010 | validation -> loss: 869.06176 | accuracy: 87.996033 | precision: 79.253113 | recall: 94.789085 | f2: 91.212990
2023-05-24 20:17:42,319 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 20:18:33,593 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 74 | train -> loss: 30.85763 | validation -> loss: 916.20054 | accuracy: 88.392860 | precision: 79.183670 | recall: 96.277916 | f2: 92.293053
2023-05-24 20:19:26,024 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 75 | train -> loss: 24.72271 | validation -> loss: 961.50462 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:20:18,068 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 76 | train -> loss: 24.28685 | validation -> loss: 955.90260 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:21:10,569 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 77 | train -> loss: 23.64206 | validation -> loss: 954.22983 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:22:02,714 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 78 | train -> loss: 25.58403 | validation -> loss: 948.46747 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:22:55,157 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 79 | train -> loss: 23.06531 | validation -> loss: 940.33178 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:23:47,338 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 80 | train -> loss: 25.63500 | validation -> loss: 959.72306 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:24:39,093 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 81 | train -> loss: 24.43508 | validation -> loss: 952.99315 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:25:30,744 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 82 | train -> loss: 24.05473 | validation -> loss: 949.20687 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:26:23,087 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 83 | train -> loss: 23.92895 | validation -> loss: 961.90849 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:27:16,301 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 84 | train -> loss: 23.80484 | validation -> loss: 969.76592 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:28:08,290 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 85 | train -> loss: 27.41937 | validation -> loss: 960.99693 | accuracy: 88.293655 | precision: 79.022400 | recall: 96.277916 | f2: 92.249168
2023-05-24 20:28:59,954 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 86 | train -> loss: 23.37446 | validation -> loss: 957.78030 | accuracy: 88.194443 | precision: 79.098358 | recall: 95.781639 | f2: 91.904762
2023-05-24 20:29:52,343 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 87 | train -> loss: 23.80723 | validation -> loss: 958.33798 | accuracy: 88.194443 | precision: 79.098358 | recall: 95.781639 | f2: 91.904762
2023-05-24 20:30:44,637 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 88 | train -> loss: 24.69288 | validation -> loss: 962.75358 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:31:36,655 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 89 | train -> loss: 23.32502 | validation -> loss: 967.91504 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:32:28,854 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 90 | train -> loss: 23.17223 | validation -> loss: 979.35284 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:33:20,549 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 91 | train -> loss: 30.19271 | validation -> loss: 980.89427 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:34:12,648 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 92 | train -> loss: 23.40420 | validation -> loss: 975.02510 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:35:04,627 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 93 | train -> loss: 23.99150 | validation -> loss: 978.97490 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:35:56,569 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 94 | train -> loss: 25.46677 | validation -> loss: 990.39833 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:36:48,088 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 95 | train -> loss: 22.67960 | validation -> loss: 978.26284 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:37:40,522 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 96 | train -> loss: 24.48576 | validation -> loss: 982.13902 | accuracy: 88.293655 | precision: 79.141106 | recall: 96.029778 | f2: 92.098999
2023-05-24 20:38:32,405 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 97 | train -> loss: 24.00446 | validation -> loss: 978.86209 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:39:24,926 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 98 | train -> loss: 22.97509 | validation -> loss: 991.83503 | accuracy: 88.194443 | precision: 78.861794 | recall: 96.277916 | f2: 92.205322
2023-05-24 20:40:16,205 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 99 | train -> loss: 28.11997 | validation -> loss: 1014.19460 | accuracy: 88.095238 | precision: 78.701820 | recall: 96.277916 | f2: 92.161522
2023-05-24 20:40:16,206 | root | INFO | rnn.py learn @ 113 : fold: 0 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 20:41:07,791 | root | INFO | rnn.py learn @ 148 : fold: 0 | epoch: 100 | train -> loss: 24.88255 | validation -> loss: 1002.47851 | accuracy: 88.095238 | precision: 78.701820 | recall: 96.277916 | f2: 92.161522
2023-05-24 20:41:08,334 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-lstm-balanced-v2-04/lstm/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f0/model_fold0.pth
2023-05-24 20:41:08,698 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 20:41:08,702 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD4066E20>
2023-05-24 20:41:08,703 | root | INFO | rnn.py learn @ 85 : fetching data for fold #1
2023-05-24 20:41:08,704 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 20:41:08,705 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 20:41:08,706 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 20:41:08,707 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 20:42:01,096 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 1 | train -> loss: 2552.95175 | validation -> loss: 481.39964 | accuracy: 84.722221 | precision: 87.164185 | recall: 72.456573 | f2: 74.987160
2023-05-24 20:42:53,551 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 2 | train -> loss: 1939.62615 | validation -> loss: 469.41125 | accuracy: 84.920631 | precision: 89.096573 | recall: 70.967743 | f2: 73.978271
2023-05-24 20:43:45,840 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 3 | train -> loss: 1960.97740 | validation -> loss: 473.54595 | accuracy: 84.920631 | precision: 87.240356 | recall: 72.952858 | f2: 75.423294
2023-05-24 20:44:38,187 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 4 | train -> loss: 2103.47732 | validation -> loss: 526.54623 | accuracy: 81.150795 | precision: 90.188683 | recall: 59.305210 | f2: 63.665424
2023-05-24 20:45:30,484 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 5 | train -> loss: 2106.29251 | validation -> loss: 658.70224 | accuracy: 75.793655 | precision: 69.727043 | recall: 69.727043 | f2: 69.727043
2023-05-24 20:46:23,330 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 6 | train -> loss: 2123.41140 | validation -> loss: 556.62056 | accuracy: 79.563492 | precision: 74.811081 | recall: 73.697266 | f2: 73.917374
2023-05-24 20:47:15,662 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 7 | train -> loss: 1996.13732 | validation -> loss: 508.66883 | accuracy: 82.837303 | precision: 81.944443 | recall: 73.200996 | f2: 74.797157
2023-05-24 20:48:07,566 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 8 | train -> loss: 1917.68300 | validation -> loss: 521.48678 | accuracy: 81.349205 | precision: 92.156860 | recall: 58.312653 | f2: 62.935192
2023-05-24 20:49:00,218 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 9 | train -> loss: 1842.22208 | validation -> loss: 483.12885 | accuracy: 84.424606 | precision: 83.977905 | recall: 75.434242 | f2: 77.001015
2023-05-24 20:49:52,431 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 10 | train -> loss: 1691.66275 | validation -> loss: 454.15502 | accuracy: 85.317459 | precision: 80.000000 | recall: 84.367249 | f2: 83.456062
2023-05-24 20:50:44,938 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 11 | train -> loss: 1618.59654 | validation -> loss: 470.62938 | accuracy: 86.309525 | precision: 83.375320 | recall: 82.133995 | f2: 82.379295
2023-05-24 20:51:37,039 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 12 | train -> loss: 1646.33487 | validation -> loss: 428.66579 | accuracy: 86.805557 | precision: 83.750000 | recall: 83.126549 | f2: 83.250496
2023-05-24 20:52:29,217 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 13 | train -> loss: 1605.98544 | validation -> loss: 446.12937 | accuracy: 86.309525 | precision: 84.415588 | recall: 80.645164 | f2: 81.372055
2023-05-24 20:53:20,898 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 14 | train -> loss: 1637.67402 | validation -> loss: 577.11102 | accuracy: 76.091270 | precision: 93.548386 | recall: 43.176182 | f2: 48.387096
2023-05-24 20:54:12,443 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 15 | train -> loss: 1911.18811 | validation -> loss: 512.93121 | accuracy: 82.837303 | precision: 83.430229 | recall: 71.215881 | f2: 73.364006
2023-05-24 20:55:04,795 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 16 | train -> loss: 1796.19039 | validation -> loss: 429.29698 | accuracy: 86.904762 | precision: 83.456787 | recall: 83.870964 | f2: 83.787804
2023-05-24 20:55:56,812 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 17 | train -> loss: 1814.02419 | validation -> loss: 483.61215 | accuracy: 83.829369 | precision: 82.786888 | recall: 75.186104 | f2: 76.592514
2023-05-24 20:56:49,424 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 18 | train -> loss: 1689.05525 | validation -> loss: 450.44957 | accuracy: 86.309525 | precision: 87.323944 | recall: 76.923080 | f2: 78.800201
2023-05-24 20:57:41,429 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 19 | train -> loss: 1654.10609 | validation -> loss: 409.67680 | accuracy: 87.996033 | precision: 87.500000 | recall: 81.637718 | f2: 82.746475
2023-05-24 20:58:33,444 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 20 | train -> loss: 1603.29519 | validation -> loss: 565.91803 | accuracy: 78.174606 | precision: 91.402718 | recall: 50.124065 | f2: 55.100929
2023-05-24 20:59:25,366 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 21 | train -> loss: 2207.97360 | validation -> loss: 576.27439 | accuracy: 77.480164 | precision: 91.121498 | recall: 48.387096 | f2: 53.395401
2023-05-24 20:59:25,366 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 21:00:17,632 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 22 | train -> loss: 2034.41848 | validation -> loss: 422.58029 | accuracy: 87.301590 | precision: 92.307693 | recall: 74.441689 | f2: 77.439339
2023-05-24 21:01:09,502 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 23 | train -> loss: 1679.23390 | validation -> loss: 426.44806 | accuracy: 87.003967 | precision: 91.975311 | recall: 73.945412 | f2: 76.962814
2023-05-24 21:02:02,100 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 24 | train -> loss: 1824.07358 | validation -> loss: 589.48467 | accuracy: 78.075394 | precision: 83.211678 | recall: 56.575680 | f2: 60.445385
2023-05-24 21:02:54,709 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 25 | train -> loss: 2120.60389 | validation -> loss: 530.24820 | accuracy: 80.357140 | precision: 91.164658 | recall: 56.327545 | f2: 60.988720
2023-05-24 21:03:47,866 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 26 | train -> loss: 1966.67570 | validation -> loss: 518.60614 | accuracy: 82.142860 | precision: 91.449814 | recall: 61.042183 | f2: 65.390747
2023-05-24 21:04:40,787 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 27 | train -> loss: 1800.56557 | validation -> loss: 466.01149 | accuracy: 85.317459 | precision: 92.642143 | recall: 68.734489 | f2: 72.475143
2023-05-24 21:05:32,908 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 28 | train -> loss: 1827.12970 | validation -> loss: 537.23188 | accuracy: 79.861107 | precision: 92.016808 | recall: 54.342430 | f2: 59.189190
2023-05-24 21:06:25,181 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 29 | train -> loss: 2141.81790 | validation -> loss: 568.48457 | accuracy: 77.182541 | precision: 89.861748 | recall: 48.387096 | f2: 53.307819
2023-05-24 21:07:17,819 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 30 | train -> loss: 2121.19369 | validation -> loss: 539.54004 | accuracy: 80.059525 | precision: 92.436974 | recall: 54.590572 | f2: 59.459461
2023-05-24 21:08:10,215 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 31 | train -> loss: 1751.85186 | validation -> loss: 513.19235 | accuracy: 82.539680 | precision: 92.830185 | recall: 61.042183 | f2: 65.530106
2023-05-24 21:09:03,680 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 32 | train -> loss: 1706.41970 | validation -> loss: 414.52552 | accuracy: 87.500000 | precision: 92.097267 | recall: 75.186104 | f2: 78.052551
2023-05-24 21:09:55,303 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 33 | train -> loss: 2297.35170 | validation -> loss: 443.15051 | accuracy: 87.896820 | precision: 92.447128 | recall: 75.930527 | f2: 78.744209
2023-05-24 21:10:48,291 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 34 | train -> loss: 1615.61866 | validation -> loss: 402.14483 | accuracy: 87.996033 | precision: 91.964287 | recall: 76.674942 | f2: 79.312119
2023-05-24 21:11:39,950 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 35 | train -> loss: 1471.82972 | validation -> loss: 391.53939 | accuracy: 87.896820 | precision: 91.691391 | recall: 76.674942 | f2: 79.271423
2023-05-24 21:12:32,932 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 36 | train -> loss: 1412.71828 | validation -> loss: 395.47272 | accuracy: 88.392860 | precision: 86.855667 | recall: 83.622833 | f2: 84.250000
2023-05-24 21:13:25,316 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 37 | train -> loss: 1391.68791 | validation -> loss: 366.15450 | accuracy: 89.682541 | precision: 90.958908 | recall: 82.382133 | f2: 83.965607
2023-05-24 21:14:18,002 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 38 | train -> loss: 1371.18916 | validation -> loss: 367.31643 | accuracy: 89.583328 | precision: 90.053764 | recall: 83.126549 | f2: 84.425400
2023-05-24 21:15:10,718 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 39 | train -> loss: 1403.58754 | validation -> loss: 349.90817 | accuracy: 90.178574 | precision: 91.530052 | recall: 83.126549 | f2: 84.681496
2023-05-24 21:16:03,611 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 40 | train -> loss: 1373.71752 | validation -> loss: 465.80555 | accuracy: 83.928574 | precision: 92.579506 | recall: 65.012405 | f2: 69.129288
2023-05-24 21:16:55,955 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 41 | train -> loss: 1391.29608 | validation -> loss: 375.38110 | accuracy: 88.988098 | precision: 91.242943 | recall: 80.148880 | f2: 82.146492
2023-05-24 21:17:48,122 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 42 | train -> loss: 1293.97262 | validation -> loss: 360.34493 | accuracy: 89.980164 | precision: 90.159576 | recall: 84.119102 | f2: 85.261574
2023-05-24 21:18:41,256 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 43 | train -> loss: 1423.33369 | validation -> loss: 344.62227 | accuracy: 90.079369 | precision: 88.946014 | recall: 85.856079 | f2: 86.456772
2023-05-24 21:19:33,155 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 44 | train -> loss: 1266.09365 | validation -> loss: 340.45062 | accuracy: 90.873016 | precision: 90.180878 | recall: 86.600494 | f2: 87.293648
2023-05-24 21:20:25,436 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 45 | train -> loss: 1258.35175 | validation -> loss: 334.15693 | accuracy: 91.071426 | precision: 90.861618 | recall: 86.352364 | f2: 87.218048
2023-05-24 21:21:17,771 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 46 | train -> loss: 1335.85388 | validation -> loss: 346.77518 | accuracy: 90.575394 | precision: 91.176468 | recall: 84.615387 | f2: 85.850952
2023-05-24 21:22:10,477 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 47 | train -> loss: 1204.25254 | validation -> loss: 343.03127 | accuracy: 90.376984 | precision: 92.265198 | recall: 82.878410 | f2: 84.599800
2023-05-24 21:22:10,478 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 21:23:02,079 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 48 | train -> loss: 1164.49288 | validation -> loss: 343.50136 | accuracy: 90.277779 | precision: 91.105118 | recall: 83.870964 | f2: 85.224411
2023-05-24 21:23:54,618 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 49 | train -> loss: 1156.46611 | validation -> loss: 342.50668 | accuracy: 90.773811 | precision: 92.817680 | recall: 83.374695 | f2: 85.106384
2023-05-24 21:24:46,604 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 50 | train -> loss: 1151.17619 | validation -> loss: 341.96028 | accuracy: 90.773811 | precision: 91.891891 | recall: 84.367249 | f2: 85.771950
2023-05-24 21:25:38,304 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 51 | train -> loss: 1148.80504 | validation -> loss: 341.44630 | accuracy: 90.773811 | precision: 91.891891 | recall: 84.367249 | f2: 85.771950
2023-05-24 21:26:30,529 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 52 | train -> loss: 1134.72889 | validation -> loss: 348.64052 | accuracy: 90.575394 | precision: 92.777779 | recall: 82.878410 | f2: 84.685600
2023-05-24 21:27:22,919 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 53 | train -> loss: 1138.12384 | validation -> loss: 356.04095 | accuracy: 90.277779 | precision: 91.327911 | recall: 83.622833 | f2: 85.058052
2023-05-24 21:28:16,103 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 54 | train -> loss: 1152.97030 | validation -> loss: 337.77578 | accuracy: 90.972221 | precision: 92.391304 | recall: 84.367249 | f2: 85.858582
2023-05-24 21:29:08,135 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 55 | train -> loss: 1123.38211 | validation -> loss: 338.15706 | accuracy: 90.873016 | precision: 92.140923 | recall: 84.367249 | f2: 85.815247
2023-05-24 21:30:00,111 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 56 | train -> loss: 1111.98154 | validation -> loss: 339.42351 | accuracy: 90.873016 | precision: 92.140923 | recall: 84.367249 | f2: 85.815247
2023-05-24 21:30:53,009 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 57 | train -> loss: 1118.43459 | validation -> loss: 344.03470 | accuracy: 90.773811 | precision: 92.349724 | recall: 83.870964 | f2: 85.439835
2023-05-24 21:31:44,283 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 58 | train -> loss: 1109.59511 | validation -> loss: 343.27082 | accuracy: 90.674606 | precision: 91.420914 | recall: 84.615387 | f2: 85.894211
2023-05-24 21:32:36,688 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 59 | train -> loss: 1112.33791 | validation -> loss: 346.10653 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:33:29,452 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 60 | train -> loss: 1103.02311 | validation -> loss: 342.47225 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:34:22,092 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 61 | train -> loss: 1092.73715 | validation -> loss: 338.89908 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:35:14,837 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 62 | train -> loss: 1102.53976 | validation -> loss: 341.35127 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:36:07,230 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 63 | train -> loss: 1087.10103 | validation -> loss: 349.25414 | accuracy: 90.873016 | precision: 92.370567 | recall: 84.119102 | f2: 85.649315
2023-05-24 21:36:58,837 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 64 | train -> loss: 1094.46376 | validation -> loss: 345.47301 | accuracy: 90.575394 | precision: 92.076508 | recall: 83.622833 | f2: 85.187057
2023-05-24 21:37:51,142 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 65 | train -> loss: 1086.53539 | validation -> loss: 341.79923 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:38:44,682 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 66 | train -> loss: 1073.42220 | validation -> loss: 341.88129 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:39:37,046 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 67 | train -> loss: 1081.02100 | validation -> loss: 338.57401 | accuracy: 90.972221 | precision: 92.162163 | recall: 84.615387 | f2: 86.024216
2023-05-24 21:40:29,402 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 68 | train -> loss: 1051.16009 | validation -> loss: 327.01798 | accuracy: 90.773811 | precision: 92.349724 | recall: 83.870964 | f2: 85.439835
2023-05-24 21:41:21,389 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 69 | train -> loss: 1095.81867 | validation -> loss: 348.48752 | accuracy: 90.674606 | precision: 91.199997 | recall: 84.863525 | f2: 86.059387
2023-05-24 21:42:14,372 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 70 | train -> loss: 1074.84070 | validation -> loss: 340.60987 | accuracy: 90.873016 | precision: 92.837463 | recall: 83.622833 | f2: 85.316452
2023-05-24 21:43:06,637 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 71 | train -> loss: 1067.67422 | validation -> loss: 335.39383 | accuracy: 91.071426 | precision: 92.411926 | recall: 84.615387 | f2: 86.067642
2023-05-24 21:43:59,128 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 72 | train -> loss: 1063.20560 | validation -> loss: 330.65302 | accuracy: 91.269836 | precision: 92.452827 | recall: 85.111656 | f2: 86.485123
2023-05-24 21:44:51,107 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 73 | train -> loss: 1035.03919 | validation -> loss: 342.64073 | accuracy: 90.674606 | precision: 91.644203 | recall: 84.367249 | f2: 85.728691
2023-05-24 21:44:51,108 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 21:45:43,582 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 74 | train -> loss: 1040.87679 | validation -> loss: 336.48941 | accuracy: 90.674606 | precision: 91.869919 | recall: 84.119102 | f2: 85.562851
2023-05-24 21:46:35,848 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 75 | train -> loss: 1022.19701 | validation -> loss: 335.14286 | accuracy: 90.873016 | precision: 92.370567 | recall: 84.119102 | f2: 85.649315
2023-05-24 21:47:28,294 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 76 | train -> loss: 993.80428 | validation -> loss: 317.71500 | accuracy: 90.873016 | precision: 92.602745 | recall: 83.870964 | f2: 85.483055
2023-05-24 21:48:21,066 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 77 | train -> loss: 936.34389 | validation -> loss: 323.75219 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:49:13,927 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 78 | train -> loss: 953.87702 | validation -> loss: 309.21181 | accuracy: 90.873016 | precision: 92.602745 | recall: 83.870964 | f2: 85.483055
2023-05-24 21:50:06,507 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 79 | train -> loss: 883.88672 | validation -> loss: 307.77631 | accuracy: 90.773811 | precision: 92.349724 | recall: 83.870964 | f2: 85.439835
2023-05-24 21:50:58,964 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 80 | train -> loss: 861.98879 | validation -> loss: 297.66363 | accuracy: 90.773811 | precision: 92.349724 | recall: 83.870964 | f2: 85.439835
2023-05-24 21:51:51,413 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 81 | train -> loss: 972.40650 | validation -> loss: 365.37393 | accuracy: 90.873016 | precision: 92.602745 | recall: 83.870964 | f2: 85.483055
2023-05-24 21:52:44,154 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 82 | train -> loss: 1064.34095 | validation -> loss: 339.62548 | accuracy: 90.575394 | precision: 91.621620 | recall: 84.119102 | f2: 85.519676
2023-05-24 21:53:36,917 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 83 | train -> loss: 910.94654 | validation -> loss: 319.17562 | accuracy: 90.674606 | precision: 92.098091 | recall: 83.870964 | f2: 85.396667
2023-05-24 21:54:29,104 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 84 | train -> loss: 929.28864 | validation -> loss: 313.30195 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:55:22,788 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 85 | train -> loss: 837.82938 | validation -> loss: 295.14708 | accuracy: 90.873016 | precision: 92.602745 | recall: 83.870964 | f2: 85.483055
2023-05-24 21:56:15,564 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 86 | train -> loss: 859.72160 | validation -> loss: 369.76499 | accuracy: 90.873016 | precision: 92.837463 | recall: 83.622833 | f2: 85.316452
2023-05-24 21:57:07,978 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 87 | train -> loss: 1151.84185 | validation -> loss: 369.71332 | accuracy: 90.773811 | precision: 92.349724 | recall: 83.870964 | f2: 85.439835
2023-05-24 21:58:00,692 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 88 | train -> loss: 1133.75542 | validation -> loss: 363.82894 | accuracy: 90.873016 | precision: 92.602745 | recall: 83.870964 | f2: 85.483055
2023-05-24 21:58:52,485 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 89 | train -> loss: 1105.70641 | validation -> loss: 335.62685 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 21:59:46,408 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 90 | train -> loss: 857.65702 | validation -> loss: 302.13278 | accuracy: 90.476189 | precision: 91.374664 | recall: 84.119102 | f2: 85.476555
2023-05-24 22:00:39,172 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 91 | train -> loss: 878.40786 | validation -> loss: 286.68225 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 22:01:31,744 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 92 | train -> loss: 784.31973 | validation -> loss: 286.22788 | accuracy: 90.773811 | precision: 92.119560 | recall: 84.119102 | f2: 85.606064
2023-05-24 22:02:23,115 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 93 | train -> loss: 868.24015 | validation -> loss: 284.49365 | accuracy: 90.773811 | precision: 92.582413 | recall: 83.622833 | f2: 85.273277
2023-05-24 22:03:15,681 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 94 | train -> loss: 847.39366 | validation -> loss: 294.72841 | accuracy: 90.575394 | precision: 91.847824 | recall: 83.870964 | f2: 85.353539
2023-05-24 22:04:08,654 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 95 | train -> loss: 761.06130 | validation -> loss: 277.98120 | accuracy: 90.773811 | precision: 92.582413 | recall: 83.622833 | f2: 85.273277
2023-05-24 22:05:00,209 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 96 | train -> loss: 993.15542 | validation -> loss: 305.05577 | accuracy: 90.674606 | precision: 91.869919 | recall: 84.119102 | f2: 85.562851
2023-05-24 22:05:53,014 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 97 | train -> loss: 769.08552 | validation -> loss: 290.35800 | accuracy: 90.674606 | precision: 92.098091 | recall: 83.870964 | f2: 85.396667
2023-05-24 22:06:45,496 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 98 | train -> loss: 752.30790 | validation -> loss: 292.79437 | accuracy: 90.674606 | precision: 92.098091 | recall: 83.870964 | f2: 85.396667
2023-05-24 22:07:36,916 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 99 | train -> loss: 735.38907 | validation -> loss: 276.54950 | accuracy: 90.674606 | precision: 92.098091 | recall: 83.870964 | f2: 85.396667
2023-05-24 22:07:36,917 | root | INFO | rnn.py learn @ 113 : fold: 1 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 22:08:29,777 | root | INFO | rnn.py learn @ 148 : fold: 1 | epoch: 100 | train -> loss: 734.95700 | validation -> loss: 277.78529 | accuracy: 90.674606 | precision: 92.098091 | recall: 83.870964 | f2: 85.396667
2023-05-24 22:08:30,247 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-lstm-balanced-v2-04/lstm/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f1/model_fold1.pth
2023-05-24 22:08:30,567 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 22:08:30,571 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD2298C70>
2023-05-24 22:08:30,572 | root | INFO | rnn.py learn @ 85 : fetching data for fold #2
2023-05-24 22:08:30,573 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 22:08:30,573 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 22:08:30,574 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 22:08:30,575 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 22:09:22,044 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 1 | train -> loss: 2563.32864 | validation -> loss: 597.62873 | accuracy: 74.900795 | precision: 95.731705 | recall: 38.957817 | f2: 44.200451
2023-05-24 22:10:14,009 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 2 | train -> loss: 2212.51322 | validation -> loss: 565.34835 | accuracy: 80.158730 | precision: 85.614037 | recall: 60.545902 | f2: 64.312073
2023-05-24 22:11:06,000 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 3 | train -> loss: 2036.08719 | validation -> loss: 537.13426 | accuracy: 81.250000 | precision: 84.740257 | recall: 64.764267 | f2: 67.968750
2023-05-24 22:11:57,885 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 4 | train -> loss: 1968.85814 | validation -> loss: 559.99270 | accuracy: 77.976189 | precision: 95.939087 | recall: 46.898262 | f2: 52.238804
2023-05-24 22:12:49,331 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 5 | train -> loss: 2084.16404 | validation -> loss: 570.75448 | accuracy: 76.686508 | precision: 97.727272 | recall: 42.679901 | f2: 48.098434
2023-05-24 22:13:41,730 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 6 | train -> loss: 2462.92032 | validation -> loss: 752.10396 | accuracy: 60.119045 | precision: 100.000000 | recall: 0.248139 | f2: 0.309981
2023-05-24 22:14:33,033 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 7 | train -> loss: 2979.45308 | validation -> loss: 739.68252 | accuracy: 63.591270 | precision: 92.857140 | recall: 9.677419 | f2: 11.789601
2023-05-24 22:15:24,906 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 8 | train -> loss: 2967.53406 | validation -> loss: 738.95526 | accuracy: 62.103176 | precision: 92.000000 | recall: 5.707196 | f2: 7.025046
2023-05-24 22:16:17,431 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 9 | train -> loss: 2931.38458 | validation -> loss: 579.30913 | accuracy: 81.646820 | precision: 90.671638 | recall: 60.297768 | f2: 64.627663
2023-05-24 22:17:09,509 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 10 | train -> loss: 2350.51454 | validation -> loss: 567.78452 | accuracy: 77.976189 | precision: 92.488266 | recall: 48.883377 | f2: 53.972603
2023-05-24 22:18:01,225 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 11 | train -> loss: 2320.06023 | validation -> loss: 567.53853 | accuracy: 77.876984 | precision: 92.056076 | recall: 48.883377 | f2: 53.943043
2023-05-24 22:18:52,811 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 12 | train -> loss: 2311.37908 | validation -> loss: 548.99970 | accuracy: 79.960320 | precision: 92.050209 | recall: 54.590572 | f2: 59.427338
2023-05-24 22:19:45,323 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 13 | train -> loss: 2255.94657 | validation -> loss: 536.79877 | accuracy: 80.158730 | precision: 92.116180 | recall: 55.086853 | f2: 59.902859
2023-05-24 22:20:36,910 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 14 | train -> loss: 2257.68252 | validation -> loss: 564.08228 | accuracy: 79.265877 | precision: 93.693695 | recall: 51.612900 | f2: 56.706654
2023-05-24 22:21:29,537 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 15 | train -> loss: 2417.96964 | validation -> loss: 734.13514 | accuracy: 56.349205 | precision: 47.800236 | recall: 99.751862 | f2: 81.940475
2023-05-24 22:22:22,253 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 16 | train -> loss: 1598.36295 | validation -> loss: 242.10025 | accuracy: 91.468254 | precision: 84.086021 | recall: 97.022331 | f2: 94.126144
2023-05-24 22:23:14,020 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 17 | train -> loss: 624.37586 | validation -> loss: 222.04834 | accuracy: 91.567459 | precision: 87.677727 | recall: 91.811409 | f2: 90.953789
2023-05-24 22:24:06,437 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 18 | train -> loss: 363.34953 | validation -> loss: 237.51563 | accuracy: 91.071426 | precision: 83.655914 | recall: 96.526054 | f2: 93.644676
2023-05-24 22:24:59,048 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 19 | train -> loss: 288.61766 | validation -> loss: 348.64351 | accuracy: 89.682541 | precision: 80.202019 | recall: 98.511162 | f2: 94.209778
2023-05-24 22:25:51,250 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 20 | train -> loss: 199.77254 | validation -> loss: 285.07274 | accuracy: 92.063492 | precision: 85.339172 | recall: 96.774193 | f2: 94.248428
2023-05-24 22:26:43,425 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 21 | train -> loss: 190.89492 | validation -> loss: 292.86152 | accuracy: 91.666672 | precision: 84.598694 | recall: 96.774193 | f2: 94.066574
2023-05-24 22:26:43,426 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 22:27:35,239 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 22 | train -> loss: 131.29198 | validation -> loss: 296.24411 | accuracy: 92.261902 | precision: 85.557983 | recall: 97.022331 | f2: 94.490089
2023-05-24 22:28:27,588 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 23 | train -> loss: 171.67394 | validation -> loss: 316.21044 | accuracy: 91.765877 | precision: 84.188034 | recall: 97.766754 | f2: 94.711533
2023-05-24 22:29:20,179 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 24 | train -> loss: 119.28771 | validation -> loss: 330.59151 | accuracy: 91.964287 | precision: 85.000000 | recall: 97.022331 | f2: 94.353279
2023-05-24 22:30:12,287 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 25 | train -> loss: 109.91308 | validation -> loss: 332.31907 | accuracy: 91.666672 | precision: 84.154175 | recall: 97.518608 | f2: 94.516594
2023-05-24 22:31:05,679 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 26 | train -> loss: 103.60475 | validation -> loss: 347.70313 | accuracy: 92.261902 | precision: 85.097191 | recall: 97.766754 | f2: 94.939758
2023-05-24 22:31:57,772 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 27 | train -> loss: 95.70048 | validation -> loss: 345.09811 | accuracy: 92.063492 | precision: 85.494507 | recall: 96.526054 | f2: 94.097725
2023-05-24 22:32:50,290 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 28 | train -> loss: 89.74168 | validation -> loss: 339.60739 | accuracy: 91.964287 | precision: 84.401711 | recall: 98.014893 | f2: 94.951920
2023-05-24 22:33:42,568 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 29 | train -> loss: 101.28237 | validation -> loss: 347.64825 | accuracy: 91.567459 | precision: 83.686440 | recall: 98.014893 | f2: 94.769676
2023-05-24 22:34:34,639 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 30 | train -> loss: 81.37118 | validation -> loss: 340.80636 | accuracy: 92.261902 | precision: 85.871964 | recall: 96.526054 | f2: 94.188866
2023-05-24 22:35:26,665 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 31 | train -> loss: 88.69316 | validation -> loss: 377.74160 | accuracy: 91.765877 | precision: 84.188034 | recall: 97.766754 | f2: 94.711533
2023-05-24 22:36:19,404 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 32 | train -> loss: 73.40616 | validation -> loss: 359.92756 | accuracy: 91.666672 | precision: 84.301071 | recall: 97.270470 | f2: 94.366875
2023-05-24 22:37:11,765 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 33 | train -> loss: 69.88352 | validation -> loss: 384.69270 | accuracy: 91.468254 | precision: 83.509514 | recall: 98.014893 | f2: 94.724220
2023-05-24 22:38:04,620 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 34 | train -> loss: 70.16442 | validation -> loss: 377.62530 | accuracy: 91.567459 | precision: 84.565216 | recall: 96.526054 | f2: 93.870659
2023-05-24 22:38:57,535 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 35 | train -> loss: 58.53340 | validation -> loss: 399.40415 | accuracy: 91.964287 | precision: 84.848488 | recall: 97.270470 | f2: 94.503372
2023-05-24 22:39:48,860 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 36 | train -> loss: 88.61302 | validation -> loss: 530.10418 | accuracy: 88.293655 | precision: 78.106514 | recall: 98.263023 | f2: 93.440300
2023-05-24 22:40:41,595 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 37 | train -> loss: 134.62676 | validation -> loss: 364.56505 | accuracy: 91.765877 | precision: 84.482758 | recall: 97.270470 | f2: 94.412331
2023-05-24 22:41:33,581 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 38 | train -> loss: 102.45559 | validation -> loss: 357.25073 | accuracy: 91.567459 | precision: 84.415588 | recall: 96.774193 | f2: 94.021210
2023-05-24 22:42:26,651 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 39 | train -> loss: 89.64334 | validation -> loss: 363.67366 | accuracy: 91.567459 | precision: 84.716156 | recall: 96.277916 | f2: 93.719803
2023-05-24 22:43:19,713 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 40 | train -> loss: 86.78679 | validation -> loss: 367.62673 | accuracy: 91.567459 | precision: 85.972855 | recall: 94.292801 | f2: 92.502434
2023-05-24 22:44:12,553 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 41 | train -> loss: 62.16653 | validation -> loss: 416.59054 | accuracy: 90.972221 | precision: 83.050850 | recall: 97.270470 | f2: 94.049904
2023-05-24 22:45:05,232 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 42 | train -> loss: 46.64343 | validation -> loss: 516.66861 | accuracy: 90.575394 | precision: 82.352943 | recall: 97.270470 | f2: 93.869736
2023-05-24 22:45:57,285 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 43 | train -> loss: 44.75256 | validation -> loss: 440.97641 | accuracy: 91.865082 | precision: 84.815613 | recall: 97.022331 | f2: 94.307770
2023-05-24 22:46:49,742 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 44 | train -> loss: 46.94217 | validation -> loss: 343.28654 | accuracy: 91.269836 | precision: 85.234901 | recall: 94.540939 | f2: 92.520645
2023-05-24 22:47:42,437 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 45 | train -> loss: 46.33470 | validation -> loss: 428.72275 | accuracy: 91.666672 | precision: 84.301071 | recall: 97.270470 | f2: 94.366875
2023-05-24 22:48:34,640 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 46 | train -> loss: 47.87542 | validation -> loss: 477.20259 | accuracy: 90.972221 | precision: 82.500000 | recall: 98.263023 | f2: 94.646271
2023-05-24 22:49:25,513 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 47 | train -> loss: 50.02576 | validation -> loss: 411.55599 | accuracy: 91.964287 | precision: 85.000000 | recall: 97.022331 | f2: 94.353279
2023-05-24 22:49:25,514 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-24 22:50:17,356 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 48 | train -> loss: 42.54908 | validation -> loss: 460.76387 | accuracy: 91.071426 | precision: 83.086685 | recall: 97.518608 | f2: 94.244606
2023-05-24 22:51:09,590 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 49 | train -> loss: 37.84246 | validation -> loss: 473.77477 | accuracy: 91.170631 | precision: 83.404251 | recall: 97.270470 | f2: 94.140251
2023-05-24 22:52:00,995 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 50 | train -> loss: 38.00098 | validation -> loss: 486.42284 | accuracy: 91.170631 | precision: 83.404251 | recall: 97.270470 | f2: 94.140251
2023-05-24 22:52:53,701 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 51 | train -> loss: 36.65741 | validation -> loss: 486.86532 | accuracy: 90.972221 | precision: 83.050850 | recall: 97.270470 | f2: 94.049904
2023-05-24 22:53:46,169 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 52 | train -> loss: 36.69934 | validation -> loss: 473.24769 | accuracy: 91.666672 | precision: 84.301071 | recall: 97.270470 | f2: 94.366875
2023-05-24 22:54:38,137 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 53 | train -> loss: 36.07790 | validation -> loss: 568.65435 | accuracy: 89.384918 | precision: 79.838715 | recall: 98.263023 | f2: 93.927895
2023-05-24 22:55:30,628 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 54 | train -> loss: 45.76343 | validation -> loss: 455.14037 | accuracy: 91.865082 | precision: 84.967323 | recall: 96.774193 | f2: 94.157410
2023-05-24 22:56:22,815 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 55 | train -> loss: 35.22267 | validation -> loss: 505.85622 | accuracy: 90.674606 | precision: 82.526314 | recall: 97.270470 | f2: 93.914711
2023-05-24 22:57:14,824 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 56 | train -> loss: 33.67633 | validation -> loss: 445.98298 | accuracy: 92.261902 | precision: 85.871964 | recall: 96.526054 | f2: 94.188866
2023-05-24 22:58:06,743 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 57 | train -> loss: 40.05885 | validation -> loss: 490.35234 | accuracy: 91.071426 | precision: 83.227173 | recall: 97.270470 | f2: 94.095055
2023-05-24 22:58:59,070 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 58 | train -> loss: 39.57084 | validation -> loss: 461.13220 | accuracy: 91.666672 | precision: 84.449242 | recall: 97.022331 | f2: 94.216866
2023-05-24 22:59:51,675 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 59 | train -> loss: 31.32276 | validation -> loss: 496.15412 | accuracy: 91.071426 | precision: 83.227173 | recall: 97.270470 | f2: 94.095055
2023-05-24 23:00:44,568 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 60 | train -> loss: 26.32913 | validation -> loss: 483.70950 | accuracy: 91.567459 | precision: 84.267242 | recall: 97.022331 | f2: 94.171486
2023-05-24 23:01:37,425 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 61 | train -> loss: 29.67736 | validation -> loss: 495.79402 | accuracy: 91.765877 | precision: 84.632034 | recall: 97.022331 | f2: 94.262299
2023-05-24 23:02:28,748 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 62 | train -> loss: 28.10274 | validation -> loss: 493.51000 | accuracy: 91.765877 | precision: 84.334770 | recall: 97.518608 | f2: 94.562080
2023-05-24 23:03:20,953 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 63 | train -> loss: 36.14252 | validation -> loss: 500.84928 | accuracy: 91.964287 | precision: 84.848488 | recall: 97.270470 | f2: 94.503372
2023-05-24 23:04:13,657 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 64 | train -> loss: 27.04964 | validation -> loss: 505.28027 | accuracy: 91.865082 | precision: 84.815613 | recall: 97.022331 | f2: 94.307770
2023-05-24 23:05:05,877 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 65 | train -> loss: 26.75203 | validation -> loss: 488.28810 | accuracy: 91.865082 | precision: 84.815613 | recall: 97.022331 | f2: 94.307770
2023-05-24 23:05:57,983 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 66 | train -> loss: 31.07880 | validation -> loss: 522.60586 | accuracy: 91.369041 | precision: 83.905579 | recall: 97.022331 | f2: 94.080849
2023-05-24 23:06:49,873 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 67 | train -> loss: 26.60845 | validation -> loss: 526.12911 | accuracy: 91.765877 | precision: 84.334770 | recall: 97.518608 | f2: 94.562080
2023-05-24 23:07:41,575 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 68 | train -> loss: 23.59577 | validation -> loss: 563.18199 | accuracy: 90.079369 | precision: 81.237114 | recall: 97.766754 | f2: 93.943726
2023-05-24 23:08:34,834 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 69 | train -> loss: 30.33469 | validation -> loss: 490.20742 | accuracy: 91.071426 | precision: 83.227173 | recall: 97.270470 | f2: 94.095055
2023-05-24 23:09:26,956 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 70 | train -> loss: 23.89351 | validation -> loss: 531.05316 | accuracy: 91.170631 | precision: 83.404251 | recall: 97.270470 | f2: 94.140251
2023-05-24 23:10:19,550 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 71 | train -> loss: 24.41989 | validation -> loss: 542.92541 | accuracy: 90.873016 | precision: 82.875267 | recall: 97.270470 | f2: 94.004799
2023-05-24 23:11:11,562 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 72 | train -> loss: 23.55368 | validation -> loss: 534.28059 | accuracy: 91.865082 | precision: 85.274727 | recall: 96.277916 | f2: 93.855827
2023-05-24 23:12:04,128 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 73 | train -> loss: 34.13229 | validation -> loss: 541.83739 | accuracy: 91.269836 | precision: 83.298096 | recall: 97.766754 | f2: 94.484413
2023-05-24 23:12:04,128 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-24 23:12:56,416 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 74 | train -> loss: 22.49334 | validation -> loss: 543.84478 | accuracy: 91.468254 | precision: 83.795311 | recall: 97.518608 | f2: 94.425758
2023-05-24 23:13:49,054 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 75 | train -> loss: 23.76773 | validation -> loss: 550.88494 | accuracy: 91.567459 | precision: 83.974365 | recall: 97.518608 | f2: 94.471153
2023-05-24 23:14:41,025 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 76 | train -> loss: 21.74066 | validation -> loss: 562.19772 | accuracy: 91.468254 | precision: 83.795311 | recall: 97.518608 | f2: 94.425758
2023-05-24 23:15:34,087 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 77 | train -> loss: 22.68131 | validation -> loss: 543.93653 | accuracy: 91.765877 | precision: 84.632034 | recall: 97.022331 | f2: 94.262299
2023-05-24 23:16:26,402 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 78 | train -> loss: 21.38651 | validation -> loss: 561.84310 | accuracy: 91.666672 | precision: 84.154175 | recall: 97.518608 | f2: 94.516594
2023-05-24 23:17:18,607 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 79 | train -> loss: 23.91296 | validation -> loss: 542.00695 | accuracy: 91.666672 | precision: 84.749451 | recall: 96.526054 | f2: 93.915977
2023-05-24 23:18:11,519 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 80 | train -> loss: 22.49610 | validation -> loss: 566.03131 | accuracy: 91.865082 | precision: 84.815613 | recall: 97.022331 | f2: 94.307770
2023-05-24 23:19:03,695 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 81 | train -> loss: 27.25562 | validation -> loss: 575.81093 | accuracy: 91.369041 | precision: 83.617020 | recall: 97.518608 | f2: 94.380402
2023-05-24 23:19:55,937 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 82 | train -> loss: 24.55107 | validation -> loss: 567.16833 | accuracy: 91.865082 | precision: 84.665230 | recall: 97.270470 | f2: 94.457832
2023-05-24 23:20:48,267 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 83 | train -> loss: 21.01311 | validation -> loss: 570.37239 | accuracy: 91.765877 | precision: 84.482758 | recall: 97.270470 | f2: 94.412331
2023-05-24 23:21:40,022 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 84 | train -> loss: 21.36119 | validation -> loss: 572.71414 | accuracy: 91.865082 | precision: 84.815613 | recall: 97.022331 | f2: 94.307770
2023-05-24 23:22:32,144 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 85 | train -> loss: 21.02258 | validation -> loss: 565.60597 | accuracy: 91.865082 | precision: 84.815613 | recall: 97.022331 | f2: 94.307770
2023-05-24 23:23:24,665 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 86 | train -> loss: 24.05349 | validation -> loss: 569.66477 | accuracy: 91.964287 | precision: 84.848488 | recall: 97.270470 | f2: 94.503372
2023-05-24 23:24:16,014 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 87 | train -> loss: 22.31100 | validation -> loss: 583.71673 | accuracy: 91.269836 | precision: 83.582092 | recall: 97.270470 | f2: 94.185486
2023-05-24 23:25:08,322 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 88 | train -> loss: 21.55400 | validation -> loss: 588.96416 | accuracy: 91.369041 | precision: 83.617020 | recall: 97.518608 | f2: 94.380402
2023-05-24 23:26:00,351 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 89 | train -> loss: 20.97490 | validation -> loss: 571.53760 | accuracy: 91.567459 | precision: 84.267242 | recall: 97.022331 | f2: 94.171486
2023-05-24 23:26:52,753 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 90 | train -> loss: 20.57734 | validation -> loss: 594.72234 | accuracy: 91.071426 | precision: 83.086685 | recall: 97.518608 | f2: 94.244606
2023-05-24 23:27:45,315 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 91 | train -> loss: 21.05648 | validation -> loss: 587.67699 | accuracy: 91.269836 | precision: 83.582092 | recall: 97.270470 | f2: 94.185486
2023-05-24 23:28:38,247 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 92 | train -> loss: 20.25193 | validation -> loss: 598.48145 | accuracy: 91.269836 | precision: 83.439491 | recall: 97.518608 | f2: 94.335091
2023-05-24 23:29:30,048 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 93 | train -> loss: 25.68846 | validation -> loss: 599.72010 | accuracy: 91.071426 | precision: 83.086685 | recall: 97.518608 | f2: 94.244606
2023-05-24 23:30:22,207 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 94 | train -> loss: 20.46294 | validation -> loss: 594.36651 | accuracy: 91.269836 | precision: 83.439491 | recall: 97.518608 | f2: 94.335091
2023-05-24 23:31:13,987 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 95 | train -> loss: 21.28654 | validation -> loss: 603.18165 | accuracy: 90.873016 | precision: 82.736847 | recall: 97.518608 | f2: 94.154289
2023-05-24 23:32:06,522 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 96 | train -> loss: 22.55077 | validation -> loss: 615.68592 | accuracy: 90.873016 | precision: 82.736847 | recall: 97.518608 | f2: 94.154289
2023-05-24 23:32:58,421 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 97 | train -> loss: 21.61019 | validation -> loss: 597.43526 | accuracy: 91.071426 | precision: 83.227173 | recall: 97.270470 | f2: 94.095055
2023-05-24 23:33:50,718 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 98 | train -> loss: 21.37969 | validation -> loss: 586.79473 | accuracy: 91.369041 | precision: 83.760681 | recall: 97.270470 | f2: 94.230774
2023-05-24 23:34:42,416 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 99 | train -> loss: 22.02617 | validation -> loss: 575.27730 | accuracy: 91.964287 | precision: 85.000000 | recall: 97.022331 | f2: 94.353279
2023-05-24 23:34:42,416 | root | INFO | rnn.py learn @ 113 : fold: 2 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-24 23:35:34,081 | root | INFO | rnn.py learn @ 148 : fold: 2 | epoch: 100 | train -> loss: 23.12860 | validation -> loss: 575.43537 | accuracy: 91.666672 | precision: 84.449242 | recall: 97.022331 | f2: 94.216866
2023-05-24 23:35:34,564 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-lstm-balanced-v2-04/lstm/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f2/model_fold2.pth
2023-05-24 23:35:34,877 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-24 23:35:34,881 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD20D0610>
2023-05-24 23:35:34,882 | root | INFO | rnn.py learn @ 85 : fetching data for fold #3
2023-05-24 23:35:34,883 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-24 23:35:34,883 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-24 23:35:34,884 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 23:35:34,885 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-24 23:36:27,053 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 1 | train -> loss: 2838.13586 | validation -> loss: 566.69238 | accuracy: 75.595238 | precision: 63.715279 | recall: 90.841583 | f2: 83.713501
2023-05-24 23:37:19,111 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 2 | train -> loss: 2124.86722 | validation -> loss: 486.42950 | accuracy: 83.432541 | precision: 94.382027 | recall: 62.376236 | f2: 66.914497
2023-05-24 23:38:10,648 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 3 | train -> loss: 1951.68424 | validation -> loss: 449.12828 | accuracy: 85.813492 | precision: 83.547554 | recall: 80.445549 | f2: 81.047379
2023-05-24 23:39:02,470 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 4 | train -> loss: 1857.20418 | validation -> loss: 425.02012 | accuracy: 87.202385 | precision: 91.793312 | recall: 74.752472 | f2: 77.634964
2023-05-24 23:39:53,890 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 5 | train -> loss: 2427.91939 | validation -> loss: 688.29786 | accuracy: 49.206348 | precision: 44.104801 | recall: 100.000000 | f2: 79.778831
2023-05-24 23:40:47,032 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 6 | train -> loss: 2728.40137 | validation -> loss: 651.69460 | accuracy: 66.964287 | precision: 96.103897 | recall: 18.316832 | f2: 21.854696
2023-05-24 23:41:39,153 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 7 | train -> loss: 2729.17167 | validation -> loss: 690.99874 | accuracy: 63.194443 | precision: 100.000000 | recall: 8.168317 | f2: 10.006064
2023-05-24 23:42:31,124 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 8 | train -> loss: 2623.98340 | validation -> loss: 746.19201 | accuracy: 60.218258 | precision: 100.000000 | recall: 0.742574 | f2: 0.926498
2023-05-24 23:43:23,028 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 9 | train -> loss: 2334.70087 | validation -> loss: 535.77753 | accuracy: 80.952385 | precision: 76.237625 | recall: 76.237625 | f2: 76.237625
2023-05-24 23:44:14,408 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 10 | train -> loss: 2026.14385 | validation -> loss: 532.43594 | accuracy: 82.043655 | precision: 78.961037 | recall: 75.247528 | f2: 75.962021
2023-05-24 23:45:06,803 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 11 | train -> loss: 1984.29922 | validation -> loss: 512.47009 | accuracy: 82.142860 | precision: 79.166672 | recall: 75.247528 | f2: 76.000000
2023-05-24 23:45:57,808 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 12 | train -> loss: 2001.84633 | validation -> loss: 525.63935 | accuracy: 81.448410 | precision: 78.036179 | recall: 74.752472 | f2: 75.386917
2023-05-24 23:46:49,956 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 13 | train -> loss: 1959.16688 | validation -> loss: 501.47389 | accuracy: 83.432541 | precision: 82.465759 | recall: 74.504944 | f2: 75.971725
2023-05-24 23:47:42,012 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 14 | train -> loss: 2058.59426 | validation -> loss: 740.96046 | accuracy: 61.210316 | precision: 76.000000 | recall: 4.702971 | f2: 5.789153
2023-05-24 23:48:33,100 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 15 | train -> loss: 2515.68822 | validation -> loss: 554.64614 | accuracy: 90.773811 | precision: 89.974289 | recall: 86.633667 | f2: 87.281792
2023-05-24 23:49:24,720 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 16 | train -> loss: 2917.06017 | validation -> loss: 741.69445 | accuracy: 56.746029 | precision: 44.557823 | recall: 32.425743 | f2: 34.293194
2023-05-24 23:50:16,297 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 17 | train -> loss: 2959.27418 | validation -> loss: 747.17527 | accuracy: 54.067463 | precision: 42.005421 | recall: 38.366337 | f2: 39.042820
2023-05-24 23:51:08,361 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 18 | train -> loss: 2971.76357 | validation -> loss: 738.20561 | accuracy: 62.500000 | precision: 96.428574 | recall: 6.683168 | f2: 8.211679
2023-05-24 23:51:59,876 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 19 | train -> loss: 3008.03867 | validation -> loss: 727.45362 | accuracy: 62.599205 | precision: 55.696201 | recall: 32.673267 | f2: 35.617916
2023-05-24 23:52:51,489 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 20 | train -> loss: 2958.80902 | validation -> loss: 1291.22919 | accuracy: 40.079365 | precision: 40.079365 | recall: 100.000000 | f2: 76.981705
2023-05-24 23:53:42,426 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 21 | train -> loss: 2979.34395 | validation -> loss: 720.48627 | accuracy: 65.674606 | precision: 88.157890 | recall: 16.584158 | f2: 19.799053
2023-05-24 23:53:42,428 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-24 23:54:34,299 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 22 | train -> loss: 2750.73374 | validation -> loss: 598.17632 | accuracy: 78.769836 | precision: 79.503105 | recall: 63.366337 | f2: 66.047470
2023-05-24 23:55:26,668 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 23 | train -> loss: 2989.51950 | validation -> loss: 726.66560 | accuracy: 64.880959 | precision: 96.296295 | recall: 12.871287 | f2: 15.568863
2023-05-24 23:56:18,931 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 24 | train -> loss: 2881.63114 | validation -> loss: 724.04166 | accuracy: 64.583328 | precision: 87.301590 | recall: 13.613862 | f2: 16.378798
2023-05-24 23:57:10,389 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 25 | train -> loss: 2865.71925 | validation -> loss: 731.71119 | accuracy: 63.888889 | precision: 97.619041 | recall: 10.148515 | f2: 12.364294
2023-05-24 23:58:02,144 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 26 | train -> loss: 2808.21756 | validation -> loss: 630.39886 | accuracy: 70.039680 | precision: 93.965515 | recall: 26.980198 | f2: 31.466515
2023-05-24 23:58:53,779 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 27 | train -> loss: 1958.14369 | validation -> loss: 447.85697 | accuracy: 85.615082 | precision: 95.121948 | recall: 67.574257 | f2: 71.728851
2023-05-24 23:59:45,106 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 28 | train -> loss: 1898.90747 | validation -> loss: 507.33606 | accuracy: 84.424606 | precision: 81.585678 | recall: 78.960396 | f2: 79.471848
2023-05-25 00:00:37,075 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 29 | train -> loss: 2682.98687 | validation -> loss: 618.77571 | accuracy: 74.107140 | precision: 98.639458 | recall: 35.891090 | f2: 41.123085
2023-05-25 00:01:29,055 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 30 | train -> loss: 2352.45529 | validation -> loss: 468.92683 | accuracy: 84.325394 | precision: 77.212387 | recall: 86.386139 | f2: 84.381042
2023-05-25 00:02:21,010 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 31 | train -> loss: 1823.42793 | validation -> loss: 428.32317 | accuracy: 86.706345 | precision: 82.926826 | recall: 84.158417 | f2: 83.909180
2023-05-25 00:03:14,347 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 32 | train -> loss: 1721.47672 | validation -> loss: 418.98288 | accuracy: 87.003967 | precision: 84.210526 | recall: 83.168320 | f2: 83.374695
2023-05-25 00:04:07,006 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 33 | train -> loss: 1697.43481 | validation -> loss: 422.93079 | accuracy: 87.003967 | precision: 83.870964 | recall: 83.663368 | f2: 83.704803
2023-05-25 00:05:00,384 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 34 | train -> loss: 1701.59952 | validation -> loss: 413.15569 | accuracy: 87.003967 | precision: 83.870964 | recall: 83.663368 | f2: 83.704803
2023-05-25 00:05:52,433 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 35 | train -> loss: 1696.02098 | validation -> loss: 411.13168 | accuracy: 87.003967 | precision: 84.382874 | recall: 82.920792 | f2: 83.209137
2023-05-25 00:06:44,927 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 36 | train -> loss: 1682.42434 | validation -> loss: 415.79911 | accuracy: 87.500000 | precision: 86.010361 | recall: 82.178215 | f2: 82.917084
2023-05-25 00:07:36,849 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 37 | train -> loss: 1648.40717 | validation -> loss: 426.55614 | accuracy: 87.202385 | precision: 85.714287 | recall: 81.683174 | f2: 82.458771
2023-05-25 00:08:29,084 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 38 | train -> loss: 1737.29117 | validation -> loss: 417.05244 | accuracy: 86.408730 | precision: 97.173141 | recall: 68.069305 | f2: 72.406532
2023-05-25 00:09:21,463 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 39 | train -> loss: 1943.29265 | validation -> loss: 518.10318 | accuracy: 80.158730 | precision: 98.571426 | recall: 51.237625 | f2: 56.681271
2023-05-25 00:10:14,176 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 40 | train -> loss: 2170.74975 | validation -> loss: 569.33972 | accuracy: 76.289680 | precision: 98.816566 | recall: 41.336636 | f2: 46.778713
2023-05-25 00:11:06,588 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 41 | train -> loss: 2264.37714 | validation -> loss: 558.35421 | accuracy: 77.678574 | precision: 98.378380 | recall: 45.049507 | f2: 50.527485
2023-05-25 00:11:58,834 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 42 | train -> loss: 2279.42917 | validation -> loss: 546.07261 | accuracy: 79.166672 | precision: 98.500000 | recall: 48.762375 | f2: 54.240089
2023-05-25 00:12:51,341 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 43 | train -> loss: 2221.33289 | validation -> loss: 528.07036 | accuracy: 79.365082 | precision: 98.514847 | recall: 49.257423 | f2: 54.730476
2023-05-25 00:13:43,254 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 44 | train -> loss: 2184.87732 | validation -> loss: 522.29714 | accuracy: 79.761902 | precision: 97.619041 | recall: 50.742573 | f2: 56.133629
2023-05-25 00:14:35,856 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 45 | train -> loss: 2170.31242 | validation -> loss: 509.15540 | accuracy: 80.753967 | precision: 97.297302 | recall: 53.465347 | f2: 58.759521
2023-05-25 00:15:27,895 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 46 | train -> loss: 2164.48903 | validation -> loss: 580.62156 | accuracy: 74.801590 | precision: 98.701302 | recall: 37.623764 | f2: 42.937855
2023-05-25 00:16:19,850 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 47 | train -> loss: 2333.78532 | validation -> loss: 555.49198 | accuracy: 74.900795 | precision: 98.709679 | recall: 37.871284 | f2: 43.195934
2023-05-25 00:16:19,850 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-25 00:17:11,301 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 48 | train -> loss: 2197.25832 | validation -> loss: 522.23088 | accuracy: 75.198410 | precision: 98.734177 | recall: 38.613861 | f2: 43.968433
2023-05-25 00:18:03,188 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 49 | train -> loss: 2013.92875 | validation -> loss: 475.26582 | accuracy: 77.777779 | precision: 98.387100 | recall: 45.297031 | f2: 50.776917
2023-05-25 00:18:55,331 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 50 | train -> loss: 1835.97756 | validation -> loss: 422.91448 | accuracy: 85.912697 | precision: 92.258064 | recall: 70.792076 | f2: 74.247147
2023-05-25 00:19:46,761 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 51 | train -> loss: 1619.49532 | validation -> loss: 379.27117 | accuracy: 88.591270 | precision: 85.158150 | recall: 86.633667 | f2: 86.334488
2023-05-25 00:20:38,809 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 52 | train -> loss: 1464.06105 | validation -> loss: 343.70883 | accuracy: 89.384918 | precision: 87.594940 | recall: 85.643562 | f2: 86.026855
2023-05-25 00:21:30,038 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 53 | train -> loss: 1462.23545 | validation -> loss: 344.76006 | accuracy: 89.087303 | precision: 86.386139 | recall: 86.386139 | f2: 86.386139
2023-05-25 00:22:21,722 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 54 | train -> loss: 1287.08249 | validation -> loss: 308.42449 | accuracy: 89.384918 | precision: 87.032417 | recall: 86.386139 | f2: 86.514626
2023-05-25 00:23:14,689 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 55 | train -> loss: 1289.17500 | validation -> loss: 319.69484 | accuracy: 87.103180 | precision: 78.189301 | recall: 94.059410 | f2: 90.390106
2023-05-25 00:24:06,936 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 56 | train -> loss: 1151.48111 | validation -> loss: 349.39635 | accuracy: 79.464287 | precision: 66.666672 | recall: 97.524750 | f2: 89.261444
2023-05-25 00:24:59,357 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 57 | train -> loss: 1203.85972 | validation -> loss: 314.94969 | accuracy: 84.424606 | precision: 72.998138 | recall: 97.029701 | f2: 91.035767
2023-05-25 00:25:50,683 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 58 | train -> loss: 1055.04470 | validation -> loss: 309.44840 | accuracy: 88.690475 | precision: 81.250000 | recall: 93.316826 | f2: 90.625000
2023-05-25 00:26:42,293 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 59 | train -> loss: 996.29553 | validation -> loss: 296.58676 | accuracy: 89.384918 | precision: 82.637367 | recall: 93.069305 | f2: 90.777405
2023-05-25 00:27:34,073 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 60 | train -> loss: 990.42029 | validation -> loss: 286.57479 | accuracy: 88.492065 | precision: 79.752060 | recall: 95.544556 | f2: 91.904762
2023-05-25 00:28:25,299 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 61 | train -> loss: 945.12550 | validation -> loss: 288.54679 | accuracy: 88.789680 | precision: 80.631577 | recall: 94.801979 | f2: 91.582970
2023-05-25 00:29:17,658 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 62 | train -> loss: 933.83493 | validation -> loss: 260.03856 | accuracy: 90.972221 | precision: 86.143188 | recall: 92.326729 | f2: 91.020012
2023-05-25 00:30:08,955 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 63 | train -> loss: 866.79287 | validation -> loss: 266.66691 | accuracy: 91.468254 | precision: 88.405800 | recall: 90.594063 | f2: 90.147781
2023-05-25 00:31:00,733 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 64 | train -> loss: 827.20388 | validation -> loss: 256.75017 | accuracy: 91.269836 | precision: 90.306122 | recall: 87.623764 | f2: 88.147408
2023-05-25 00:31:52,039 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 65 | train -> loss: 825.39488 | validation -> loss: 246.49079 | accuracy: 91.071426 | precision: 84.734512 | recall: 94.801979 | f2: 92.601547
2023-05-25 00:32:43,997 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 66 | train -> loss: 782.53285 | validation -> loss: 247.84557 | accuracy: 90.277779 | precision: 82.142860 | recall: 96.782181 | f2: 93.451241
2023-05-25 00:33:35,852 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 67 | train -> loss: 739.97015 | validation -> loss: 249.07143 | accuracy: 91.865082 | precision: 86.926605 | recall: 93.811882 | f2: 92.348930
2023-05-25 00:34:26,672 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 68 | train -> loss: 937.71930 | validation -> loss: 288.50984 | accuracy: 90.277779 | precision: 91.803276 | recall: 83.168320 | f2: 84.762863
2023-05-25 00:35:18,884 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 69 | train -> loss: 883.21817 | validation -> loss: 243.38889 | accuracy: 90.476189 | precision: 90.314140 | recall: 85.396042 | f2: 86.336342
2023-05-25 00:36:11,517 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 70 | train -> loss: 739.85093 | validation -> loss: 274.78134 | accuracy: 89.583328 | precision: 81.341721 | recall: 96.039604 | f2: 92.689919
2023-05-25 00:37:03,796 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 71 | train -> loss: 741.09977 | validation -> loss: 252.39481 | accuracy: 89.980164 | precision: 83.892616 | recall: 92.821785 | f2: 90.887054
2023-05-25 00:37:55,337 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 72 | train -> loss: 749.94509 | validation -> loss: 239.94317 | accuracy: 91.468254 | precision: 85.491074 | recall: 94.801979 | f2: 92.781006
2023-05-25 00:38:47,035 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 73 | train -> loss: 766.42168 | validation -> loss: 243.56396 | accuracy: 91.071426 | precision: 87.380951 | recall: 90.841583 | f2: 90.127701
2023-05-25 00:38:47,036 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-25 00:39:39,058 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 74 | train -> loss: 673.97604 | validation -> loss: 236.53526 | accuracy: 91.567459 | precision: 85.682327 | recall: 94.801979 | f2: 92.825981
2023-05-25 00:40:30,273 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 75 | train -> loss: 702.57933 | validation -> loss: 229.46953 | accuracy: 91.865082 | precision: 87.096771 | recall: 93.564354 | f2: 92.195122
2023-05-25 00:41:22,136 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 76 | train -> loss: 696.17459 | validation -> loss: 235.13073 | accuracy: 92.162697 | precision: 89.156631 | recall: 91.584160 | f2: 91.088135
2023-05-25 00:42:13,647 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 77 | train -> loss: 676.53025 | validation -> loss: 231.60165 | accuracy: 91.964287 | precision: 88.544151 | recall: 91.831680 | f2: 91.154793
2023-05-25 00:43:06,199 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 78 | train -> loss: 672.83342 | validation -> loss: 224.57947 | accuracy: 92.361107 | precision: 89.781021 | recall: 91.336632 | f2: 91.021217
2023-05-25 00:43:58,357 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 79 | train -> loss: 656.79283 | validation -> loss: 229.22106 | accuracy: 92.261902 | precision: 90.147781 | recall: 90.594063 | f2: 90.504448
2023-05-25 00:44:50,425 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 80 | train -> loss: 665.66969 | validation -> loss: 234.24764 | accuracy: 92.658730 | precision: 89.285713 | recall: 92.821785 | f2: 92.092339
2023-05-25 00:45:43,125 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 81 | train -> loss: 670.33432 | validation -> loss: 235.02222 | accuracy: 92.559525 | precision: 88.888893 | recall: 93.069305 | f2: 92.202065
2023-05-25 00:46:35,988 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 82 | train -> loss: 654.73736 | validation -> loss: 228.49629 | accuracy: 92.757935 | precision: 89.311165 | recall: 93.069305 | f2: 92.292587
2023-05-25 00:47:27,831 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 83 | train -> loss: 719.25351 | validation -> loss: 234.80224 | accuracy: 92.063492 | precision: 90.099014 | recall: 90.099014 | f2: 90.099014
2023-05-25 00:48:19,649 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 84 | train -> loss: 639.31567 | validation -> loss: 223.03749 | accuracy: 92.658730 | precision: 89.285713 | recall: 92.821785 | f2: 92.092339
2023-05-25 00:49:11,855 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 85 | train -> loss: 631.86227 | validation -> loss: 221.20468 | accuracy: 92.757935 | precision: 88.941177 | recall: 93.564354 | f2: 92.601662
2023-05-25 00:50:03,714 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 86 | train -> loss: 670.53356 | validation -> loss: 230.94411 | accuracy: 92.460320 | precision: 91.414139 | recall: 89.603958 | f2: 89.960243
2023-05-25 00:50:56,658 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 87 | train -> loss: 679.12882 | validation -> loss: 220.36873 | accuracy: 91.865082 | precision: 90.862946 | recall: 88.613861 | f2: 89.054726
2023-05-25 00:51:48,456 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 88 | train -> loss: 723.27590 | validation -> loss: 228.79744 | accuracy: 91.468254 | precision: 90.561226 | recall: 87.871292 | f2: 88.396416
2023-05-25 00:52:40,493 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 89 | train -> loss: 719.61772 | validation -> loss: 227.31596 | accuracy: 91.666672 | precision: 90.201004 | recall: 88.861389 | f2: 89.126114
2023-05-25 00:53:32,558 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 90 | train -> loss: 701.18737 | validation -> loss: 228.92478 | accuracy: 91.567459 | precision: 89.974937 | recall: 88.861389 | f2: 89.081886
2023-05-25 00:54:23,976 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 91 | train -> loss: 694.00870 | validation -> loss: 229.92735 | accuracy: 91.567459 | precision: 90.176323 | recall: 88.613861 | f2: 88.922005
2023-05-25 00:55:16,662 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 92 | train -> loss: 674.84089 | validation -> loss: 227.90027 | accuracy: 91.567459 | precision: 89.974937 | recall: 88.861389 | f2: 89.081886
2023-05-25 00:56:09,036 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 93 | train -> loss: 655.10932 | validation -> loss: 222.71608 | accuracy: 91.964287 | precision: 90.680099 | recall: 89.108910 | f2: 89.418777
2023-05-25 00:57:01,314 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 94 | train -> loss: 644.79359 | validation -> loss: 222.57940 | accuracy: 91.865082 | precision: 90.656570 | recall: 88.861389 | f2: 89.214714
2023-05-25 00:57:53,061 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 95 | train -> loss: 617.01630 | validation -> loss: 220.62447 | accuracy: 92.162697 | precision: 91.139236 | recall: 89.108910 | f2: 89.507706
2023-05-25 00:58:44,716 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 96 | train -> loss: 621.94487 | validation -> loss: 220.87537 | accuracy: 92.261902 | precision: 90.954773 | recall: 89.603958 | f2: 89.870903
2023-05-25 00:59:37,619 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 97 | train -> loss: 620.36173 | validation -> loss: 226.90227 | accuracy: 91.964287 | precision: 90.886078 | recall: 88.861389 | f2: 89.259079
2023-05-25 01:00:29,775 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 98 | train -> loss: 615.13271 | validation -> loss: 220.93235 | accuracy: 92.063492 | precision: 90.099014 | recall: 90.099014 | f2: 90.099014
2023-05-25 01:01:22,259 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 99 | train -> loss: 602.09878 | validation -> loss: 223.30406 | accuracy: 92.361107 | precision: 90.773071 | recall: 90.099014 | f2: 90.233025
2023-05-25 01:01:22,260 | root | INFO | rnn.py learn @ 113 : fold: 3 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-25 01:02:14,679 | root | INFO | rnn.py learn @ 148 : fold: 3 | epoch: 100 | train -> loss: 598.90426 | validation -> loss: 212.25466 | accuracy: 92.063492 | precision: 90.703514 | recall: 89.356438 | f2: 89.622643
2023-05-25 01:02:15,128 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-lstm-balanced-v2-04/lstm/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f3/model_fold3.pth
2023-05-25 01:02:15,375 | root | INFO | rnn.py learn @ 83 : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
2023-05-25 01:02:15,379 | root | INFO | rnn.py learn @ 84 : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001EBD40C70A0>
2023-05-25 01:02:15,379 | root | INFO | rnn.py learn @ 85 : fetching data for fold #4
2023-05-25 01:02:15,380 | root | ERROR | rnn.py learn @ 106 : 'ReLU' object has no attribute 'reset_parameters'
2023-05-25 01:02:15,381 | root | ERROR | rnn.py learn @ 106 : 'BCEWithLogitsLoss' object has no attribute 'reset_parameters'
2023-05-25 01:02:15,382 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-25 01:02:15,383 | root | INFO | rnn.py learn @ 104 : parameters reset
2023-05-25 01:03:06,667 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 1 | train -> loss: 2970.49643 | validation -> loss: 576.35959 | accuracy: 80.436935 | precision: 80.838326 | recall: 66.997513 | f2: 69.373070
2023-05-25 01:03:58,768 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 2 | train -> loss: 1825.33694 | validation -> loss: 415.36412 | accuracy: 87.090370 | precision: 82.577568 | recall: 85.856079 | f2: 85.179718
2023-05-25 01:04:50,082 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 3 | train -> loss: 1811.31591 | validation -> loss: 400.06745 | accuracy: 85.501495 | precision: 75.751503 | recall: 93.796524 | f2: 89.531029
2023-05-25 01:05:41,424 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 4 | train -> loss: 1546.97980 | validation -> loss: 370.11151 | accuracy: 89.870903 | precision: 90.348526 | recall: 83.622833 | f2: 84.886650
2023-05-25 01:06:32,972 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 5 | train -> loss: 1423.39946 | validation -> loss: 361.29539 | accuracy: 89.672295 | precision: 86.552567 | recall: 87.841187 | f2: 87.580406
2023-05-25 01:07:25,004 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 6 | train -> loss: 1472.09647 | validation -> loss: 390.52123 | accuracy: 87.686195 | precision: 79.492599 | recall: 93.300247 | f2: 90.167870
2023-05-25 01:08:16,270 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 7 | train -> loss: 1905.08782 | validation -> loss: 1173.24249 | accuracy: 65.541214 | precision: 98.275864 | recall: 14.143920 | f2: 17.065868
2023-05-25 01:09:08,786 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 8 | train -> loss: 2206.17743 | validation -> loss: 431.30670 | accuracy: 86.991058 | precision: 85.978836 | recall: 80.645164 | f2: 81.658295
2023-05-25 01:10:01,394 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 9 | train -> loss: 1607.89718 | validation -> loss: 391.62319 | accuracy: 89.076462 | precision: 90.358124 | recall: 81.389580 | f2: 83.037971
2023-05-25 01:10:53,144 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 10 | train -> loss: 1572.37052 | validation -> loss: 393.41155 | accuracy: 88.381332 | precision: 93.597565 | recall: 76.178658 | f2: 79.123711
2023-05-25 01:11:44,509 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 11 | train -> loss: 1514.53491 | validation -> loss: 369.63787 | accuracy: 89.572990 | precision: 91.853935 | recall: 81.141441 | f2: 83.079269
2023-05-25 01:12:36,631 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 12 | train -> loss: 1446.45042 | validation -> loss: 468.75817 | accuracy: 85.898712 | precision: 93.645485 | recall: 69.478912 | f2: 73.260078
2023-05-25 01:13:28,817 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 13 | train -> loss: 1619.44359 | validation -> loss: 393.39899 | accuracy: 88.480637 | precision: 92.581596 | recall: 77.419350 | f2: 80.041046
2023-05-25 01:14:19,962 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 14 | train -> loss: 1507.11184 | validation -> loss: 376.38650 | accuracy: 89.275070 | precision: 93.002914 | recall: 79.156326 | f2: 81.585678
2023-05-25 01:15:11,322 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 15 | train -> loss: 1419.35944 | validation -> loss: 362.98333 | accuracy: 89.870903 | precision: 92.877495 | recall: 80.893303 | f2: 83.036163
2023-05-25 01:16:03,040 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 16 | train -> loss: 1497.86428 | validation -> loss: 461.36452 | accuracy: 84.011917 | precision: 97.637794 | recall: 61.538464 | f2: 66.452309
2023-05-25 01:16:54,770 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 17 | train -> loss: 1814.30124 | validation -> loss: 446.74687 | accuracy: 85.104271 | precision: 96.000000 | recall: 65.508690 | f2: 69.952301
2023-05-25 01:17:47,166 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 18 | train -> loss: 1816.62857 | validation -> loss: 439.14346 | accuracy: 85.700104 | precision: 95.438591 | recall: 67.493797 | f2: 71.692146
2023-05-25 01:18:39,161 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 19 | train -> loss: 2069.03678 | validation -> loss: 722.60372 | accuracy: 63.753723 | precision: 97.500000 | recall: 9.677419 | f2: 11.803874
2023-05-25 01:19:30,292 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 20 | train -> loss: 2882.94993 | validation -> loss: 729.47696 | accuracy: 64.647469 | precision: 96.078430 | recall: 12.158809 | f2: 14.732411
2023-05-25 01:20:21,984 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 21 | train -> loss: 2949.04878 | validation -> loss: 736.06556 | accuracy: 63.257198 | precision: 94.594589 | recall: 8.684864 | f2: 10.612493
2023-05-25 01:20:21,985 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 22 | Learning rate changed from: 0.0005 -> 0.000125
2023-05-25 01:21:14,100 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 22 | train -> loss: 2914.47595 | validation -> loss: 726.24124 | accuracy: 64.448860 | precision: 97.872337 | recall: 11.414392 | f2: 13.863773
2023-05-25 01:22:06,637 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 23 | train -> loss: 2821.00788 | validation -> loss: 688.93241 | accuracy: 69.513405 | precision: 96.153847 | recall: 24.813896 | f2: 29.137527
2023-05-25 01:22:59,023 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 24 | train -> loss: 2743.03587 | validation -> loss: 722.86285 | accuracy: 63.853031 | precision: 100.000000 | recall: 9.677419 | f2: 11.811024
2023-05-25 01:23:50,861 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 25 | train -> loss: 2554.63027 | validation -> loss: 463.76763 | accuracy: 85.898712 | precision: 92.786880 | recall: 70.223328 | f2: 73.813248
2023-05-25 01:24:42,313 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 26 | train -> loss: 1638.04741 | validation -> loss: 398.23541 | accuracy: 87.686195 | precision: 96.345512 | recall: 71.960297 | f2: 75.797180
2023-05-25 01:25:34,567 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 27 | train -> loss: 1633.47983 | validation -> loss: 320.54455 | accuracy: 89.672295 | precision: 84.848488 | recall: 90.322578 | f2: 89.171974
2023-05-25 01:26:26,654 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 28 | train -> loss: 1177.83940 | validation -> loss: 280.56808 | accuracy: 90.764648 | precision: 87.621361 | recall: 89.578163 | f2: 89.179840
2023-05-25 01:27:18,651 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 29 | train -> loss: 1304.01020 | validation -> loss: 352.94042 | accuracy: 90.466728 | precision: 87.714989 | recall: 88.585609 | f2: 88.410103
2023-05-25 01:28:10,063 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 30 | train -> loss: 1177.05080 | validation -> loss: 437.89703 | accuracy: 84.409134 | precision: 72.363640 | recall: 98.759308 | f2: 92.044403
2023-05-25 01:29:02,391 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 31 | train -> loss: 2469.89952 | validation -> loss: 642.75106 | accuracy: 60.575970 | precision: 50.375004 | recall: 100.000000 | f2: 83.540634
2023-05-25 01:29:54,849 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 32 | train -> loss: 2181.10305 | validation -> loss: 507.52574 | accuracy: 72.591858 | precision: 59.407406 | recall: 99.503723 | f2: 87.669441
2023-05-25 01:30:46,485 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 33 | train -> loss: 1186.21273 | validation -> loss: 228.80387 | accuracy: 92.552139 | precision: 91.414139 | recall: 89.826302 | f2: 90.139442
2023-05-25 01:31:39,209 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 34 | train -> loss: 712.33737 | validation -> loss: 214.37183 | accuracy: 92.651436 | precision: 85.995628 | recall: 97.518608 | f2: 94.973412
2023-05-25 01:32:30,895 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 35 | train -> loss: 754.12892 | validation -> loss: 193.31850 | accuracy: 92.949356 | precision: 90.886703 | recall: 91.563271 | f2: 91.427155
2023-05-25 01:33:23,461 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 36 | train -> loss: 554.39682 | validation -> loss: 221.30595 | accuracy: 91.956306 | precision: 86.261261 | recall: 95.037224 | f2: 93.142021
2023-05-25 01:34:15,038 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 37 | train -> loss: 409.48952 | validation -> loss: 276.13199 | accuracy: 90.268120 | precision: 81.443298 | recall: 98.014893 | f2: 94.182167
2023-05-25 01:35:07,567 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 38 | train -> loss: 393.66253 | validation -> loss: 216.05175 | accuracy: 91.757698 | precision: 84.632034 | recall: 97.022331 | f2: 94.262299
2023-05-25 01:35:59,156 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 39 | train -> loss: 328.40023 | validation -> loss: 273.83510 | accuracy: 89.672295 | precision: 80.324539 | recall: 98.263023 | f2: 94.061752
2023-05-25 01:36:50,725 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 40 | train -> loss: 416.28700 | validation -> loss: 245.28731 | accuracy: 89.473686 | precision: 79.759521 | recall: 98.759308 | f2: 94.268120
2023-05-25 01:37:43,164 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 41 | train -> loss: 588.89673 | validation -> loss: 327.83161 | accuracy: 90.665344 | precision: 82.389938 | recall: 97.518608 | f2: 94.064148
2023-05-25 01:38:34,505 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 42 | train -> loss: 339.73518 | validation -> loss: 277.74019 | accuracy: 90.367432 | precision: 81.481483 | recall: 98.263023 | f2: 94.375595
2023-05-25 01:39:27,033 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 43 | train -> loss: 266.58645 | validation -> loss: 298.04080 | accuracy: 89.076462 | precision: 78.895462 | recall: 99.255585 | f2: 94.384148
2023-05-25 01:40:19,218 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 44 | train -> loss: 243.32996 | validation -> loss: 381.35688 | accuracy: 89.076462 | precision: 79.241516 | recall: 98.511162 | f2: 93.942261
2023-05-25 01:41:10,959 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 45 | train -> loss: 225.72868 | validation -> loss: 305.43719 | accuracy: 89.473686 | precision: 79.405937 | recall: 99.503723 | f2: 94.709488
2023-05-25 01:42:03,462 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 46 | train -> loss: 241.19611 | validation -> loss: 402.31469 | accuracy: 89.076462 | precision: 79.241516 | recall: 98.511162 | f2: 93.942261
2023-05-25 01:42:55,126 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 47 | train -> loss: 204.86992 | validation -> loss: 440.99642 | accuracy: 88.877853 | precision: 79.275658 | recall: 97.766754 | f2: 93.409195
2023-05-25 01:42:55,127 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 48 | Learning rate changed from: 0.000125 -> 3.125e-05
2023-05-25 01:43:47,041 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 48 | train -> loss: 169.98065 | validation -> loss: 436.14304 | accuracy: 88.182724 | precision: 77.734375 | recall: 98.759308 | f2: 93.691147
2023-05-25 01:44:39,329 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 49 | train -> loss: 158.76632 | validation -> loss: 396.57004 | accuracy: 88.679245 | precision: 78.842316 | recall: 98.014893 | f2: 93.469002
2023-05-25 01:45:31,402 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 50 | train -> loss: 147.24970 | validation -> loss: 378.36557 | accuracy: 89.275070 | precision: 79.678070 | recall: 98.263023 | f2: 93.883362
2023-05-25 01:46:22,861 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 51 | train -> loss: 127.03509 | validation -> loss: 348.80891 | accuracy: 89.672295 | precision: 80.824745 | recall: 97.270470 | f2: 93.466858
2023-05-25 01:47:14,614 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 52 | train -> loss: 193.12370 | validation -> loss: 323.68829 | accuracy: 91.956306 | precision: 86.590912 | recall: 94.540939 | f2: 92.836258
2023-05-25 01:48:06,271 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 53 | train -> loss: 140.42918 | validation -> loss: 365.01798 | accuracy: 89.870903 | precision: 81.684204 | recall: 96.277916 | f2: 92.956390
2023-05-25 01:48:58,331 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 54 | train -> loss: 124.11451 | validation -> loss: 415.13251 | accuracy: 88.877853 | precision: 79.754601 | recall: 96.774193 | f2: 92.812943
2023-05-25 01:49:49,509 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 55 | train -> loss: 144.60173 | validation -> loss: 491.37817 | accuracy: 87.189674 | precision: 76.447876 | recall: 98.263023 | f2: 92.957748
2023-05-25 01:50:41,127 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 56 | train -> loss: 196.68906 | validation -> loss: 334.01246 | accuracy: 91.559090 | precision: 83.686440 | recall: 98.014893 | f2: 94.769676
2023-05-25 01:51:33,057 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 57 | train -> loss: 130.86342 | validation -> loss: 352.40389 | accuracy: 89.672295 | precision: 80.324539 | recall: 98.263023 | f2: 94.061752
2023-05-25 01:52:25,592 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 58 | train -> loss: 111.33978 | validation -> loss: 369.50705 | accuracy: 89.672295 | precision: 80.202019 | recall: 98.511162 | f2: 94.209778
2023-05-25 01:53:17,412 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 59 | train -> loss: 163.53744 | validation -> loss: 544.97135 | accuracy: 85.302879 | precision: 73.139748 | recall: 100.000000 | f2: 93.157646
2023-05-25 01:54:09,438 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 60 | train -> loss: 129.41692 | validation -> loss: 321.03491 | accuracy: 90.168816 | precision: 81.147537 | recall: 98.263023 | f2: 94.285713
2023-05-25 01:55:01,042 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 61 | train -> loss: 107.68581 | validation -> loss: 390.96363 | accuracy: 90.168816 | precision: 80.894310 | recall: 98.759308 | f2: 94.581749
2023-05-25 01:55:53,116 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 62 | train -> loss: 141.76770 | validation -> loss: 366.01705 | accuracy: 89.175766 | precision: 79.518074 | recall: 98.263023 | f2: 93.838867
2023-05-25 01:56:44,891 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 63 | train -> loss: 107.79718 | validation -> loss: 391.46610 | accuracy: 89.473686 | precision: 80.121704 | recall: 98.014893 | f2: 93.824226
2023-05-25 01:57:36,932 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 64 | train -> loss: 103.27510 | validation -> loss: 387.82411 | accuracy: 90.268120 | precision: 81.443298 | recall: 98.014893 | f2: 94.182167
2023-05-25 01:58:28,739 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 65 | train -> loss: 91.82806 | validation -> loss: 376.93062 | accuracy: 90.466728 | precision: 81.912682 | recall: 97.766754 | f2: 94.123268
2023-05-25 01:59:20,014 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 66 | train -> loss: 96.16090 | validation -> loss: 347.96941 | accuracy: 90.367432 | precision: 81.875000 | recall: 97.518608 | f2: 93.929253
2023-05-25 02:00:12,033 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 67 | train -> loss: 88.86015 | validation -> loss: 373.91616 | accuracy: 90.566040 | precision: 81.818184 | recall: 98.263023 | f2: 94.465652
2023-05-25 02:01:03,246 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 68 | train -> loss: 85.06221 | validation -> loss: 361.20470 | accuracy: 91.161865 | precision: 83.122360 | recall: 97.766754 | f2: 94.439117
2023-05-25 02:01:54,753 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 69 | train -> loss: 82.11304 | validation -> loss: 408.01985 | accuracy: 90.367432 | precision: 81.224487 | recall: 98.759308 | f2: 94.671745
2023-05-25 02:02:45,242 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 70 | train -> loss: 124.94243 | validation -> loss: 369.88867 | accuracy: 89.672295 | precision: 80.080482 | recall: 98.759308 | f2: 94.357513
2023-05-25 02:03:37,154 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 71 | train -> loss: 103.56865 | validation -> loss: 410.36717 | accuracy: 88.877853 | precision: 79.158318 | recall: 98.014893 | f2: 93.557556
2023-05-25 02:04:28,495 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 72 | train -> loss: 88.53702 | validation -> loss: 349.11970 | accuracy: 90.863953 | precision: 82.599579 | recall: 97.766754 | f2: 94.303497
2023-05-25 02:05:20,937 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 73 | train -> loss: 88.02216 | validation -> loss: 355.24534 | accuracy: 90.863953 | precision: 82.463470 | recall: 98.014893 | f2: 94.452415
2023-05-25 02:05:20,938 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 74 | Learning rate changed from: 3.125e-05 -> 7.8125e-06
2023-05-25 02:06:12,858 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 74 | train -> loss: 73.70098 | validation -> loss: 386.34855 | accuracy: 90.466728 | precision: 81.519508 | recall: 98.511162 | f2: 94.568840
2023-05-25 02:07:04,468 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 75 | train -> loss: 68.37566 | validation -> loss: 394.60128 | accuracy: 90.566040 | precision: 81.557373 | recall: 98.759308 | f2: 94.761902
2023-05-25 02:07:55,699 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 76 | train -> loss: 72.37793 | validation -> loss: 394.72466 | accuracy: 90.764648 | precision: 81.893005 | recall: 98.759308 | f2: 94.852242
2023-05-25 02:08:47,591 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 77 | train -> loss: 66.31751 | validation -> loss: 402.90741 | accuracy: 90.764648 | precision: 82.024796 | recall: 98.511162 | f2: 94.704201
2023-05-25 02:09:39,488 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 78 | train -> loss: 74.30915 | validation -> loss: 419.61713 | accuracy: 90.665344 | precision: 81.724846 | recall: 98.759308 | f2: 94.807053
2023-05-25 02:10:31,067 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 79 | train -> loss: 67.06794 | validation -> loss: 435.26392 | accuracy: 90.963257 | precision: 82.231400 | recall: 98.759308 | f2: 94.942749
2023-05-25 02:11:23,115 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 80 | train -> loss: 70.59824 | validation -> loss: 413.03828 | accuracy: 91.062561 | precision: 82.536385 | recall: 98.511162 | f2: 94.839943
2023-05-25 02:12:15,037 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 81 | train -> loss: 67.14483 | validation -> loss: 388.99690 | accuracy: 90.963257 | precision: 82.365143 | recall: 98.511162 | f2: 94.794647
2023-05-25 02:13:05,461 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 82 | train -> loss: 66.88343 | validation -> loss: 408.35531 | accuracy: 90.367432 | precision: 81.352463 | recall: 98.511162 | f2: 94.523811
2023-05-25 02:13:57,219 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 83 | train -> loss: 69.92147 | validation -> loss: 402.70542 | accuracy: 90.367432 | precision: 81.352463 | recall: 98.511162 | f2: 94.523811
2023-05-25 02:14:49,255 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 84 | train -> loss: 65.38598 | validation -> loss: 446.11038 | accuracy: 89.970207 | precision: 80.691055 | recall: 98.511162 | f2: 94.344109
2023-05-25 02:15:41,429 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 85 | train -> loss: 61.83408 | validation -> loss: 459.53973 | accuracy: 89.572990 | precision: 80.040321 | recall: 98.511162 | f2: 94.165085
2023-05-25 02:16:33,797 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 86 | train -> loss: 62.63130 | validation -> loss: 462.83060 | accuracy: 89.473686 | precision: 79.759521 | recall: 98.759308 | f2: 94.268120
2023-05-25 02:17:26,002 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 87 | train -> loss: 69.21467 | validation -> loss: 447.38771 | accuracy: 89.175766 | precision: 79.400002 | recall: 98.511162 | f2: 93.986740
2023-05-25 02:18:18,304 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 88 | train -> loss: 61.26278 | validation -> loss: 431.97853 | accuracy: 90.069511 | precision: 80.855400 | recall: 98.511162 | f2: 94.388969
2023-05-25 02:19:10,771 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 89 | train -> loss: 60.87302 | validation -> loss: 459.42691 | accuracy: 89.771599 | precision: 80.364372 | recall: 98.511162 | f2: 94.254509
2023-05-25 02:20:02,211 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 90 | train -> loss: 61.53622 | validation -> loss: 488.72793 | accuracy: 89.572990 | precision: 80.040321 | recall: 98.511162 | f2: 94.165085
2023-05-25 02:20:54,493 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 91 | train -> loss: 71.69711 | validation -> loss: 405.46409 | accuracy: 89.970207 | precision: 80.816330 | recall: 98.263023 | f2: 94.196007
2023-05-25 02:21:46,563 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 92 | train -> loss: 67.93448 | validation -> loss: 469.04469 | accuracy: 89.870903 | precision: 80.527382 | recall: 98.511162 | f2: 94.299286
2023-05-25 02:22:38,159 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 93 | train -> loss: 61.12491 | validation -> loss: 466.97119 | accuracy: 89.771599 | precision: 80.364372 | recall: 98.511162 | f2: 94.254509
2023-05-25 02:23:30,544 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 94 | train -> loss: 60.28356 | validation -> loss: 491.60326 | accuracy: 89.572990 | precision: 80.040321 | recall: 98.511162 | f2: 94.165085
2023-05-25 02:24:22,599 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 95 | train -> loss: 65.62590 | validation -> loss: 487.18713 | accuracy: 89.672295 | precision: 80.202019 | recall: 98.511162 | f2: 94.209778
2023-05-25 02:25:15,327 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 96 | train -> loss: 59.92072 | validation -> loss: 484.40903 | accuracy: 89.771599 | precision: 80.364372 | recall: 98.511162 | f2: 94.254509
2023-05-25 02:26:07,517 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 97 | train -> loss: 64.74220 | validation -> loss: 494.35452 | accuracy: 89.374382 | precision: 79.718872 | recall: 98.511162 | f2: 94.075829
2023-05-25 02:26:59,589 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 98 | train -> loss: 67.73891 | validation -> loss: 502.64509 | accuracy: 89.175766 | precision: 79.757080 | recall: 97.766754 | f2: 93.542259
2023-05-25 02:27:51,236 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 99 | train -> loss: 59.28128 | validation -> loss: 492.94714 | accuracy: 89.374382 | precision: 79.718872 | recall: 98.511162 | f2: 94.075829
2023-05-25 02:27:51,237 | root | INFO | rnn.py learn @ 113 : fold: 4 | epoch: 100 | Learning rate changed from: 7.8125e-06 -> 1.953125e-06
2023-05-25 02:28:43,349 | root | INFO | rnn.py learn @ 148 : fold: 4 | epoch: 100 | train -> loss: 60.25102 | validation -> loss: 490.96290 | accuracy: 89.275070 | precision: 79.559120 | recall: 98.511162 | f2: 94.031265
2023-05-25 02:28:43,790 | root | INFO | rnn.py save @ 198 : saving sanpshot at output/05-24-2023-13-12-01-lstm-balanced-v2-04/lstm/basic-sequential/rr.idr-lr0.000500-h512-l1/weights/f4/model_fold4.pth
2023-05-25 02:28:44,154 | root | INFO | rnn.py learn @ 166 : best model of cross validation for current training phase: fold #4 with metric value of '0.985111653804779'
